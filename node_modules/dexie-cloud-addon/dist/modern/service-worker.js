/* ========================================================================== 
 *                           dexie-cloud-addon.js
 * ==========================================================================
 *
 * Dexie addon that syncs IndexedDB with Dexie Cloud.
 *
 * By David Fahlander, david@dexie.org
 *
 * ==========================================================================
 *
 * Version 4.2.5, Sat Dec 20 2025
 *
 * https://dexie.org
 *
 * Apache License Version 2.0, January 2004, http://www.apache.org/licenses/
 * 
 */

import Dexie, { PropModification, cmp, RangeSet, liveQuery } from 'dexie';
import { Observable, BehaviorSubject, firstValueFrom, Subject, from, filter as filter$1, of, fromEvent, merge, switchMap as switchMap$1, tap as tap$1, mergeMap, Subscription, throwError, combineLatest, map as map$1, share, timer, startWith as startWith$1 } from 'rxjs';
import { filter, switchMap, delay, distinctUntilChanged, map, tap, take, catchError, debounceTime, startWith, skip } from 'rxjs/operators';
import { Encoder, writeVarString, writeAny, writeVarUint8Array, writeBigUint64, toUint8Array } from 'lib0/encoding';
import { Decoder, readVarString, readAny, readVarUint8Array, readBigUint64, hasContent, readUint8 } from 'lib0/decoding';
import * as Y from 'yjs';
import { DexieYProvider } from 'y-dexie';
import * as awap from 'y-protocols/awareness';

/******************************************************************************
Copyright (c) Microsoft Corporation.

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
PERFORMANCE OF THIS SOFTWARE.
***************************************************************************** */
/* global Reflect, Promise, SuppressedError, Symbol, Iterator */


function __rest(s, e) {
    var t = {};
    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)
        t[p] = s[p];
    if (s != null && typeof Object.getOwnPropertySymbols === "function")
        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {
            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))
                t[p[i]] = s[p[i]];
        }
    return t;
}

function __awaiter(thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
}

function __values(o) {
    var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
    if (m) return m.call(o);
    if (o && typeof o.length === "number") return {
        next: function () {
            if (o && i >= o.length) o = void 0;
            return { value: o && o[i++], done: !o };
        }
    };
    throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
}

function __await(v) {
    return this instanceof __await ? (this.v = v, this) : new __await(v);
}

function __asyncGenerator(thisArg, _arguments, generator) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var g = generator.apply(thisArg, _arguments || []), i, q = [];
    return i = Object.create((typeof AsyncIterator === "function" ? AsyncIterator : Object).prototype), verb("next"), verb("throw"), verb("return", awaitReturn), i[Symbol.asyncIterator] = function () { return this; }, i;
    function awaitReturn(f) { return function (v) { return Promise.resolve(v).then(f, reject); }; }
    function verb(n, f) { if (g[n]) { i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; if (f) i[n] = f(i[n]); } }
    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }
    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }
    function fulfill(value) { resume("next", value); }
    function reject(value) { resume("throw", value); }
    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }
}

function __asyncValues(o) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var m = o[Symbol.asyncIterator], i;
    return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function () { return this; }, i);
    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }
    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }
}

typeof SuppressedError === "function" ? SuppressedError : function (error, suppressed, message) {
    var e = new Error(message);
    return e.name = "SuppressedError", e.error = error, e.suppressed = suppressed, e;
};

const UNAUTHORIZED_USER = {
    userId: "unauthorized",
    name: "Unauthorized",
    claims: {
        sub: "unauthorized",
    },
    lastLogin: new Date(0)
};
try {
    Object.freeze(UNAUTHORIZED_USER);
    Object.freeze(UNAUTHORIZED_USER.claims);
}
catch (_a) { }

const swHolder = {};
const swContainer = typeof self !== 'undefined' && self.document && // self.document is to verify we're not the SW ourself
    typeof navigator !== 'undefined' && navigator.serviceWorker;
if (swContainer)
    swContainer.ready.then((registration) => (swHolder.registration = registration));
if (typeof self !== 'undefined' && 'clients' in self && !self.document) {
    // We are the service worker. Propagate messages to all our clients.
    addEventListener('message', (ev) => {
        var _a, _b;
        if ((_b = (_a = ev.data) === null || _a === void 0 ? void 0 : _a.type) === null || _b === void 0 ? void 0 : _b.startsWith('sw-broadcast-')) {
            [...self['clients'].matchAll({ includeUncontrolled: true })].forEach((client) => { var _a; return client.id !== ((_a = ev.source) === null || _a === void 0 ? void 0 : _a.id) && client.postMessage(ev.data); });
        }
    });
}
/** This class is a fallback for browsers that lacks BroadcastChannel but have
 * service workers (which is Safari versions 11.1 through 15.3).
 * Safari 15.4 with BroadcastChannel was released on 2022-03-14.
 * We might be able to remove this class in a near future as Safari < 15.4 is
 * already very low in market share as of 2023-03-10.
 */
class SWBroadcastChannel {
    constructor(name) {
        this.name = name;
    }
    subscribe(listener) {
        if (!swContainer)
            return () => { };
        const forwarder = (ev) => {
            var _a;
            if (((_a = ev.data) === null || _a === void 0 ? void 0 : _a.type) === `sw-broadcast-${this.name}`) {
                listener(ev.data.message);
            }
        };
        swContainer.addEventListener('message', forwarder);
        return () => swContainer.removeEventListener('message', forwarder);
    }
    postMessage(message) {
        var _a;
        if (typeof self['clients'] === 'object') {
            // We're a service worker. Propagate to our browser clients.
            [...self['clients'].matchAll({ includeUncontrolled: true })].forEach((client) => client.postMessage({
                type: `sw-broadcast-${this.name}`,
                message,
            }));
        }
        else if (swHolder.registration) {
            // We're a client (browser window or other worker)
            // Post to SW so it can repost to all its clients and to itself
            (_a = swHolder.registration.active) === null || _a === void 0 ? void 0 : _a.postMessage({
                type: `sw-broadcast-${this.name}`,
                message,
            });
        }
    }
}

const events = globalThis['lbc-events'] || (globalThis['lbc-events'] = new Map());
function addListener(name, listener) {
    if (events.has(name)) {
        events.get(name).push(listener);
    }
    else {
        events.set(name, [listener]);
    }
}
function removeListener(name, listener) {
    const listeners = events.get(name);
    if (listeners) {
        const idx = listeners.indexOf(listener);
        if (idx !== -1) {
            listeners.splice(idx, 1);
        }
    }
}
function dispatch(ev) {
    const listeners = events.get(ev.type);
    if (listeners) {
        listeners.forEach(listener => {
            try {
                listener(ev);
            }
            catch (_a) {
            }
        });
    }
}
class BroadcastedAndLocalEvent extends Observable {
    constructor(name) {
        const bc = typeof BroadcastChannel === "undefined"
            ? new SWBroadcastChannel(name) : new BroadcastChannel(name);
        super(subscriber => {
            function onCustomEvent(ev) {
                subscriber.next(ev.detail);
            }
            function onMessageEvent(ev) {
                console.debug("BroadcastedAndLocalEvent: onMessageEvent", ev);
                subscriber.next(ev.data);
            }
            let unsubscribe;
            //self.addEventListener(`lbc-${name}`, onCustomEvent); // Fails in service workers
            addListener(`lbc-${name}`, onCustomEvent); // Works better in service worker
            try {
                if (bc instanceof SWBroadcastChannel) {
                    unsubscribe = bc.subscribe(message => subscriber.next(message));
                }
                else {
                    console.debug("BroadcastedAndLocalEvent: bc.addEventListener()", name, "bc is a", bc);
                    bc.addEventListener("message", onMessageEvent);
                }
            }
            catch (err) {
                // Service workers might fail to subscribe outside its initial script.
                console.warn('Failed to subscribe to broadcast channel', err);
            }
            return () => {
                //self.removeEventListener(`lbc-${name}`, onCustomEvent);
                removeListener(`lbc-${name}`, onCustomEvent);
                if (bc instanceof SWBroadcastChannel) {
                    unsubscribe();
                }
                else {
                    bc.removeEventListener("message", onMessageEvent);
                }
            };
        });
        this.name = name;
        this.bc = bc;
    }
    next(message) {
        console.debug("BroadcastedAndLocalEvent: bc.postMessage()", Object.assign({}, message), "bc is a", this.bc);
        this.bc.postMessage(message);
        const ev = new CustomEvent(`lbc-${this.name}`, { detail: message });
        //self.dispatchEvent(ev);
        dispatch(ev);
    }
}

//const hasSW = 'serviceWorker' in navigator;
let hasComplainedAboutSyncEvent = false;
function registerSyncEvent(db, purpose) {
    return __awaiter(this, void 0, void 0, function* () {
        try {
            // Send sync event to SW:
            const sw = yield navigator.serviceWorker.ready;
            if (purpose === "push" && sw.sync) {
                yield sw.sync.register(`dexie-cloud:${db.name}`);
            }
            if (sw.active) {
                // Use postMessage for pull syncs and for browsers not supporting sync event (Firefox, Safari).
                // Also chromium based browsers with sw.sync as a fallback for sleepy sync events not taking action for a while.
                sw.active.postMessage({
                    type: 'dexie-cloud-sync',
                    dbName: db.name,
                    purpose
                });
            }
            else {
                throw new Error(`Failed to trigger sync - there's no active service worker`);
            }
            return;
        }
        catch (e) {
            if (!hasComplainedAboutSyncEvent) {
                console.debug(`Dexie Cloud: Could not register sync event`, e);
                hasComplainedAboutSyncEvent = true;
            }
        }
    });
}
function registerPeriodicSyncEvent(db) {
    return __awaiter(this, void 0, void 0, function* () {
        var _a;
        try {
            // Register periodicSync event to SW:
            // @ts-ignore
            const { periodicSync } = yield navigator.serviceWorker.ready;
            if (periodicSync) {
                try {
                    yield periodicSync.register(`dexie-cloud:${db.name}`, (_a = db.cloud.options) === null || _a === void 0 ? void 0 : _a.periodicSync);
                    console.debug(`Dexie Cloud: Successfully registered periodicsync event for ${db.name}`);
                }
                catch (e) {
                    console.debug(`Dexie Cloud: Failed to register periodic sync. Your PWA must be installed to allow background sync.`, e);
                }
            }
            else {
                console.debug(`Dexie Cloud: periodicSync not supported.`);
            }
        }
        catch (e) {
            console.debug(`Dexie Cloud: Could not register periodicSync for ${db.name}`, e);
        }
    });
}

function triggerSync(db, purpose) {
    if (db.cloud.usingServiceWorker) {
        console.debug('registering sync event');
        registerSyncEvent(db, purpose);
    }
    else {
        db.localSyncEvent.next({ purpose });
    }
}

const hasArrayBufferFromBase64 = "fromBase64" in Uint8Array; // https://github.com/tc39/proposal-arraybuffer-base64;
const hasArrayBufferToBase64 = "toBase64" in Uint8Array.prototype; // https://github.com/tc39/proposal-arraybuffer-base64;
const b64decode = typeof Buffer !== "undefined"
    ? (base64) => Buffer.from(base64, "base64") // Node
    : hasArrayBufferFromBase64
        ? // @ts-ignore: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array/fromBase64
            (base64) => Uint8Array.fromBase64(base64) // Modern javascript standard
        : (base64) => {
            // Legacy DOM workaround
            const binary_string = atob(base64);
            const len = binary_string.length;
            const bytes = new Uint8Array(len);
            for (var i = 0; i < len; i++) {
                bytes[i] = binary_string.charCodeAt(i);
            }
            return bytes;
        };
const b64encode = typeof Buffer !== "undefined"
    ? (b) => {
        // Node
        if (ArrayBuffer.isView(b)) {
            return Buffer.from(b.buffer, b.byteOffset, b.byteLength).toString("base64");
        }
        else {
            return Buffer.from(b).toString("base64");
        }
    }
    : hasArrayBufferToBase64
        ? (b) => {
            // Uint8Array.prototype.toBase64 is available in modern browsers
            const u8a = ArrayBuffer.isView(b) ? b : new Uint8Array(b);
            // @ts-ignore: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array/toBase64
            return u8a.toBase64();
        }
        : (b) => {
            // Legacy DOM workaround
            const u8a = ArrayBuffer.isView(b) ? b : new Uint8Array(b);
            const CHUNK_SIZE = 0x1000;
            const strs = [];
            for (let i = 0, l = u8a.length; i < l; i += CHUNK_SIZE) {
                const chunk = u8a.subarray(i, i + CHUNK_SIZE);
                strs.push(String.fromCharCode.apply(null, chunk));
            }
            return btoa(strs.join(""));
        };

function computeRealmSetHash(_a) {
    return __awaiter(this, arguments, void 0, function* ({ realms, inviteRealms, }) {
        const data = JSON.stringify([
            ...realms.map((realmId) => ({ realmId, accepted: true })),
            ...inviteRealms.map((realmId) => ({ realmId, accepted: false })),
        ].sort((a, b) => a.realmId < b.realmId ? -1 : a.realmId > b.realmId ? 1 : 0));
        const byteArray = new TextEncoder().encode(data);
        const digestBytes = yield crypto.subtle.digest('SHA-1', byteArray);
        const base64 = b64encode(digestBytes);
        return base64;
    });
}

function getSyncableTables(db) {
    return Object.entries(db.cloud.schema || {})
        .filter(([, { markedForSync }]) => markedForSync)
        .map(([tbl]) => db.tables.filter(({ name }) => name === tbl)[0])
        .filter(cloudTableSchema => cloudTableSchema);
}

function getMutationTable(tableName) {
    return `$${tableName}_mutations`;
}

function getTableFromMutationTable(mutationTable) {
    var _a;
    const tableName = (_a = /^\$(.*)_mutations$/.exec(mutationTable)) === null || _a === void 0 ? void 0 : _a[1];
    if (!tableName)
        throw new Error(`Given mutationTable ${mutationTable} is not correct`);
    return tableName;
}

const concat = [].concat;
function flatten(a) {
    return concat.apply([], a);
}

function listClientChanges(mutationTables_1, db_1) {
    return __awaiter(this, arguments, void 0, function* (mutationTables, db, { since = {}, limit = Infinity } = {}) {
        const allMutsOnTables = yield Promise.all(mutationTables.map((mutationTable) => __awaiter(this, void 0, void 0, function* () {
            const tableName = getTableFromMutationTable(mutationTable.name);
            const lastRevision = since[tableName];
            let query = lastRevision
                ? mutationTable.where('rev').above(lastRevision)
                : mutationTable;
            if (limit < Infinity)
                query = query.limit(limit);
            let muts = yield query.toArray();
            muts = canonicalizeToUpdateOps(muts);
            muts = removeRedundantUpdateOps(muts);
            const rv = muts.map((mut) => ({
                table: tableName,
                mut,
            }));
            return rv;
        })));
        // Sort by time to get a true order of the operations (between tables)
        const sorted = flatten(allMutsOnTables).sort((a, b) => a.mut.txid === b.mut.txid
            ? a.mut.opNo - b.mut.opNo // Within same transaction, sort by opNo
            : a.mut.ts - b.mut.ts // Different transactions - sort by timestamp when mutation resolved
        );
        const result = [];
        let currentEntry = null;
        let currentTxid = null;
        for (const { table, mut } of sorted) {
            if (currentEntry &&
                currentEntry.table === table &&
                currentTxid === mut.txid) {
                currentEntry.muts.push(mut);
            }
            else {
                currentEntry = {
                    table,
                    muts: [mut],
                };
                currentTxid = mut.txid;
                result.push(currentEntry);
            }
        }
        // Filter out those tables that doesn't have any mutations:
        return result;
    });
}
function removeRedundantUpdateOps(muts) {
    const updateCoverage = new Map();
    for (const mut of muts) {
        if (mut.type === 'update') {
            if (mut.keys.length !== 1 || mut.changeSpecs.length !== 1) {
                continue; // Don't optimize multi-key updates
            }
            const strKey = '' + mut.keys[0];
            const changeSpecs = mut.changeSpecs[0];
            if (Object.values(changeSpecs).some(v => typeof v === "object" && v && "@@propmod" in v)) {
                continue; // Cannot optimize if any PropModification is present
            }
            let keyCoverage = updateCoverage.get(strKey);
            if (keyCoverage) {
                keyCoverage.push({ txid: mut.txid, updateSpec: changeSpecs });
            }
            else {
                updateCoverage.set(strKey, [{ txid: mut.txid, updateSpec: changeSpecs }]);
            }
        }
    }
    muts = muts.filter(mut => {
        // Only apply optimization to update mutations that are single-key
        if (mut.type !== 'update')
            return true;
        if (mut.keys.length !== 1 || mut.changeSpecs.length !== 1)
            return true;
        // Check if this has PropModifications - if so, skip optimization
        const changeSpecs = mut.changeSpecs[0];
        if (Object.values(changeSpecs).some(v => typeof v === "object" && v && "@@propmod" in v)) {
            return true; // Cannot optimize if any PropModification is present
        }
        // Keep track of properties that aren't overlapped by later transactions
        const unoverlappedProps = new Set(Object.keys(mut.changeSpecs[0]));
        const strKey = '' + mut.keys[0];
        const keyCoverage = updateCoverage.get(strKey);
        if (!keyCoverage)
            return true; // No coverage info - cannot optimize
        for (let i = keyCoverage.length - 1; i >= 0; --i) {
            const { txid, updateSpec } = keyCoverage[i];
            if (txid === mut.txid)
                break; // Stop when reaching own txid
            // If all changes in updateSpec are covered by all props on all mut.changeSpecs then
            // txid is redundant and can be removed.
            for (const keyPath of Object.keys(updateSpec)) {
                unoverlappedProps.delete(keyPath);
            }
        }
        if (unoverlappedProps.size === 0) {
            // This operation is completely overlapped by later operations. It can be removed.
            return false;
        }
        return true;
    });
    return muts;
}
function canonicalizeToUpdateOps(muts) {
    muts = muts.map(mut => {
        if (mut.type === 'modify' && mut.criteria.index === null) {
            // The criteria is on primary key. Convert to an update operation instead.
            // It is simpler for the server to handle and also more efficient.
            const updateMut = Object.assign(Object.assign({}, mut), { criteria: undefined, changeSpec: undefined, type: 'update', keys: mut.keys, changeSpecs: [mut.changeSpec] });
            delete updateMut.criteria;
            delete updateMut.changeSpec;
            return updateMut;
        }
        return mut;
    });
    return muts;
}

function randomString$1(bytes) {
    const buf = new Uint8Array(bytes);
    if (typeof crypto !== 'undefined') {
        crypto.getRandomValues(buf);
    }
    else {
        for (let i = 0; i < bytes; i++)
            buf[i] = Math.floor(Math.random() * 256);
    }
    if (typeof Buffer !== 'undefined' && Buffer.from) {
        return Buffer.from(buf).toString('base64');
    }
    else if (typeof btoa !== 'undefined') {
        return btoa(String.fromCharCode.apply(null, buf));
    }
    else {
        throw new Error('No btoa or Buffer available');
    }
}

function assert(b) {
    if (!b)
        throw new Error('Assertion Failed');
}
const _hasOwn = {}.hasOwnProperty;
function hasOwn(obj, prop) {
    return _hasOwn.call(obj, prop);
}
function setByKeyPath(obj, keyPath, value) {
    if (!obj || keyPath === undefined)
        return;
    if ('isFrozen' in Object && Object.isFrozen(obj))
        return;
    if (typeof keyPath !== 'string' && 'length' in keyPath) {
        assert(typeof value !== 'string' && 'length' in value);
        for (var i = 0, l = keyPath.length; i < l; ++i) {
            setByKeyPath(obj, keyPath[i], value[i]);
        }
    }
    else {
        var period = keyPath.indexOf('.');
        if (period !== -1) {
            var currentKeyPath = keyPath.substr(0, period);
            var remainingKeyPath = keyPath.substr(period + 1);
            if (remainingKeyPath === '')
                if (value === undefined) {
                    if (Array.isArray(obj)) {
                        if (!isNaN(parseInt(currentKeyPath)))
                            obj.splice(parseInt(currentKeyPath), 1);
                    }
                    else
                        delete obj[currentKeyPath];
                    // @ts-ignore: even if currentKeyPath would be numeric string and obj would be array - it works.
                }
                else
                    obj[currentKeyPath] = value;
            else {
                //@ts-ignore: even if currentKeyPath would be numeric string and obj would be array - it works.
                var innerObj = obj[currentKeyPath];
                //@ts-ignore: even if currentKeyPath would be numeric string and obj would be array - it works.
                if (!innerObj || !hasOwn(obj, currentKeyPath))
                    innerObj = (obj[currentKeyPath] = {});
                setByKeyPath(innerObj, remainingKeyPath, value);
            }
        }
        else {
            if (value === undefined) {
                if (Array.isArray(obj) && !isNaN(parseInt(keyPath)))
                    // @ts-ignore: even if currentKeyPath would be numeric string and obj would be array - it works.
                    obj.splice(keyPath, 1);
                //@ts-ignore: even if currentKeyPath would be numeric string and obj would be array - it works.
                else
                    delete obj[keyPath];
                //@ts-ignore: even if currentKeyPath would be numeric string and obj would be array - it works.
            }
            else
                obj[keyPath] = value;
        }
    }
}
const randomString = typeof self !== 'undefined' && typeof crypto !== 'undefined' ? (bytes, randomFill = crypto.getRandomValues.bind(crypto)) => {
    // Web
    const buf = new Uint8Array(bytes);
    randomFill(buf);
    return self.btoa(String.fromCharCode.apply(null, buf));
} : typeof Buffer !== 'undefined' ? (bytes, randomFill = simpleRandomFill) => {
    // Node
    const buf = Buffer.alloc(bytes);
    randomFill(buf);
    return buf.toString("base64");
} : () => { throw new Error("No implementation of randomString was found"); };
function simpleRandomFill(buf) {
    for (let i = 0; i < buf.length; ++i) {
        buf[i] = Math.floor(Math.random() * 256);
    }
}

/** Verifies that given primary key is valid.
 * The reason we narrow validity for valid keys are twofold:
 *  1: Make sure to only support types that can be used as an object index in DBKeyMutationSet.
 *     For example, ArrayBuffer cannot be used (gives "object ArrayBuffer") but Uint8Array can be
 *     used (gives comma-delimited list of included bytes).
 *  2: Avoid using plain numbers and Dates as keys when they are synced, as they are not globally unique.
 *  3: Since we store the key as a VARCHAR server side in current version, try not promote types that stringifies to become very long server side.
 *
 * @param id
 * @returns
 */
function isValidSyncableID(id) {
    if (typeof id === "string")
        return true;
    //if (validIDTypes[toStringTag(id)]) return true;
    //if (Array.isArray(id)) return id.every((part) => isValidSyncableID(part));
    if (Array.isArray(id) && id.some(key => isValidSyncableID(key)) && id.every(isValidSyncableIDPart))
        return true;
    return false;
}
/** Verifies that given key part is valid.
 *  1: Make sure that arrays of this types are stringified correclty and works with DBKeyMutationSet.
 *     For example, ArrayBuffer cannot be used (gives "object ArrayBuffer") but Uint8Array can be
 *     used (gives comma-delimited list of included bytes).
 *  2: Since we store the key as a VARCHAR server side in current version, try not promote types that stringifies to become very long server side.
*/
function isValidSyncableIDPart(part) {
    return typeof part === "string" || typeof part === "number" || Array.isArray(part) && part.every(isValidSyncableIDPart);
}
function isValidAtID(id, idPrefix) {
    return !idPrefix || (typeof id === "string" && id.startsWith(idPrefix));
}

function applyOperation(target, table, op) {
    const tbl = target[table] || (target[table] = {});
    const keys = op.keys.map(key => typeof key === 'string' ? key : JSON.stringify(key));
    switch (op.type) {
        case "insert":
        // TODO: Don't treat insert and upsert the same?
        case "upsert":
            keys.forEach((key, idx) => {
                tbl[key] = {
                    type: "ups",
                    val: op.values[idx],
                };
            });
            break;
        case "update":
        case "modify": {
            keys.forEach((key, idx) => {
                const changeSpec = op.type === "update"
                    ? op.changeSpecs[idx]
                    : op.changeSpec;
                const entry = tbl[key];
                if (!entry) {
                    tbl[key] = {
                        type: "upd",
                        mod: changeSpec,
                    };
                }
                else {
                    switch (entry.type) {
                        case "ups":
                            // Adjust the existing upsert with additional updates
                            for (const [propPath, value] of Object.entries(changeSpec)) {
                                setByKeyPath(entry.val, propPath, value);
                            }
                            break;
                        case "del":
                            // No action.
                            break;
                        case "upd":
                            // Adjust existing update with additional updates
                            Object.assign(entry.mod, changeSpec); // May work for deep props as well - new keys is added later, right? Does the prop order persist along TSON and all? But it will not be 100% when combined with some server code (seach for "address.city": "Stockholm" comment)
                            break;
                    }
                }
            });
            break;
        }
        case "delete":
            keys.forEach((key) => {
                tbl[key] = {
                    type: "del",
                };
            });
            break;
    }
    return target;
}

function applyOperations(target, ops) {
    for (const { table, muts } of ops) {
        for (const mut of muts) {
            applyOperation(target, table, mut);
        }
    }
}

function subtractChanges(target, // Server change set
changesToSubtract // additional mutations on client during syncWithServer()
) {
    for (const [table, mutationSet] of Object.entries(changesToSubtract)) {
        for (const [key, mut] of Object.entries(mutationSet)) {
            switch (mut.type) {
                case 'ups':
                    {
                        const targetMut = target[table]?.[key];
                        if (targetMut) {
                            switch (targetMut.type) {
                                case 'ups':
                                    delete target[table][key];
                                    break;
                                case 'del':
                                    // Leave delete operation.
                                    // (Don't resurrect objects unintenionally (using tx(get, put) pattern locally))
                                    break;
                                case 'upd':
                                    delete target[table][key];
                                    break;
                            }
                        }
                    }
                    break;
                case 'del':
                    delete target[table]?.[key];
                    break;
                case 'upd': {
                    const targetMut = target[table]?.[key];
                    if (targetMut) {
                        switch (targetMut.type) {
                            case 'ups':
                                // Adjust the server upsert with locally updated values.
                                for (const [propPath, value] of Object.entries(mut.mod)) {
                                    setByKeyPath(targetMut.val, propPath, value);
                                }
                                break;
                            case 'del':
                                // Leave delete.
                                break;
                            case 'upd':
                                // Remove the local update props from the server update mutation.
                                for (const propPath of Object.keys(mut.mod)) {
                                    delete targetMut.mod[propPath];
                                }
                                break;
                        }
                    }
                    break;
                }
            }
        }
    }
}

/** Convert a DBKeyMutationSet (which is an internal format capable of looking up changes per ID)
 * ...into a DBOperationsSet (which is more optimal for performing DB operations into DB (bulkAdd() etc))
 *
 * @param inSet
 * @returns DBOperationsSet representing inSet
 */
function toDBOperationSet(inSet, txid) {
    // Convert data into a temporary map to collect mutations of same table and type
    const map = {};
    for (const [table, ops] of Object.entries(inSet)) {
        for (const [key, op] of Object.entries(ops)) {
            const mapEntry = map[table] || (map[table] = {});
            const ops = mapEntry[op.type] || (mapEntry[op.type] = []);
            ops.push({ key, ...op }); // DBKeyMutation doesn't contain key, so we need to bring it in.
        }
    }
    // Start computing the resulting format:
    const result = [];
    for (const [table, ops] of Object.entries(map)) {
        const resultEntry = {
            table,
            muts: [],
        };
        for (const [optype, muts] of Object.entries(ops)) {
            switch (optype) {
                case "ups": {
                    const op = {
                        type: "upsert",
                        keys: muts.map(mut => mut.key),
                        values: muts.map(mut => mut.val),
                        txid
                    };
                    resultEntry.muts.push(op);
                    break;
                }
                case "upd": {
                    const op = {
                        type: "update",
                        keys: muts.map(mut => mut.key),
                        changeSpecs: muts.map(mut => mut.mod),
                        txid
                    };
                    resultEntry.muts.push(op);
                    break;
                }
                case "del": {
                    const op = {
                        type: "delete",
                        keys: muts.map(mut => mut.key),
                        txid,
                    };
                    resultEntry.muts.push(op);
                    break;
                }
            }
        }
        result.push(resultEntry);
    }
    return result;
}

function getDbNameFromDbUrl(dbUrl) {
    const url = new URL(dbUrl);
    return url.pathname === "/"
        ? url.hostname.split('.')[0]
        : url.pathname.split('/')[1];
}

function encodeYMessage(msg) {
    const encoder = new Encoder();
    writeVarString(encoder, msg.type);
    if ('table' in msg)
        writeVarString(encoder, msg.table);
    if ('prop' in msg)
        writeVarString(encoder, msg.prop);
    switch (msg.type) {
        case 'u-ack':
        case 'u-reject':
            writeBigUint64(encoder, BigInt(msg.i));
            break;
        case 'outdated-server-rev':
            break;
        case 'y-complete-sync-done':
            writeVarString(encoder, msg.yServerRev);
            break;
        default:
            writeAny(encoder, msg.k);
            switch (msg.type) {
                case 'aware':
                    writeVarUint8Array(encoder, msg.u);
                    break;
                case 'doc-open':
                    writeAny(encoder, msg.serverRev);
                    writeAny(encoder, msg.sv);
                    break;
                case 'doc-close':
                    break;
                case 'sv':
                    writeVarUint8Array(encoder, msg.sv);
                    break;
                case 'u-c':
                    writeVarUint8Array(encoder, msg.u);
                    writeBigUint64(encoder, BigInt(msg.i));
                    break;
                case 'u-s':
                    writeVarUint8Array(encoder, msg.u);
                    writeVarString(encoder, msg.r || '');
                    break;
            }
    }
    return toUint8Array(encoder);
}

function decodeYMessage(a) {
    const decoder = new Decoder(a);
    const type = readVarString(decoder);
    if (type === 'outdated-server-rev') {
        return { type };
    }
    if (type === 'y-complete-sync-done') {
        return { type, yServerRev: readVarString(decoder) };
    }
    const table = readVarString(decoder);
    const prop = readVarString(decoder);
    switch (type) {
        case 'u-ack':
        case 'u-reject':
            return {
                type,
                table,
                prop,
                i: Number(readBigUint64(decoder)),
            };
        default: {
            const k = readAny(decoder);
            switch (type) {
                case 'in-sync':
                    return { type, table, prop, k };
                case 'aware':
                    return {
                        type,
                        table,
                        prop,
                        k,
                        u: readVarUint8Array(decoder),
                    };
                case 'doc-open':
                    return {
                        type,
                        table,
                        prop,
                        k,
                        serverRev: readAny(decoder),
                        sv: readAny(decoder),
                    };
                case 'doc-close':
                    return { type, table, prop, k };
                case 'sv':
                    return {
                        type,
                        table,
                        prop,
                        k,
                        sv: readVarUint8Array(decoder),
                    };
                case 'u-c':
                    return {
                        type,
                        table,
                        prop,
                        k,
                        u: readVarUint8Array(decoder),
                        i: Number(readBigUint64(decoder)),
                    };
                case 'u-s':
                    return {
                        type,
                        table,
                        prop,
                        k,
                        u: readVarUint8Array(decoder),
                        r: (decoder.pos < decoder.arr.length && readVarString(decoder)) || undefined,
                    };
                default:
                    throw new TypeError(`Unknown message type: ${type}`);
            }
        }
    }
}

async function asyncIterablePipeline(source, ...stages) {
    // Chain generators by sending outdata from one to another
    let result = source(); // Start with the source generator
    for (let i = 0; i < stages.length; i++) {
        result = stages[i](result); // Pass on the result to next generator
    }
    // Start running the machine. If the last stage is a sink, it will consume the data and never emit anything
    // to us here...
    for await (const chunk of result) { }
}

async function* consumeChunkedBinaryStream(source) {
    let state = 0;
    let sizeBuf = new Uint8Array(4);
    let sizeBufPos = 0;
    let bufs = [];
    let len = 0;
    for await (const chunk of source) {
        const dw = new DataView(chunk.buffer, chunk.byteOffset, chunk.byteLength);
        let pos = 0;
        while (pos < chunk.byteLength) {
            switch (state) {
                case 0:
                    // Beginning of a size header
                    if (pos + 4 > chunk.byteLength) {
                        for (const b of chunk.slice(pos)) {
                            if (sizeBufPos === 4)
                                break;
                            sizeBuf[sizeBufPos++] = b;
                            ++pos;
                        }
                        if (sizeBufPos < 4) {
                            // Need more bytes in order to read length.
                            // Will go out from while loop as well because pos is defenitely = chunk.byteLength here.
                            break;
                        }
                    }
                    else if (sizeBufPos > 0 && sizeBufPos < 4) {
                        for (const b of chunk.slice(pos, pos + 4 - sizeBufPos)) {
                            sizeBuf[sizeBufPos++] = b;
                            ++pos;
                        }
                    }
                // Intentional fall-through...
                case 1:
                    len =
                        sizeBufPos === 4
                            ? new DataView(sizeBuf.buffer, 0, 4).getUint32(0, false)
                            : dw.getUint32(pos, false);
                    if (sizeBufPos)
                        sizeBufPos = 0; // in this case pos is already forwarded
                    else
                        pos += 4; // else pos is not yet forwarded - that's why we do it now
                // Intentional fall-through...
                case 2:
                    // Eat the chunk
                    if (pos >= chunk.byteLength) {
                        state = 2;
                        break;
                    }
                    if (pos + len > chunk.byteLength) {
                        bufs.push(chunk.slice(pos));
                        len -= (chunk.byteLength - pos);
                        state = 2;
                        pos = chunk.byteLength; // will break while loop.
                    }
                    else {
                        if (bufs.length > 0) {
                            const concats = new Uint8Array(bufs.reduce((p, c) => p + c.byteLength, len));
                            let p = 0;
                            for (const buf of bufs) {
                                concats.set(buf, p);
                                p += buf.byteLength;
                            }
                            concats.set(chunk.slice(pos, pos + len), p);
                            bufs = [];
                            yield concats;
                        }
                        else {
                            yield chunk.slice(pos, pos + len);
                        }
                        pos += len;
                        state = 0;
                    }
                    break;
            }
        }
    }
}

function getFetchResponseBodyGenerator(res) {
    return async function* () {
        if (!res.body)
            throw new Error("Response body is not readable");
        const reader = res.body.getReader();
        try {
            while (true) {
                const { done, value } = await reader.read();
                if (done)
                    return;
                yield value;
            }
        }
        finally {
            reader.releaseLock();
        }
    };
}

function listSyncifiedChanges(tablesToSyncify, currentUser, schema, alreadySyncedRealms) {
    return __awaiter(this, void 0, void 0, function* () {
        const txid = `upload-${randomString$1(8)}`;
        if (currentUser.isLoggedIn) {
            if (tablesToSyncify.length > 0) {
                const ignoredRealms = new Set(alreadySyncedRealms || []);
                const upserts = yield Promise.all(tablesToSyncify.map((table) => __awaiter(this, void 0, void 0, function* () {
                    const { extractKey } = table.core.schema.primaryKey;
                    if (!extractKey)
                        return { table: table.name, muts: [] }; // Outbound tables are not synced.
                    const dexieCloudTableSchema = schema[table.name];
                    const query = (dexieCloudTableSchema === null || dexieCloudTableSchema === void 0 ? void 0 : dexieCloudTableSchema.generatedGlobalId)
                        ? table.filter((item) => {
                            extractKey(item);
                            return (!ignoredRealms.has(item.realmId || '') &&
                                //(id[0] !== '#' || !!item.$ts) && // Private obj need no sync if not changed
                                isValidAtID(extractKey(item), dexieCloudTableSchema === null || dexieCloudTableSchema === void 0 ? void 0 : dexieCloudTableSchema.idPrefix));
                        })
                        : table.filter((item) => {
                            const id = extractKey(item);
                            return (!ignoredRealms.has(item.realmId || '') &&
                                //(id[0] !== '#' || !!item.$ts) && // Private obj need no sync if not changed
                                isValidSyncableID(id));
                        });
                    const unsyncedObjects = yield query.toArray();
                    if (unsyncedObjects.length > 0) {
                        const mut = {
                            type: 'upsert',
                            values: unsyncedObjects,
                            keys: unsyncedObjects.map(extractKey),
                            userId: currentUser.userId,
                            txid,
                        };
                        return {
                            table: table.name,
                            muts: [mut],
                        };
                    }
                    else {
                        return {
                            table: table.name,
                            muts: [],
                        };
                    }
                })));
                return upserts.filter((op) => op.muts.length > 0);
            }
        }
        return [];
    });
}

function getTablesToSyncify(db, syncState) {
    const syncedTables = (syncState === null || syncState === void 0 ? void 0 : syncState.syncedTables) || [];
    const syncableTables = getSyncableTables(db);
    const tablesToSyncify = syncableTables.filter((tbl) => !syncedTables.includes(tbl.name));
    return tablesToSyncify;
}

class TokenErrorResponseError extends Error {
    constructor({ title, message, messageCode, messageParams, }) {
        super(message);
        this.name = 'TokenErrorResponseError';
        this.title = title;
        this.messageCode = messageCode;
        this.messageParams = messageParams;
    }
}

function interactWithUser(userInteraction, req) {
    return new Promise((resolve, reject) => {
        const interactionProps = Object.assign(Object.assign({ submitLabel: 'Submit', cancelLabel: 'Cancel' }, req), { onSubmit: (res) => {
                userInteraction.next(undefined);
                resolve(res);
            }, onCancel: () => {
                userInteraction.next(undefined);
                reject(new Dexie.AbortError('User cancelled'));
            } });
        userInteraction.next(interactionProps);
        // Start subscribing for external updates to db.cloud.userInteraction, and if so, cancel this request.
        /*const subscription = userInteraction.subscribe((currentInteractionProps) => {
          if (currentInteractionProps !== interactionProps) {
            if (subscription) subscription.unsubscribe();
            if (!done) {
              reject(new Dexie.AbortError("User cancelled"));
            }
          }
        });*/
    });
}
function alertUser(userInteraction, title, ...alerts) {
    return interactWithUser(userInteraction, {
        type: 'message-alert',
        title,
        alerts,
        fields: {},
        submitLabel: 'OK',
        cancelLabel: null,
    });
}
function promptForEmail(userInteraction, title, emailHint) {
    return __awaiter(this, void 0, void 0, function* () {
        let email = emailHint || '';
        // Regular expression for email validation
        // ^[\w-+.]+@([\w-]+\.)+[\w-]{2,10}(\sas\s[\w-+.]+@([\w-]+\.)+[\w-]{2,10})?$
        //
        // ^[\w-+.]+ : Matches the start of the string. Allows one or more word characters
        // (a-z, A-Z, 0-9, and underscore), hyphen, plus, or dot.
        //
        // @ : Matches the @ symbol.
        // ([\w-]+\.)+ : Matches one or more word characters or hyphens followed by a dot.
        //   The plus sign outside the parentheses means this pattern can repeat one or more times,
        //   allowing for subdomains.
        // [\w-]{2,10} : Matches between 2 and 10 word characters or hyphens. This is typically for
        //   the domain extension like .com, .net, etc.
        // (\sas\s[\w-+.]+@([\w-]+\.)+[\w-]{2,10})?$ : This part is optional (due to the ? at the end).
        //   If present, it matches " as " followed by another valid email address. This allows for the
        //   input to be either a single email address or two email addresses separated by " as ". 
        //
        // The use case for "<email1> as <email2>"" is for when a database owner with full access to the
        // database needs to impersonate another user in the database in order to troubleshoot. This
        // format will only be possible to use when email1 is the owner of an API client with GLOBAL_READ
        // and GLOBAL_WRITE permissions on the database. The email will be checked on the server before
        // allowing it and giving out a token for email2, using the OTP sent to email1.
        while (!email || !/^[\w-+.]+@([\w-]+\.)+[\w-]{2,10}(\sas\s[\w-+.]+@([\w-]+\.)+[\w-]{2,10})?$/.test(email)) {
            email = (yield interactWithUser(userInteraction, {
                type: 'email',
                title,
                alerts: email
                    ? [
                        {
                            type: 'error',
                            messageCode: 'INVALID_EMAIL',
                            message: 'Please enter a valid email address',
                            messageParams: {},
                        },
                    ]
                    : [],
                fields: {
                    email: {
                        type: 'email',
                        placeholder: 'you@somedomain.com',
                    },
                },
            })).email;
        }
        return email;
    });
}
function promptForOTP(userInteraction, email, alert) {
    return __awaiter(this, void 0, void 0, function* () {
        const alerts = [
            {
                type: 'info',
                messageCode: 'OTP_SENT',
                message: `A One-Time password has been sent to {email}`,
                messageParams: { email },
            },
        ];
        if (alert) {
            alerts.push(alert);
        }
        const { otp } = yield interactWithUser(userInteraction, {
            type: 'otp',
            title: 'Enter OTP',
            alerts,
            fields: {
                otp: {
                    type: 'otp',
                    label: 'OTP',
                    placeholder: 'Paste OTP here',
                },
            },
        });
        return otp;
    });
}
function confirmLogout(userInteraction, currentUserId, numUnsyncedChanges) {
    return __awaiter(this, void 0, void 0, function* () {
        const alerts = [
            {
                type: 'warning',
                messageCode: 'LOGOUT_CONFIRMATION',
                message: `{numUnsyncedChanges} unsynced changes will get lost!
                Logout anyway?`,
                messageParams: {
                    currentUserId,
                    numUnsyncedChanges: numUnsyncedChanges.toString(),
                }
            },
        ];
        return yield interactWithUser(userInteraction, {
            type: 'logout-confirmation',
            title: 'Confirm Logout',
            alerts,
            fields: {},
            submitLabel: 'Confirm logout',
            cancelLabel: 'Cancel'
        })
            .then(() => true)
            .catch(() => false);
    });
}

function loadAccessToken(db) {
    return __awaiter(this, void 0, void 0, function* () {
        var _a, _b, _c;
        const currentUser = yield db.getCurrentUser();
        const { accessToken, accessTokenExpiration, refreshToken, refreshTokenExpiration, claims, } = currentUser;
        if (!accessToken)
            return null;
        const expTime = (_a = accessTokenExpiration === null || accessTokenExpiration === void 0 ? void 0 : accessTokenExpiration.getTime()) !== null && _a !== void 0 ? _a : Infinity;
        if (expTime > Date.now() && (((_b = currentUser.license) === null || _b === void 0 ? void 0 : _b.status) || 'ok') === 'ok') {
            return currentUser;
        }
        if (!refreshToken) {
            throw new Error(`Refresh token missing`);
        }
        const refreshExpTime = (_c = refreshTokenExpiration === null || refreshTokenExpiration === void 0 ? void 0 : refreshTokenExpiration.getTime()) !== null && _c !== void 0 ? _c : Infinity;
        if (refreshExpTime <= Date.now()) {
            throw new Error(`Refresh token has expired`);
        }
        const refreshedLogin = yield refreshAccessToken(db.cloud.options.databaseUrl, currentUser);
        yield db.table('$logins').update(claims.sub, {
            accessToken: refreshedLogin.accessToken,
            accessTokenExpiration: refreshedLogin.accessTokenExpiration,
            claims: refreshedLogin.claims,
            license: refreshedLogin.license,
            data: refreshedLogin.data,
        });
        return refreshedLogin;
    });
}
function authenticate(url, context, fetchToken, userInteraction, hints) {
    return __awaiter(this, void 0, void 0, function* () {
        if (context.accessToken &&
            context.accessTokenExpiration.getTime() > Date.now()) {
            return context;
        }
        else if (context.refreshToken &&
            (!context.refreshTokenExpiration ||
                context.refreshTokenExpiration.getTime() > Date.now())) {
            return yield refreshAccessToken(url, context);
        }
        else {
            return yield userAuthenticate(context, fetchToken, userInteraction, hints);
        }
    });
}
function refreshAccessToken(url, login) {
    return __awaiter(this, void 0, void 0, function* () {
        if (!login.refreshToken)
            throw new Error(`Cannot refresh token - refresh token is missing.`);
        if (!login.nonExportablePrivateKey)
            throw new Error(`login.nonExportablePrivateKey is missing - cannot sign refresh token without a private key.`);
        const time_stamp = Date.now();
        const signing_algorithm = 'RSASSA-PKCS1-v1_5';
        const textEncoder = new TextEncoder();
        const data = textEncoder.encode(login.refreshToken + time_stamp);
        const binarySignature = yield crypto.subtle.sign(signing_algorithm, login.nonExportablePrivateKey, data);
        const signature = b64encode(binarySignature);
        const tokenRequest = {
            grant_type: 'refresh_token',
            refresh_token: login.refreshToken,
            scopes: ['ACCESS_DB'],
            signature,
            signing_algorithm,
            time_stamp,
        };
        const res = yield fetch(`${url}/token`, {
            body: JSON.stringify(tokenRequest),
            method: 'post',
            headers: { 'Content-Type': 'application/json' },
            mode: 'cors',
        });
        if (res.status !== 200)
            throw new Error(`RefreshToken: Status ${res.status} from ${url}/token`);
        const response = yield res.json();
        if (response.type === 'error') {
            throw new TokenErrorResponseError(response);
        }
        login.accessToken = response.accessToken;
        login.accessTokenExpiration = response.accessTokenExpiration
            ? new Date(response.accessTokenExpiration)
            : undefined;
        login.claims = response.claims;
        login.license = {
            type: response.userType,
            status: response.claims.license || 'ok',
        };
        if (response.evalDaysLeft != null) {
            login.license.evalDaysLeft = response.evalDaysLeft;
        }
        if (response.userValidUntil != null) {
            login.license.validUntil = new Date(response.userValidUntil);
        }
        if (response.data) {
            login.data = response.data;
        }
        return login;
    });
}
function userAuthenticate(context, fetchToken, userInteraction, hints) {
    return __awaiter(this, void 0, void 0, function* () {
        if (!crypto.subtle) {
            if (typeof location !== 'undefined' && location.protocol === 'http:') {
                throw new Error(`Dexie Cloud Addon needs to use WebCrypto, but your browser has disabled it due to being served from an insecure location. Please serve it from https or http://localhost:<port> (See https://stackoverflow.com/questions/46670556/how-to-enable-crypto-subtle-for-unsecure-origins-in-chrome/46671627#46671627)`);
            }
            else {
                throw new Error(`This browser does not support WebCrypto.`);
            }
        }
        const { privateKey, publicKey } = yield crypto.subtle.generateKey({
            name: 'RSASSA-PKCS1-v1_5',
            modulusLength: 2048,
            publicExponent: new Uint8Array([0x01, 0x00, 0x01]),
            hash: { name: 'SHA-256' },
        }, false, // Non-exportable...
        ['sign', 'verify']);
        if (!privateKey || !publicKey)
            throw new Error(`Could not generate RSA keypair`); // Typings suggest these can be undefined...
        context.nonExportablePrivateKey = privateKey; //...but storable!
        const publicKeySPKI = yield crypto.subtle.exportKey('spki', publicKey);
        const publicKeyPEM = spkiToPEM(publicKeySPKI);
        context.publicKey = publicKey;
        try {
            const response2 = yield fetchToken({
                public_key: publicKeyPEM,
                hints,
            });
            if (response2.type === 'error') {
                throw new TokenErrorResponseError(response2);
            }
            if (response2.type !== 'tokens')
                throw new Error(`Unexpected response type from token endpoint: ${response2.type}`);
            /*const licenseStatus = response2.claims.license ||'ok';
            if (licenseStatus !== 'ok') {
              throw new InvalidLicenseError(licenseStatus);
            }*/
            context.accessToken = response2.accessToken;
            context.accessTokenExpiration = new Date(response2.accessTokenExpiration);
            context.refreshToken = response2.refreshToken;
            if (response2.refreshTokenExpiration) {
                context.refreshTokenExpiration = new Date(response2.refreshTokenExpiration);
            }
            context.userId = response2.claims.sub;
            context.email = response2.claims.email;
            context.name = response2.claims.name;
            context.claims = response2.claims;
            context.license = {
                type: response2.userType,
                status: response2.claims.license || 'ok',
            };
            context.data = response2.data;
            if (response2.evalDaysLeft != null) {
                context.license.evalDaysLeft = response2.evalDaysLeft;
            }
            if (response2.userValidUntil != null) {
                context.license.validUntil = new Date(response2.userValidUntil);
            }
            if (response2.alerts && response2.alerts.length > 0) {
                yield interactWithUser(userInteraction, {
                    type: 'message-alert',
                    title: 'Authentication Alert',
                    fields: {},
                    alerts: response2.alerts,
                });
            }
            return context;
        }
        catch (error) {
            if (error instanceof TokenErrorResponseError) {
                yield alertUser(userInteraction, error.title, {
                    type: 'error',
                    messageCode: error.messageCode,
                    message: error.message,
                    messageParams: {},
                });
                throw error;
            }
            let message = `We're having a problem authenticating right now.`;
            console.error(`Error authenticating`, error);
            if (error instanceof TypeError) {
                const isOffline = typeof navigator !== undefined && !navigator.onLine;
                if (isOffline) {
                    message = `You seem to be offline. Please connect to the internet and try again.`;
                }
                else if (Dexie.debug || (typeof location !== 'undefined' && (location.hostname === 'localhost' || location.hostname === '127.0.0.1'))) {
                    // The audience is most likely the developer. Suggest to whitelist the localhost origin:
                    message = `Could not connect to server. Please verify that your origin '${location.origin}' is whitelisted using \`npx dexie-cloud whitelist\``;
                }
                else {
                    message = `Could not connect to server. Please verify the connection.`;
                }
                yield alertUser(userInteraction, 'Authentication Failed', {
                    type: 'error',
                    messageCode: 'GENERIC_ERROR',
                    message,
                    messageParams: {},
                }).catch(() => { });
            }
            throw error;
        }
    });
}
function spkiToPEM(keydata) {
    const keydataB64 = b64encode(keydata);
    const keydataB64Pem = formatAsPem(keydataB64);
    return keydataB64Pem;
}
function formatAsPem(str) {
    let finalString = '-----BEGIN PUBLIC KEY-----\n';
    while (str.length > 0) {
        finalString += str.substring(0, 64) + '\n';
        str = str.substring(64);
    }
    finalString = finalString + '-----END PUBLIC KEY-----';
    return finalString;
}

const { toString: toStr } = {};
function getToStringTag(val) {
    return toStr.call(val).slice(8, -1);
}
function escapeDollarProps(value) {
    const keys = Object.keys(value);
    let dollarKeys = null;
    for (let i = 0, l = keys.length; i < l; ++i) {
        if (keys[i][0] === "$") {
            dollarKeys = dollarKeys || [];
            dollarKeys.push(keys[i]);
        }
    }
    if (!dollarKeys)
        return value;
    const clone = { ...value };
    for (const k of dollarKeys) {
        delete clone[k];
    }
    for (const k of dollarKeys) {
        clone["$" + k] = value[k];
    }
    return clone;
}
const ObjectDef = {
    replace: escapeDollarProps,
};
function TypesonSimplified(...typeDefsInputs) {
    const typeDefs = typeDefsInputs.reduce((p, c) => ({ ...p, ...c }), typeDefsInputs.reduce((p, c) => ({ ...c, ...p }), {}));
    const protoMap = new WeakMap();
    return {
        stringify(value, alternateChannel, space) {
            const json = JSON.stringify(value, function (key) {
                const realVal = this[key];
                const typeDef = getTypeDef(realVal);
                return typeDef
                    ? typeDef.replace(realVal, alternateChannel, typeDefs)
                    : realVal;
            }, space);
            return json;
        },
        parse(tson, alternateChannel) {
            const stack = [];
            return JSON.parse(tson, function (key, value) {
                //
                // Parent Part
                //
                const type = value === null || value === void 0 ? void 0 : value.$t;
                if (type) {
                    const typeDef = typeDefs[type];
                    value = typeDef
                        ? typeDef.revive(value, alternateChannel, typeDefs)
                        : value;
                }
                let top = stack[stack.length - 1];
                if (top && top[0] === value) {
                    // Do what the kid told us to
                    // Unescape dollar props
                    value = { ...value };
                    // Delete keys that children wanted us to delete
                    for (const k of top[1])
                        delete value[k];
                    // Set keys that children wanted us to set
                    for (const [k, v] of Object.entries(top[2])) {
                        value[k] = v;
                    }
                    stack.pop();
                }
                //
                // Child part
                //
                if (value === undefined || (key[0] === "$" && key !== "$t")) {
                    top = stack[stack.length - 1];
                    let deletes;
                    let mods;
                    if (top && top[0] === this) {
                        deletes = top[1];
                        mods = top[2];
                    }
                    else {
                        stack.push([this, (deletes = []), (mods = {})]);
                    }
                    if (key[0] === "$" && key !== "$t") {
                        // Unescape props (also preserves undefined if this is a combo)
                        deletes.push(key);
                        mods[key.substr(1)] = value;
                    }
                    else {
                        // Preserve undefined
                        mods[key] = undefined;
                    }
                }
                return value;
            });
        },
    };
    function getTypeDef(realVal) {
        const type = typeof realVal;
        switch (typeof realVal) {
            case "object":
            case "function": {
                // "object", "function", null
                if (realVal === null)
                    return null;
                const proto = Object.getPrototypeOf(realVal);
                if (!proto)
                    return ObjectDef;
                let typeDef = protoMap.get(proto);
                if (typeDef !== undefined)
                    return typeDef; // Null counts to! So the caching of Array.prototype also counts.
                const toStringTag = getToStringTag(realVal);
                const entry = Object.entries(typeDefs).find(([typeName, typeDef]) => { var _a, _b; return (_b = (_a = typeDef === null || typeDef === void 0 ? void 0 : typeDef.test) === null || _a === void 0 ? void 0 : _a.call(typeDef, realVal, toStringTag)) !== null && _b !== void 0 ? _b : typeName === toStringTag; });
                typeDef = entry === null || entry === void 0 ? void 0 : entry[1];
                if (!typeDef) {
                    typeDef = Array.isArray(realVal)
                        ? null
                        : typeof realVal === "function"
                            ? typeDefs.function || null
                            : ObjectDef;
                }
                protoMap.set(proto, typeDef);
                return typeDef;
            }
            default:
                return typeDefs[type];
        }
    }
}

const BisonBinaryTypes = {
    Blob: {
        test: (blob, toStringTag) => toStringTag === "Blob",
        replace: (blob, altChannel) => {
            const i = altChannel.length;
            altChannel.push(blob);
            return {
                $t: "Blob",
                mimeType: blob.type,
                i,
            };
        },
        revive: ({ i, mimeType }, altChannel) => new Blob([altChannel[i]], { type: mimeType }),
    },
};

var numberDef = {
    number: {
        replace: (num) => {
            switch (true) {
                case isNaN(num):
                    return { $t: "number", v: "NaN" };
                case num === Infinity:
                    return { $t: "number", v: "Infinity" };
                case num === -Infinity:
                    return { $t: "number", v: "-Infinity" };
                default:
                    return num;
            }
        },
        revive: ({ v }) => Number(v),
    },
};

const bigIntDef$1 = {
    bigint: {
        replace: (realVal) => {
            return { $t: "bigint", v: "" + realVal };
        },
        revive: (obj) => BigInt(obj.v),
    },
};

var DateDef = {
    Date: {
        replace: (date) => ({
            $t: "Date",
            v: isNaN(date.getTime()) ? "NaN" : date.toISOString(),
        }),
        revive: ({ v }) => new Date(v === "NaN" ? NaN : Date.parse(v)),
    },
};

var SetDef = {
    Set: {
        replace: (set) => ({
            $t: "Set",
            v: Array.from(set.entries()),
        }),
        revive: ({ v }) => new Set(v),
    },
};

var MapDef = {
    Map: {
        replace: (map) => ({
            $t: "Map",
            v: Array.from(map.entries()),
        }),
        revive: ({ v }) => new Map(v),
    },
};

const _global = typeof globalThis !== "undefined" // All modern environments (node, bun, deno, browser, workers, webview etc)
    ? globalThis
    : typeof self !== "undefined" // Older browsers, workers, webview, window etc
        ? self
        : typeof global !== "undefined" // Older versions of node
            ? global
            : undefined; // Unsupported environment. No idea to return 'this' since we are in a module or a function scope anyway.

var TypedArraysDefs = [
    "Int8Array",
    "Uint8Array",
    "Uint8ClampedArray",
    "Int16Array",
    "Uint16Array",
    "Int32Array",
    "Uint32Array",
    "Float32Array",
    "Float64Array",
    "DataView",
    "BigInt64Array",
    "BigUint64Array",
].reduce((specs, typeName) => ({
    ...specs,
    [typeName]: {
        // Replace passes the the typed array into $t, buffer so that
        // the ArrayBuffer typedef takes care of further handling of the buffer:
        // {$t:"Uint8Array",buffer:{$t:"ArrayBuffer",idx:0}}
        // CHANGED ABOVE! Now shortcutting that for more sparse format of the typed arrays
        // to contain the b64 property directly.
        replace: (a, _, typeDefs) => {
            const result = {
                $t: typeName,
                v: typeDefs.ArrayBuffer.replace(a.byteOffset === 0 && a.byteLength === a.buffer.byteLength
                    ? a.buffer
                    : a.buffer.slice(a.byteOffset, a.byteOffset + a.byteLength), _, typeDefs).v,
            };
            return result;
        },
        revive: ({ v }, _, typeDefs) => {
            const TypedArray = _global[typeName];
            return (TypedArray &&
                new TypedArray(typeDefs.ArrayBuffer.revive({ v }, _, typeDefs)));
        },
    },
}), {});

function b64LexEncode(b) {
    return b64ToLex(b64encode(b));
}
function b64LexDecode(b64Lex) {
    return b64decode(lexToB64(b64Lex));
}
function b64ToLex(base64) {
    var encoded = "";
    for (var i = 0, length = base64.length; i < length; i++) {
        encoded += ENCODE_TABLE[base64[i]];
    }
    return encoded;
}
function lexToB64(base64lex) {
    // only accept string input
    if (typeof base64lex !== "string") {
        throw new Error("invalid decoder input: " + base64lex);
    }
    var base64 = "";
    for (var i = 0, length = base64lex.length; i < length; i++) {
        base64 += DECODE_TABLE[base64lex[i]];
    }
    return base64;
}
const DECODE_TABLE = {
    "-": "=",
    "0": "A",
    "1": "B",
    "2": "C",
    "3": "D",
    "4": "E",
    "5": "F",
    "6": "G",
    "7": "H",
    "8": "I",
    "9": "J",
    A: "K",
    B: "L",
    C: "M",
    D: "N",
    E: "O",
    F: "P",
    G: "Q",
    H: "R",
    I: "S",
    J: "T",
    K: "U",
    L: "V",
    M: "W",
    N: "X",
    O: "Y",
    P: "Z",
    Q: "a",
    R: "b",
    S: "c",
    T: "d",
    U: "e",
    V: "f",
    W: "g",
    X: "h",
    Y: "i",
    Z: "j",
    _: "k",
    a: "l",
    b: "m",
    c: "n",
    d: "o",
    e: "p",
    f: "q",
    g: "r",
    h: "s",
    i: "t",
    j: "u",
    k: "v",
    l: "w",
    m: "x",
    n: "y",
    o: "z",
    p: "0",
    q: "1",
    r: "2",
    s: "3",
    t: "4",
    u: "5",
    v: "6",
    w: "7",
    x: "8",
    y: "9",
    z: "+",
    "|": "/",
};
const ENCODE_TABLE = {};
for (const c of Object.keys(DECODE_TABLE)) {
    ENCODE_TABLE[DECODE_TABLE[c]] = c;
}

var ArrayBufferDef = {
    ArrayBuffer: {
        replace: (ab) => ({
            $t: "ArrayBuffer",
            v: b64LexEncode(ab),
        }),
        revive: ({ v }) => {
            const ba = b64LexDecode(v);
            return ba.buffer.byteLength === ba.byteLength
                ? ba.buffer
                : ba.buffer.slice(ba.byteOffset, ba.byteOffset + ba.byteLength);
        },
    },
};

class FakeBlob {
    constructor(buf, type) {
        this.buf = buf;
        this.type = type;
    }
}

function readBlobSync(b) {
    const req = new XMLHttpRequest();
    req.overrideMimeType("text/plain; charset=x-user-defined");
    req.open("GET", URL.createObjectURL(b), false); // Sync
    req.send();
    if (req.status !== 200 && req.status !== 0) {
        throw new Error("Bad Blob access: " + req.status);
    }
    return req.responseText;
}

function string2ArrayBuffer(str) {
    const array = new Uint8Array(str.length);
    for (let i = 0; i < str.length; ++i) {
        array[i] = str.charCodeAt(i); // & 0xff;
    }
    return array.buffer;
}

var BlobDef = {
    Blob: {
        test: (blob, toStringTag) => toStringTag === "Blob" || blob instanceof FakeBlob,
        replace: (blob) => ({
            $t: "Blob",
            v: blob instanceof FakeBlob
                ? b64encode(blob.buf)
                : b64encode(string2ArrayBuffer(readBlobSync(blob))),
            type: blob.type,
        }),
        revive: ({ type, v }) => {
            const ab = b64decode(v);
            return typeof Blob !== undefined
                ? new Blob([ab])
                : new FakeBlob(ab.buffer, type);
        },
    },
};

const builtin = {
    ...numberDef,
    ...bigIntDef$1,
    ...DateDef,
    ...SetDef,
    ...MapDef,
    ...TypedArraysDefs,
    ...ArrayBufferDef,
    ...BlobDef, // Should be moved to another preset for DOM types (or universal? since it supports node as well with FakeBlob)
};

function Bison(...typeDefsInputs) {
    const tson = TypesonSimplified(builtin, BisonBinaryTypes, ...typeDefsInputs);
    return {
        toBinary(value) {
            const [blob, json] = this.stringify(value);
            const lenBuf = new ArrayBuffer(4);
            new DataView(lenBuf).setUint32(0, blob.size);
            return new Blob([lenBuf, blob, json]);
        },
        stringify(value) {
            const binaries = [];
            const json = tson.stringify(value, binaries);
            const blob = new Blob(binaries.map((b) => {
                const lenBuf = new ArrayBuffer(4);
                new DataView(lenBuf).setUint32(0, "byteLength" in b ? b.byteLength : b.size);
                return new Blob([lenBuf, b]);
            }));
            return [blob, json];
        },
        async parse(json, binData) {
            let pos = 0;
            const arrayBuffers = [];
            const buf = await readBlobBinary(binData);
            const view = new DataView(buf);
            while (pos < buf.byteLength) {
                const len = view.getUint32(pos);
                pos += 4;
                const ab = buf.slice(pos, pos + len);
                pos += len;
                arrayBuffers.push(ab);
            }
            return tson.parse(json, arrayBuffers);
        },
        async fromBinary(blob) {
            const len = new DataView(await readBlobBinary(blob.slice(0, 4))).getUint32(0);
            const binData = blob.slice(4, len + 4);
            const json = await readBlob(blob.slice(len + 4));
            return await this.parse(json, binData);
        },
    };
}
function readBlob(blob) {
    return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onabort = (ev) => reject(new Error("file read aborted"));
        reader.onerror = (ev) => reject(ev.target.error);
        reader.onload = (ev) => resolve(ev.target.result);
        reader.readAsText(blob);
    });
}
function readBlobBinary(blob) {
    return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onabort = (ev) => reject(new Error("file read aborted"));
        reader.onerror = (ev) => reject(ev.target.error);
        reader.onload = (ev) => resolve(ev.target.result);
        reader.readAsArrayBuffer(blob);
    });
}

/** The undefined type is not part of builtin but can be manually added.
 * The reason for supporting undefined is if the following object should be revived correctly:
 *
 *    {foo: undefined}
 *
 * Without including this typedef, the revived object would just be {}.
 * If including this typedef, the revived object would be {foo: undefined}.
 */
var undefinedDef = {
    undefined: {
        replace: () => ({
            $t: "undefined"
        }),
        revive: () => undefined,
    },
};

var FileDef = {
    File: {
        test: (file, toStringTag) => toStringTag === "File",
        replace: (file) => ({
            $t: "File",
            v: b64encode(string2ArrayBuffer(readBlobSync(file))),
            type: file.type,
            name: file.name,
            lastModified: new Date(file.lastModified).toISOString(),
        }),
        revive: ({ type, v, name, lastModified }) => {
            const ab = b64decode(v);
            return new File([ab], name, {
                type,
                lastModified: new Date(lastModified).getTime(),
            });
        },
    },
};

// Since server revisions are stored in bigints, we need to handle clients without
// bigint support to not fail when serverRevision is passed over to client.
// We need to not fail when reviving it and we need to somehow store the information.
// Since the revived version will later on be put into indexedDB we have another
// issue: When reading it back from indexedDB we will get a poco object that we
// cannot replace correctly when sending it to server. So we will also need
// to do an explicit workaround in the protocol where a bigint is supported.
// The workaround should be there regardless if browser supports BigInt or not, because
// the serverRev might have been stored in IDB before the browser was upgraded to support bigint.
//
// if (typeof serverRev.rev !== "bigint")
//   if (hasBigIntSupport)
//     serverRev.rev = bigIntDef.bigint.revive(server.rev)
//   else
//     serverRev.rev = new FakeBigInt(server.rev)
const hasBigIntSupport = typeof BigInt === 'function' && typeof BigInt(0) === 'bigint';
class FakeBigInt {
    toString() {
        return this.v;
    }
    constructor(value) {
        this.v = value;
    }
}
const bigIntDef = hasBigIntSupport
    ? {}
    : {
        bigint: {
            test: (val) => val instanceof FakeBigInt,
            replace: (fakeBigInt) => {
                return Object.assign({ $t: 'bigint' }, fakeBigInt);
            },
            revive: ({ v }) => new FakeBigInt(v),
        },
    };
const defs = Object.assign(Object.assign(Object.assign(Object.assign({}, undefinedDef), bigIntDef), FileDef), { PropModification: {
        test: (val) => val instanceof PropModification,
        replace: (propModification) => {
            return Object.assign({ $t: 'PropModification' }, propModification['@@propmod']);
        },
        revive: (_a) => {
            var { $t } = _a, // strip '$t'
            propModSpec = __rest(_a, ["$t"]) // keep the rest
            ;
            return new PropModification(propModSpec);
        },
    } });
const TSON = TypesonSimplified(builtin, defs);
const BISON = Bison(defs);

class HttpError extends Error {
    constructor(res, message) {
        super(message || `${res.status} ${res.statusText}`);
        this.httpStatus = res.status;
    }
    get name() {
        return "HttpError";
    }
}

function encodeIdsForServer(schema, currentUser, changes) {
    const rv = [];
    for (let change of changes) {
        const { table, muts } = change;
        const tableSchema = schema.tables.find((t) => t.name === table);
        if (!tableSchema)
            throw new Error(`Internal error: table ${table} not found in DBCore schema`);
        const { primaryKey } = tableSchema;
        let changeClone = change;
        muts.forEach((mut, mutIndex) => {
            const rewriteValues = !primaryKey.outbound &&
                (mut.type === 'upsert' || mut.type === 'insert');
            mut.keys.forEach((key, keyIndex) => {
                if (Array.isArray(key)) {
                    // Server only support string keys. Dexie Cloud client support strings or array of strings.
                    if (changeClone === change)
                        changeClone = cloneChange(change, rewriteValues);
                    const mutClone = changeClone.muts[mutIndex];
                    const rewrittenKey = JSON.stringify(key);
                    mutClone.keys[keyIndex] = rewrittenKey;
                    /* Bug (#1777)
                      We should not rewrite values. It will fail because the key is array and the value is string.
                      Only the keys should be rewritten and it's already done on the server.
                      We should take another round of revieweing how key transformations are being done between
                      client and server and let the server do the key transformations entirely instead now that
                      we have the primary key schema on the server making it possible to do so.
                      if (rewriteValues) {
                      Dexie.setByKeyPath(
                        (mutClone as DBInsertOperation).values[keyIndex],
                        primaryKey.keyPath!,
                        rewrittenKey
                      );
                    }*/
                }
                else if (key[0] === '#') {
                    // Private ID - translate!
                    if (changeClone === change)
                        changeClone = cloneChange(change, rewriteValues);
                    const mutClone = changeClone.muts[mutIndex];
                    if (!currentUser.isLoggedIn)
                        throw new Error(`Internal error: Cannot sync private IDs before authenticated`);
                    const rewrittenKey = `${key}:${currentUser.userId}`;
                    mutClone.keys[keyIndex] = rewrittenKey;
                    if (rewriteValues) {
                        Dexie.setByKeyPath(mutClone.values[keyIndex], primaryKey.keyPath, rewrittenKey);
                    }
                }
            });
        });
        rv.push(changeClone);
    }
    return rv;
}
function cloneChange(change, rewriteValues) {
    // clone on demand:
    return Object.assign(Object.assign({}, change), { muts: rewriteValues
            ? change.muts.map((m) => {
                return (m.type === 'insert' || m.type === 'upsert') && m.values
                    ? Object.assign(Object.assign({}, m), { keys: m.keys.slice(), values: m.values.slice() }) : Object.assign(Object.assign({}, m), { keys: m.keys.slice() });
            })
            : change.muts.map((m) => (Object.assign(Object.assign({}, m), { keys: m.keys.slice() }))) });
}

// If we get Ratelimit-Limit and Ratelimit-Remaining where Ratelimit-Remaining is below
// (Ratelimit-Limit / 2), we should delay the next sync by (Ratelimit-Reset / Ratelimit-Remaining)
// seconds (given that there is a Ratelimit-Reset header).
let syncRatelimitDelays = new WeakMap();
function checkSyncRateLimitDelay(db) {
    return __awaiter(this, void 0, void 0, function* () {
        var _a, _b;
        const delatMilliseconds = ((_b = (_a = syncRatelimitDelays.get(db)) === null || _a === void 0 ? void 0 : _a.getTime()) !== null && _b !== void 0 ? _b : 0) - Date.now();
        if (delatMilliseconds > 0) {
            console.debug(`Stalling sync request ${delatMilliseconds} ms to spare ratelimits`);
            yield new Promise(resolve => setTimeout(resolve, delatMilliseconds));
        }
    });
}
function updateSyncRateLimitDelays(db, res) {
    const limit = res.headers.get('Ratelimit-Limit');
    const remaining = res.headers.get('Ratelimit-Remaining');
    const reset = res.headers.get('Ratelimit-Reset');
    if (limit && remaining && reset) {
        const limitNum = Number(limit);
        const remainingNum = Math.max(0, Number(remaining));
        const willResetInSeconds = Number(reset);
        if (remainingNum < limitNum / 2) {
            const delay = Math.ceil(willResetInSeconds / (remainingNum + 1));
            syncRatelimitDelays.set(db, new Date(Date.now() + delay * 1000));
            console.debug(`Sync ratelimit delay set to ${delay} seconds`);
        }
        else {
            syncRatelimitDelays.delete(db);
            console.debug(`Sync ratelimit delay cleared`);
        }
    }
}

//import {BisonWebStreamReader} from "dreambase-library/dist/typeson-simplified/BisonWebStreamReader";
function syncWithServer(changes, y, syncState, baseRevs, db, databaseUrl, schema, clientIdentity, currentUser) {
    return __awaiter(this, void 0, void 0, function* () {
        //
        // Push changes to server using fetch
        //
        const headers = {
            Accept: 'application/json, application/x-bison, application/x-bison-stream',
            'Content-Type': 'application/tson',
        };
        const updatedUser = yield loadAccessToken(db);
        /*
        if (updatedUser?.license && changes.length > 0) {
          if (updatedUser.license.status === 'expired') {
            throw new Error(`License has expired`);
          }
          if (updatedUser.license.status === 'deactivated') {
            throw new Error(`License deactivated`);
          }
        }
        */
        const accessToken = updatedUser === null || updatedUser === void 0 ? void 0 : updatedUser.accessToken;
        if (accessToken) {
            headers.Authorization = `Bearer ${accessToken}`;
        }
        const syncRequest = {
            v: 2,
            dbID: syncState === null || syncState === void 0 ? void 0 : syncState.remoteDbId,
            clientIdentity,
            schema: schema || {},
            lastPull: syncState
                ? {
                    serverRevision: syncState.serverRevision,
                    yServerRevision: syncState.yServerRevision,
                    realms: syncState.realms,
                    inviteRealms: syncState.inviteRealms,
                }
                : undefined,
            baseRevs,
            changes: encodeIdsForServer(db.dx.core.schema, currentUser, changes),
            y,
            dxcv: db.cloud.version
        };
        console.debug('Sync request', syncRequest);
        db.syncStateChangedEvent.next({
            phase: 'pushing',
        });
        const body = TSON.stringify(syncRequest);
        const res = yield fetch(`${databaseUrl}/sync`, {
            method: 'post',
            headers,
            credentials: 'include', // For Arr Affinity cookie only, for better Rate-Limit counting only.
            body,
        });
        //const contentLength = Number(res.headers.get('content-length'));
        db.syncStateChangedEvent.next({
            phase: 'pulling',
        });
        updateSyncRateLimitDelays(db, res);
        if (!res.ok) {
            throw new HttpError(res);
        }
        switch (res.headers.get('content-type')) {
            case 'application/x-bison':
                return BISON.fromBinary(yield res.blob());
            case 'application/x-bison-stream': //return BisonWebStreamReader(BISON, res);
            default:
            case 'application/json': {
                const text = yield res.text();
                const syncRes = TSON.parse(text);
                return syncRes;
            }
        }
    });
}

function modifyLocalObjectsWithNewUserId(syncifiedTables, currentUser, alreadySyncedRealms) {
    return __awaiter(this, void 0, void 0, function* () {
        const ignoredRealms = new Set(alreadySyncedRealms || []);
        for (const table of syncifiedTables) {
            if (table.name === "members") {
                // members
                yield table.toCollection().modify((member) => {
                    if (!ignoredRealms.has(member.realmId) && (!member.userId || member.userId === UNAUTHORIZED_USER.userId)) {
                        member.userId = currentUser.userId;
                    }
                });
            }
            else if (table.name === "roles") ;
            else if (table.name === "realms") {
                // realms
                yield table.toCollection().modify((realm) => {
                    if (!ignoredRealms.has(realm.realmId) && (realm.owner === undefined || realm.owner === UNAUTHORIZED_USER.userId)) {
                        realm.owner = currentUser.userId;
                    }
                });
            }
            else {
                // application entities
                yield table.toCollection().modify((obj) => {
                    if (!obj.realmId || !ignoredRealms.has(obj.realmId)) {
                        if (!obj.owner || obj.owner === UNAUTHORIZED_USER.userId)
                            obj.owner = currentUser.userId;
                        if (!obj.realmId || obj.realmId === UNAUTHORIZED_USER.userId) {
                            obj.realmId = currentUser.userId;
                        }
                    }
                });
            }
        }
    });
}

function throwIfCancelled(cancelToken) {
    if (cancelToken === null || cancelToken === void 0 ? void 0 : cancelToken.cancelled)
        throw new Dexie.AbortError(`Operation was cancelled`);
}

/* Need this because navigator.onLine seems to say "false" when it is actually online.
  This function relies initially on navigator.onLine but then uses online and offline events
  which seem to be more reliable.
*/
let isOnline = false;
if (typeof self !== 'undefined' && typeof navigator !== 'undefined') {
    isOnline = navigator.onLine;
    self.addEventListener('online', () => isOnline = true);
    self.addEventListener('offline', () => isOnline = false);
}

function updateBaseRevs(db, schema, latestRevisions, serverRev) {
    return __awaiter(this, void 0, void 0, function* () {
        yield db.$baseRevs.bulkPut(Object.keys(schema)
            .filter((table) => schema[table].markedForSync)
            .map((tableName) => {
            const lastClientRevOnPreviousServerRev = latestRevisions[tableName] || 0;
            return {
                tableName,
                clientRev: lastClientRevOnPreviousServerRev + 1,
                serverRev,
            };
        }));
        // Clean up baseRevs for tables that do not exist anymore or are no longer marked for sync
        // Resolve #2168 by also cleaning up baseRevs for tables that are not marked for sync
        yield db.$baseRevs.where('tableName').noneOf(Object.keys(schema).filter((table) => schema[table].markedForSync)).delete();
    });
}

function getLatestRevisionsPerTable(clientChangeSet, lastRevisions = {}) {
    for (const { table, muts } of clientChangeSet) {
        const lastRev = muts.length > 0 ? muts[muts.length - 1].rev : null;
        lastRevisions[table] = lastRev || lastRevisions[table] || 0;
    }
    return lastRevisions;
}

function bulkUpdate(table, keys, changeSpecs) {
    return __awaiter(this, void 0, void 0, function* () {
        const objs = yield table.bulkGet(keys);
        const resultKeys = [];
        const resultObjs = [];
        keys.forEach((key, idx) => {
            const obj = objs[idx];
            if (obj) {
                for (const [keyPath, value] of Object.entries(changeSpecs[idx])) {
                    if (keyPath === table.schema.primKey.keyPath) {
                        if (cmp(value, key) !== 0) {
                            throw new Error(`Cannot change primary key`);
                        }
                    }
                    else {
                        Dexie.setByKeyPath(obj, keyPath, value);
                    }
                }
                resultKeys.push(key);
                resultObjs.push(obj);
            }
        });
        yield (table.schema.primKey.keyPath == null
            ? table.bulkPut(resultObjs, resultKeys)
            : table.bulkPut(resultObjs));
    });
}

function applyServerChanges(changes, db) {
    return __awaiter(this, void 0, void 0, function* () {
        console.debug('Applying server changes', changes, Dexie.currentTransaction);
        for (const { table: tableName, muts } of changes) {
            if (!db.dx._allTables[tableName]) {
                console.debug(`Server sent changes for table ${tableName} that we don't have. Ignoring.`);
                continue;
            }
            const table = db.table(tableName);
            const { primaryKey } = table.core.schema;
            const keyDecoder = (key) => {
                switch (key[0]) {
                    case '[':
                        // Decode JSON array
                        if (key.endsWith(']'))
                            try {
                                // On server, array keys are transformed to JSON string representation
                                return JSON.parse(key);
                            }
                            catch (_a) { }
                        return key;
                    case '#':
                        // Decode private ID (do the opposite from what's done in encodeIdsForServer())
                        if (key.endsWith(':' + db.cloud.currentUserId)) {
                            return key.substr(0, key.length - db.cloud.currentUserId.length - 1);
                        }
                        return key;
                    default:
                        return key;
                }
            };
            for (const mut of muts) {
                const keys = mut.keys.map(keyDecoder);
                switch (mut.type) {
                    case 'insert':
                        if (primaryKey.outbound) {
                            yield table.bulkAdd(mut.values, keys);
                        }
                        else {
                            keys.forEach((key, i) => {
                                // Make sure inbound keys are consistent
                                Dexie.setByKeyPath(mut.values[i], primaryKey.keyPath, key);
                            });
                            yield table.bulkAdd(mut.values);
                        }
                        break;
                    case 'upsert':
                        if (primaryKey.outbound) {
                            yield table.bulkPut(mut.values, keys);
                        }
                        else {
                            keys.forEach((key, i) => {
                                // Make sure inbound keys are consistent
                                Dexie.setByKeyPath(mut.values[i], primaryKey.keyPath, key);
                            });
                            yield table.bulkPut(mut.values);
                        }
                        break;
                    case 'modify':
                        if (keys.length === 1) {
                            yield table.update(keys[0], mut.changeSpec);
                        }
                        else {
                            yield table.where(':id').anyOf(keys).modify(mut.changeSpec);
                        }
                        break;
                    case 'update':
                        yield bulkUpdate(table, keys, mut.changeSpecs);
                        break;
                    case 'delete':
                        yield table.bulkDelete(keys);
                        break;
                }
            }
        }
    });
}

const DEXIE_CLOUD_SYNCER_ID = 'dexie-cloud-syncer';

function listUpdatesSince(yTable, sinceIncluding) {
    return yTable
        .where('i')
        .between(sinceIncluding, Infinity, true)
        .toArray();
}

/** Queries the local database for YMessages to send to server.
 *
 * There are 2 messages that this function can provide:
 *   YUpdateFromClientRequest ( for local updates )
 *   YStateVector ( for state vector of foreign updates so that server can reduce the number of udpates to send back )
 *
 * Notice that we do not do a step 1 sync phase here to get a state vector from the server. Reason we can avoid
 * the 2-step sync is that we are client-server and not client-client here and we keep track of the client changes
 * sent to server by letting server acknowledge them. There is always a chance that some client update has already
 * been sent and that the client failed to receive the ack. However, if this happens it does not matter - the change
 * would be sent again and Yjs handles duplicate changes anyway. And it's rare so we earn the cost of roundtrips by
 * avoiding the step1 sync and instead keep track of this in the `unsentFrom` property of the SyncState.
 *
 * @param db
 * @returns
 */
function listYClientMessagesAndStateVector(db, tablesToSync) {
    return __awaiter(this, void 0, void 0, function* () {
        const result = [];
        const lastUpdateIds = {};
        for (const table of tablesToSync) {
            if (table.schema.yProps) {
                for (const yProp of table.schema.yProps) {
                    const yTable = db.table(yProp.updatesTable); // the updates-table for this combo of table+propName
                    const syncState = (yield yTable.get(DEXIE_CLOUD_SYNCER_ID));
                    // unsentFrom = the `i` value of updates that aren't yet sent to server (or at least not acked by the server yet)
                    const unsentFrom = (syncState === null || syncState === void 0 ? void 0 : syncState.unsentFrom) || 1;
                    // receivedUntil = the `i` value of updates that both we and the server knows we already have (we know it by the outcome from last syncWithServer() because server keep track of its revision numbers
                    const receivedUntil = (syncState === null || syncState === void 0 ? void 0 : syncState.receivedUntil) || 0;
                    // Compute the least value of these two (but since receivedUntil is inclusive we need to add +1 to it)
                    const unsyncedFrom = Math.min(unsentFrom, receivedUntil + 1);
                    // Query all these updates for all docs of this table+prop combination
                    const updates = yield listUpdatesSince(yTable, unsyncedFrom);
                    if (updates.length > 0)
                        lastUpdateIds[yTable.name] = updates[updates.length - 1].i;
                    // Now sort them by document and whether they are local or not + ignore local updates already sent:
                    const perDoc = {};
                    for (const update of updates) {
                        // Sort updates into buckets of the doc primary key + the flag (whether it's local or foreign)
                        const isLocal = ((update.f || 0) & 0x01) === 0x01;
                        if (isLocal && update.i < unsentFrom)
                            continue; // This local update has already been sent and acked.
                        const docKey = JSON.stringify(update.k) + '/' + isLocal;
                        let entry = perDoc[docKey];
                        if (!entry) {
                            perDoc[docKey] = entry = {
                                i: update.i,
                                k: update.k,
                                isLocal,
                                u: [],
                            };
                            entry.u.push(update.u);
                        }
                        else {
                            entry.u.push(update.u);
                            entry.i = Math.max(update.i, entry.i);
                        }
                    }
                    // Now, go through all these and:
                    // * For local updates, compute a merged update per document.
                    // * For foreign updates, compute a state vector to pass to server, so that server can
                    //   avoid re-sending updates that we already have (they might have been sent of websocket
                    //   and when that happens, we do not mark them in any way nor do we update receivedUntil -
                    //   we only update receivedUntil after a "full sync" (syncWithServer()))
                    for (const { k, isLocal, u, i } of Object.values(perDoc)) {
                        const mergedUpdate = u.length === 1 ? u[0] : Y.mergeUpdatesV2(u);
                        if (isLocal) {
                            result.push({
                                type: 'u-c',
                                table: table.name,
                                prop: yProp.prop,
                                k,
                                u: mergedUpdate,
                                i,
                            });
                        }
                        else {
                            const stateVector = Y.encodeStateVectorFromUpdateV2(mergedUpdate);
                            result.push({
                                type: 'sv',
                                table: table.name,
                                prop: yProp.prop,
                                k,
                                sv: stateVector,
                            });
                        }
                    }
                }
            }
        }
        return {
            yMessages: result,
            lastUpdateIds
        };
    });
}

function getUpdatesTable(db, table, ydocProp) {
    var _a, _b, _c;
    if (!db.dx._allTables[table])
        return undefined;
    const utbl = (_c = (_b = (_a = db.table(table)) === null || _a === void 0 ? void 0 : _a.schema.yProps) === null || _b === void 0 ? void 0 : _b.find(p => p.prop === ydocProp)) === null || _c === void 0 ? void 0 : _c.updatesTable;
    if (!utbl) {
        console.debug(`No updatesTable found for ${table}.${ydocProp}`);
        return undefined;
    }
    if (!db.dx._allTables[utbl])
        return undefined;
    return db.table(utbl);
}

function applyYServerMessages(yMessages, db) {
    return __awaiter(this, void 0, void 0, function* () {
        var _a;
        const receivedUntils = {};
        let resyncNeeded = false;
        let yServerRevision;
        for (const m of yMessages) {
            try {
                switch (m.type) {
                    case 'u-s': {
                        const utbl = getUpdatesTable(db, m.table, m.prop);
                        if (utbl) {
                            const updateRow = {
                                k: m.k,
                                u: m.u,
                            };
                            if (m.r) {
                                // @ts-ignore
                                updateRow.r = m.r;
                                yServerRevision = m.r;
                            }
                            receivedUntils[utbl.name] = yield utbl.add(updateRow);
                        }
                        break;
                    }
                    case 'u-ack': {
                        const utbl = getUpdatesTable(db, m.table, m.prop);
                        if (utbl) {
                            yield db.transaction('rw', utbl, (tx) => __awaiter(this, void 0, void 0, function* () {
                                let syncer = (yield tx
                                    .table(utbl.name)
                                    .get(DEXIE_CLOUD_SYNCER_ID));
                                yield tx.table(utbl.name).put(Object.assign(Object.assign({}, (syncer || { i: DEXIE_CLOUD_SYNCER_ID })), { unsentFrom: Math.max((syncer === null || syncer === void 0 ? void 0 : syncer.unsentFrom) || 1, m.i + 1) }));
                            }));
                        }
                        break;
                    }
                    case 'u-reject': {
                        // Acces control or constraint rejected the update.
                        // We delete it. It's not going to be sent again.
                        // What's missing is a way to notify consumers, such as Tiptap editor, that the update was rejected.
                        // This is only an issue when the document is open. We could find the open document and
                        // in a perfect world, we should send a reverse update to the open document to undo the change.
                        // See my question in https://discuss.yjs.dev/t/generate-an-inverse-update/2765
                        console.debug(`Y update rejected. Deleting it.`);
                        const utbl = getUpdatesTable(db, m.table, m.prop);
                        if (!utbl)
                            break;
                        // Delete the rejected update and all local updates since (avoid holes in the CRDT)
                        // and destroy it's open document if there is one.
                        const primaryKey = (_a = (yield utbl.get(m.i))) === null || _a === void 0 ? void 0 : _a.k;
                        if (primaryKey != null) {
                            yield db.transaction('rw', utbl, (tx) => {
                                // @ts-ignore
                                tx.idbtrans._rejecting_y_ypdate = true; // Inform ydoc triggers that we delete because of a rejection and not GC
                                return utbl
                                    .where('i')
                                    .aboveOrEqual(m.i)
                                    .filter((u) => cmp(u.k, primaryKey) === 0 && ((u.f || 0) & 1) === 1)
                                    .delete();
                            });
                            // Destroy active doc
                            const activeDoc = DexieYProvider.getDocCache(db.dx).find(m.table, primaryKey, m.prop);
                            if (activeDoc)
                                activeDoc.destroy(); // Destroy the document so that editors don't continue to work on it
                        }
                        break;
                    }
                    case 'in-sync': {
                        const doc = DexieYProvider.getDocCache(db.dx).find(m.table, m.k, m.prop);
                        if (doc && !doc.isSynced) {
                            doc.emit('sync', [true, doc]);
                        }
                        break;
                    }
                    case 'y-complete-sync-done': {
                        yServerRevision = m.yServerRev;
                        break;
                    }
                    case 'outdated-server-rev':
                        resyncNeeded = true;
                        break;
                }
            }
            catch (e) {
                console.error(`Failed to apply YMessage`, m, e);
            }
        }
        return {
            receivedUntils,
            resyncNeeded,
            yServerRevision,
        };
    });
}

function updateYSyncStates(lastUpdateIdsBeforeSync, receivedUntilsAfterSync, db) {
    return __awaiter(this, void 0, void 0, function* () {
        var _a, _b, _c, _d, _e;
        // We want to update unsentFrom for each yTable to the value specified in first argument
        //  because we got those values before we synced with server and here we are back from server
        //  that has successfully received all those messages - no matter if the last update was a client or server update,
        //  we can safely store unsentFrom to a value of the last update + 1 here.
        // We also want to update receivedUntil for each yTable to the value specified in the second argument,
        //  because that contains the highest resulted id of each update from server after storing it.
        // We could do these two tasks separately, but that would require two update calls on the same YSyncState, so
        // to optimize the dexie calls, we merge these two maps into a single one so we can do a single update request
        // per yTable.
        const mergedSpec = {};
        for (const [yTable, lastUpdateId] of Object.entries(lastUpdateIdsBeforeSync)) {
            (_a = mergedSpec[yTable]) !== null && _a !== void 0 ? _a : (mergedSpec[yTable] = {});
            mergedSpec[yTable].unsentFrom = lastUpdateId + 1;
        }
        for (const [yTable, lastUpdateId] of Object.entries(receivedUntilsAfterSync)) {
            (_b = mergedSpec[yTable]) !== null && _b !== void 0 ? _b : (mergedSpec[yTable] = {});
            mergedSpec[yTable].receivedUntil = lastUpdateId;
        }
        // Now go through all yTables and update their YSyncStates:
        const allYTables = Object.values(db.dx._dbSchema)
            .filter((tblSchema) => tblSchema.yProps)
            .map((tblSchema) => tblSchema.yProps.map((yProp) => yProp.updatesTable))
            .flat();
        for (const yTable of allYTables) {
            const mergedEntry = mergedSpec[yTable];
            const unsentFrom = (_c = mergedEntry === null || mergedEntry === void 0 ? void 0 : mergedEntry.unsentFrom) !== null && _c !== void 0 ? _c : 1;
            const receivedUntil = (_e = (_d = mergedEntry === null || mergedEntry === void 0 ? void 0 : mergedEntry.receivedUntil) !== null && _d !== void 0 ? _d : 
            // from local because we are in the same parent transaction (in sync.ts) that
            // applied all updates from the server
            (yield db
                .table(yTable)
                .where('i')
                .between(1, Infinity) // Because i might be string DEXIE_CLOUD_SYNCER_ID if not a number.
                .reverse()
                .limit(1)
                .primaryKeys())[0]) !== null && _e !== void 0 ? _e : 0;
            // We're already in a transaction, but for the sake of
            // code readability and correctness, let's launch an atomic sub transaction:
            yield db.transaction('rw', yTable, () => __awaiter(this, void 0, void 0, function* () {
                const state = yield db
                    .table(yTable)
                    .get(DEXIE_CLOUD_SYNCER_ID);
                if (!state) {
                    yield db.table(yTable).add({
                        i: DEXIE_CLOUD_SYNCER_ID,
                        unsentFrom,
                        receivedUntil
                    });
                }
                else {
                    state.unsentFrom = Math.max(unsentFrom, state.unsentFrom || 1);
                    state.receivedUntil = Math.max(receivedUntil, state.receivedUntil || 0);
                    yield db.table(yTable).put(state);
                }
            }));
        }
    });
}

const BINSTREAM_TYPE_REALMID = 1;
const BINSTREAM_TYPE_TABLE_AND_PROP = 2;
const BINSTREAM_TYPE_DOCUMENT = 3;
function downloadYDocsFromServer(db_1, databaseUrl_1, _a) {
    return __awaiter(this, arguments, void 0, function* (db, databaseUrl, { yDownloadedRealms, realms }) {
        if (yDownloadedRealms &&
            realms &&
            realms.every((realmId) => yDownloadedRealms[realmId] === '*')) {
            return; // Already done!
        }
        console.debug('Downloading Y.Docs from added realms');
        const user = yield loadAccessToken(db);
        const headers = {
            'Content-Type': 'application/json',
            Accept: 'application/octet-stream',
        };
        if (user) {
            headers.Authorization = `Bearer ${user.accessToken}`;
        }
        const res = yield fetch(`${databaseUrl}/y/download`, {
            body: TSON.stringify({ downloadedRealms: yDownloadedRealms || {} }),
            method: 'POST',
            headers,
            credentials: 'include',
        });
        if (!res.ok) {
            throw new Error(`Failed to download Yjs documents from server. Status: ${res.status}`);
        }
        yield asyncIterablePipeline(getFetchResponseBodyGenerator(res), consumeChunkedBinaryStream, consumeDownloadChunks);
        function consumeDownloadChunks(chunks) {
            return __asyncGenerator(this, arguments, function* consumeDownloadChunks_1() {
                var _a, e_1, _b, _c;
                let currentRealmId = null;
                let currentTable = null;
                let currentProp = null;
                let docsToInsert = [];
                function storeCollectedDocs(completedRealm) {
                    return __awaiter(this, void 0, void 0, function* () {
                        const lastDoc = docsToInsert[docsToInsert.length - 1];
                        if (docsToInsert.length > 0) {
                            if (!currentRealmId || !currentTable || !currentProp) {
                                throw new Error(`Protocol error from ${databaseUrl}/y/download`);
                            }
                            const yTable = getUpdatesTable(db, currentTable, currentProp);
                            if (yTable) {
                                yield yTable.bulkAdd(docsToInsert);
                            }
                            docsToInsert = [];
                        }
                        if (currentRealmId &&
                            ((currentTable && currentProp && lastDoc) || completedRealm)) {
                            yield db.$syncState.update('syncState', (syncState) => {
                                const yDownloadedRealms = syncState.yDownloadedRealms || {};
                                yDownloadedRealms[currentRealmId] = completedRealm
                                    ? '*'
                                    : {
                                        tbl: currentTable,
                                        prop: currentProp,
                                        key: lastDoc.k,
                                    };
                                syncState.yDownloadedRealms = yDownloadedRealms;
                            });
                        }
                    });
                }
                try {
                    try {
                        for (var _d = true, chunks_1 = __asyncValues(chunks), chunks_1_1; chunks_1_1 = yield __await(chunks_1.next()), _a = chunks_1_1.done, !_a; _d = true) {
                            _c = chunks_1_1.value;
                            _d = false;
                            const chunk = _c;
                            const decoder = new Decoder(chunk);
                            while (hasContent(decoder)) {
                                switch (readUint8(decoder)) {
                                    case BINSTREAM_TYPE_REALMID:
                                        yield __await(storeCollectedDocs(true));
                                        currentRealmId = readVarString(decoder);
                                        break;
                                    case BINSTREAM_TYPE_TABLE_AND_PROP:
                                        yield __await(storeCollectedDocs(false)); // still on same realm
                                        currentTable = readVarString(decoder);
                                        currentProp = readVarString(decoder);
                                        break;
                                    case BINSTREAM_TYPE_DOCUMENT: {
                                        const k = readAny(decoder);
                                        const u = readVarUint8Array(decoder);
                                        docsToInsert.push({
                                            k,
                                            u,
                                        });
                                        break;
                                    }
                                }
                            }
                            yield __await(storeCollectedDocs(false)); // Chunk full - migth still be on same realm
                        }
                    }
                    catch (e_1_1) { e_1 = { error: e_1_1 }; }
                    finally {
                        try {
                            if (!_d && !_a && (_b = chunks_1.return)) yield __await(_b.call(chunks_1));
                        }
                        finally { if (e_1) throw e_1.error; }
                    }
                    yield __await(storeCollectedDocs(true)); // Everything downloaded - finalize last downloaded realm to "*"
                }
                catch (error) {
                    if (!(error instanceof Dexie.DexieError)) {
                        // Network error might have happened.
                        // Store what we've collected so far:
                        yield __await(storeCollectedDocs(false));
                    }
                    throw error;
                }
            });
        }
    });
}

const CURRENT_SYNC_WORKER = 'currentSyncWorker';
function sync(db, options, schema, syncOptions) {
    return _sync(db, options, schema, syncOptions)
        .then((result) => {
        if (!(syncOptions === null || syncOptions === void 0 ? void 0 : syncOptions.justCheckIfNeeded)) { // && syncOptions?.purpose !== 'push') {
            db.syncStateChangedEvent.next({
                phase: 'in-sync',
            });
        }
        return result;
    })
        .catch((error) => __awaiter(this, void 0, void 0, function* () {
        if (syncOptions === null || syncOptions === void 0 ? void 0 : syncOptions.justCheckIfNeeded)
            return Promise.reject(error); // Just rethrow.
        console.debug('Error from _sync', {
            isOnline,
            syncOptions,
            error,
        });
        if (isOnline &&
            (syncOptions === null || syncOptions === void 0 ? void 0 : syncOptions.retryImmediatelyOnFetchError) &&
            (error === null || error === void 0 ? void 0 : error.name) === 'TypeError' &&
            /fetch/.test(error === null || error === void 0 ? void 0 : error.message)) {
            db.syncStateChangedEvent.next({
                phase: 'error',
                error,
            });
            // Retry again in 500 ms but if it fails again, don't retry.
            yield new Promise((resolve) => setTimeout(resolve, 500));
            return yield sync(db, options, schema, Object.assign(Object.assign({}, syncOptions), { retryImmediatelyOnFetchError: false }));
        }
        // Make sure that no matter whether sync() explodes or not,
        // always update the timestamp. Also store the error.
        yield db.$syncState.update('syncState', {
            timestamp: new Date(),
            error: '' + error,
        });
        db.syncStateChangedEvent.next({
            phase: isOnline ? 'error' : 'offline',
            error: new Error('' + (error === null || error === void 0 ? void 0 : error.message) || error),
        });
        return Promise.reject(error);
    }));
}
function _sync(db_1, options_1, schema_1) {
    return __awaiter(this, arguments, void 0, function* (db, options, schema, { isInitialSync, cancelToken, justCheckIfNeeded, purpose } = {
        isInitialSync: false,
    }) {
        var _a;
        if (!justCheckIfNeeded) {
            console.debug('SYNC STARTED', { isInitialSync, purpose });
        }
        if (!((_a = db.cloud.options) === null || _a === void 0 ? void 0 : _a.databaseUrl))
            throw new Error(`Internal error: sync must not be called when no databaseUrl is configured`);
        const { databaseUrl } = options;
        const currentUser = yield db.getCurrentUser(); // Keep same value across entire sync flow:
        const tablesToSync = currentUser.isLoggedIn ? getSyncableTables(db) : [];
        const mutationTables = tablesToSync.map((tbl) => db.table(getMutationTable(tbl.name)));
        // If this is not the initial sync,
        // go through tables that were previously not synced but should now be according to
        // logged in state and the sync table whitelist in db.cloud.options.
        //
        // Prepare for syncification by modifying locally unauthorized objects:
        //
        const persistedSyncState = yield db.getPersistedSyncState();
        const readyForSyncification = currentUser.isLoggedIn;
        const tablesToSyncify = readyForSyncification
            ? getTablesToSyncify(db, persistedSyncState)
            : [];
        throwIfCancelled(cancelToken);
        const doSyncify = tablesToSyncify.length > 0;
        if (doSyncify) {
            if (justCheckIfNeeded)
                return true;
            //console.debug('sync doSyncify is true');
            yield db.transaction('rw', tablesToSyncify, (tx) => __awaiter(this, void 0, void 0, function* () {
                // @ts-ignore
                tx.idbtrans.disableChangeTracking = true;
                // @ts-ignore
                tx.idbtrans.disableAccessControl = true; // TODO: Take care of this flag in access control middleware!
                yield modifyLocalObjectsWithNewUserId(tablesToSyncify, currentUser, persistedSyncState === null || persistedSyncState === void 0 ? void 0 : persistedSyncState.realms);
            }));
            throwIfCancelled(cancelToken);
        }
        //
        // List changes to sync
        //
        const [clientChangeSet, syncState, baseRevs, { yMessages, lastUpdateIds }] = yield db.transaction('r', db.tables, () => __awaiter(this, void 0, void 0, function* () {
            const syncState = yield db.getPersistedSyncState();
            let baseRevs = yield db.$baseRevs.toArray();
            // Resolve #2168
            baseRevs = baseRevs.filter(br => tablesToSync.some(tbl => tbl.name === br.tableName));
            let clientChanges = yield listClientChanges(mutationTables, db);
            const yResults = yield listYClientMessagesAndStateVector(db, tablesToSync);
            throwIfCancelled(cancelToken);
            if (doSyncify) {
                const alreadySyncedRealms = [
                    ...((persistedSyncState === null || persistedSyncState === void 0 ? void 0 : persistedSyncState.realms) || []),
                    ...((persistedSyncState === null || persistedSyncState === void 0 ? void 0 : persistedSyncState.inviteRealms) || []),
                ];
                const syncificationInserts = yield listSyncifiedChanges(tablesToSyncify, currentUser, schema, alreadySyncedRealms);
                throwIfCancelled(cancelToken);
                clientChanges = clientChanges.concat(syncificationInserts);
                return [clientChanges, syncState, baseRevs, yResults];
            }
            return [clientChanges, syncState, baseRevs, yResults];
        }));
        const pushSyncIsNeeded = clientChangeSet.some((set) => set.muts.some((mut) => mut.keys.length > 0)) || yMessages.some(m => m.type === 'u-c');
        if (justCheckIfNeeded) {
            console.debug('Sync is needed:', pushSyncIsNeeded);
            return pushSyncIsNeeded;
        }
        if (purpose === 'push' && !pushSyncIsNeeded) {
            // The purpose of this request was to push changes
            return false;
        }
        const latestRevisions = getLatestRevisionsPerTable(clientChangeSet, syncState === null || syncState === void 0 ? void 0 : syncState.latestRevisions);
        const clientIdentity = (syncState === null || syncState === void 0 ? void 0 : syncState.clientIdentity) || randomString(16);
        //
        // Push changes to server
        //
        throwIfCancelled(cancelToken);
        const res = yield syncWithServer(clientChangeSet, yMessages, syncState, baseRevs, db, databaseUrl, schema, clientIdentity, currentUser);
        console.debug('Sync response', res);
        //
        // Apply changes locally and clear old change entries:
        //
        const { done, newSyncState } = yield db.transaction('rw', db.tables, (tx) => __awaiter(this, void 0, void 0, function* () {
            // @ts-ignore
            tx.idbtrans.disableChangeTracking = true;
            // @ts-ignore
            tx.idbtrans.disableAccessControl = true; // TODO: Take care of this flag in access control middleware!
            // Update db.cloud.schema from server response.
            // Local schema MAY include a subset of tables, so do not force all tables into local schema.
            for (const tableName of Object.keys(schema)) {
                if (res.schema[tableName]) {
                    // Write directly into configured schema. This code can only be executed alone.
                    schema[tableName] = res.schema[tableName];
                }
            }
            yield db.$syncState.put(schema, 'schema');
            // List mutations that happened during our exchange with the server:
            const addedClientChanges = yield listClientChanges(mutationTables, db, {
                since: latestRevisions,
            });
            //
            // Delete changes now as server has return success
            // (but keep changes that haven't reached server yet)
            //
            for (const mutTable of mutationTables) {
                const tableName = getTableFromMutationTable(mutTable.name);
                if (!addedClientChanges.some((ch) => ch.table === tableName && ch.muts.length > 0)) {
                    // No added mutations for this table during the time we sent changes
                    // to the server.
                    // It is therefore safe to clear all changes (which is faster than
                    // deleting a range)
                    yield Promise.all([
                        mutTable.clear(),
                        db.$baseRevs.where({ tableName }).delete(),
                    ]);
                }
                else if (latestRevisions[tableName]) {
                    const latestRev = latestRevisions[tableName] || 0;
                    yield Promise.all([
                        mutTable.where('rev').belowOrEqual(latestRev).delete(),
                        db.$baseRevs
                            .where(':id')
                            .between([tableName, -Infinity], [tableName, latestRev + 1], true, true)
                            .reverse()
                            .offset(1) // Keep one entry (the one mapping muts that came during fetch --> previous server revision)
                            .delete(),
                    ]);
                }
                else ;
            }
            // Update latestRevisions object according to additional changes:
            getLatestRevisionsPerTable(addedClientChanges, latestRevisions);
            // Update/add new entries into baseRevs map.
            // * On tables without mutations since last serverRevision,
            //   this will update existing entry.
            // * On tables where mutations have been recorded since last
            //   serverRevision, this will create a new entry.
            // The purpose of this operation is to mark a start revision (per table)
            // so that all client-mutations that come after this, will be mapped to current
            // server revision.
            yield updateBaseRevs(db, schema, latestRevisions, res.serverRevision);
            const syncState = yield db.getPersistedSyncState();
            //
            // Delete objects from removed realms
            //
            yield deleteObjectsFromRemovedRealms(db, res, syncState);
            //
            // Update syncState
            //
            const newSyncState = syncState || {
                syncedTables: [],
                latestRevisions: {},
                realms: [],
                inviteRealms: [],
                clientIdentity,
            };
            if (readyForSyncification) {
                newSyncState.syncedTables = tablesToSync
                    .map((tbl) => tbl.name)
                    .concat(tablesToSyncify.map((tbl) => tbl.name));
            }
            newSyncState.latestRevisions = latestRevisions;
            newSyncState.remoteDbId = res.dbId;
            newSyncState.initiallySynced = true;
            newSyncState.realms = res.realms;
            newSyncState.inviteRealms = res.inviteRealms;
            newSyncState.serverRevision = res.serverRevision;
            newSyncState.yServerRevision = res.serverRevision;
            newSyncState.timestamp = new Date();
            delete newSyncState.error;
            const filteredChanges = filterServerChangesThroughAddedClientChanges(res.changes, addedClientChanges);
            //
            // apply server changes
            //
            yield applyServerChanges(filteredChanges, db);
            if (res.yMessages) {
                //
                // apply yMessages
                //
                const { receivedUntils, resyncNeeded, yServerRevision } = yield applyYServerMessages(res.yMessages, db);
                if (yServerRevision) {
                    newSyncState.yServerRevision = yServerRevision;
                }
                //
                // update Y SyncStates
                //
                yield updateYSyncStates(lastUpdateIds, receivedUntils, db);
                if (resyncNeeded) {
                    newSyncState.yDownloadedRealms = {}; // Will trigger a full download of Y-documents below...
                }
            }
            //
            // Update regular syncState
            //
            db.$syncState.put(newSyncState, 'syncState');
            return {
                done: addedClientChanges.length === 0,
                newSyncState
            };
        }));
        if (!done) {
            console.debug('MORE SYNC NEEDED. Go for it again!');
            yield checkSyncRateLimitDelay(db);
            return yield _sync(db, options, schema, { isInitialSync, cancelToken });
        }
        const usingYProps = Object.values(schema).some(tbl => { var _a; return (_a = tbl.yProps) === null || _a === void 0 ? void 0 : _a.length; });
        const serverSupportsYprops = !!res.yMessages;
        if (usingYProps && serverSupportsYprops) {
            try {
                yield downloadYDocsFromServer(db, databaseUrl, newSyncState);
            }
            catch (error) {
                console.error('Failed to download Yjs documents from server', error);
            }
        }
        console.debug('SYNC DONE', { isInitialSync });
        db.syncCompleteEvent.next();
        return false; // Not needed anymore
    });
}
function deleteObjectsFromRemovedRealms(db, res, syncState) {
    return __awaiter(this, void 0, void 0, function* () {
        const deletedRealms = new Set();
        const rejectedRealms = new Set();
        const previousRealmSet = syncState ? syncState.realms : [];
        const previousInviteRealmSet = syncState ? syncState.inviteRealms : [];
        const updatedRealmSet = new Set(res.realms);
        const updatedTotalRealmSet = new Set(res.realms.concat(res.inviteRealms));
        for (const realmId of previousRealmSet) {
            if (!updatedRealmSet.has(realmId)) {
                rejectedRealms.add(realmId);
                if (!updatedTotalRealmSet.has(realmId)) {
                    deletedRealms.add(realmId);
                }
            }
        }
        for (const realmId of previousInviteRealmSet.concat(previousRealmSet)) {
            if (!updatedTotalRealmSet.has(realmId)) {
                deletedRealms.add(realmId);
            }
        }
        if (deletedRealms.size > 0 || rejectedRealms.size > 0) {
            const tables = getSyncableTables(db);
            for (const table of tables) {
                let realmsToDelete = ['realms', 'members', 'roles'].includes(table.name)
                    ? deletedRealms // These tables should spare rejected ones.
                    : rejectedRealms; // All other tables shoudl delete rejected+deleted ones
                if (realmsToDelete.size === 0)
                    continue;
                if (table.schema.indexes.some((idx) => idx.keyPath === 'realmId' ||
                    (Array.isArray(idx.keyPath) && idx.keyPath[0] === 'realmId'))) {
                    // There's an index to use:
                    //console.debug(`REMOVAL: deleting all ${table.name} where realmId anyOf `, JSON.stringify([...realmsToDelete]));
                    yield table
                        .where('realmId')
                        .anyOf([...realmsToDelete])
                        .delete();
                }
                else {
                    // No index to use:
                    //console.debug(`REMOVAL: deleting all ${table.name} where realmId is any of `, JSON.stringify([...realmsToDelete]), realmsToDelete.size);
                    yield table
                        .filter((obj) => !!(obj === null || obj === void 0 ? void 0 : obj.realmId) && realmsToDelete.has(obj.realmId))
                        .delete();
                }
            }
        }
        if (rejectedRealms.size > 0 && (syncState === null || syncState === void 0 ? void 0 : syncState.yDownloadedRealms)) {
            for (const realmId of rejectedRealms) {
                delete syncState.yDownloadedRealms[realmId];
            }
        }
    });
}
function filterServerChangesThroughAddedClientChanges(serverChanges, addedClientChanges) {
    const changes = {};
    applyOperations(changes, serverChanges);
    const localPostChanges = {};
    applyOperations(localPostChanges, addedClientChanges);
    subtractChanges(changes, localPostChanges);
    return toDBOperationSet(changes);
}

const LIMIT_NUM_MESSAGES_PER_TIME = 10; // Allow a maximum of 10 messages per...
const TIME_WINDOW = 10000; // ...10 seconds.
const PAUSE_PERIOD = 1000; // Pause for 1 second if reached
function MessagesFromServerConsumer(db) {
    const queue = [];
    const readyToServe = new BehaviorSubject(true);
    const event = new BehaviorSubject(null);
    let isWorking = false;
    let loopDetection = new Array(LIMIT_NUM_MESSAGES_PER_TIME).fill(0);
    event.subscribe(() => __awaiter(this, void 0, void 0, function* () {
        if (isWorking)
            return;
        if (queue.length > 0) {
            isWorking = true;
            loopDetection.shift();
            loopDetection.push(Date.now());
            readyToServe.next(false);
            try {
                yield consumeQueue();
            }
            finally {
                if (loopDetection[loopDetection.length - 1] - loopDetection[0] <
                    TIME_WINDOW) {
                    // Ten loops within 10 seconds. Slow down!
                    // This is a one-time event. Just pause 10 seconds.
                    console.warn(`Slowing down websocket loop for ${PAUSE_PERIOD} milliseconds`);
                    yield new Promise((resolve) => setTimeout(resolve, PAUSE_PERIOD));
                }
                isWorking = false;
                readyToServe.next(true);
            }
        }
    }));
    function enqueue(msg) {
        queue.push(msg);
        event.next(null);
    }
    function consumeQueue() {
        return __awaiter(this, void 0, void 0, function* () {
            var _a, _b, _c, _d, _e, _f;
            while (queue.length > 0) {
                const msg = queue.shift();
                try {
                    // If the sync worker or service worker is syncing, wait 'til thei're done.
                    // It's no need to have two channels at the same time - even though it wouldnt
                    // be a problem - this is an optimization.
                    yield firstValueFrom(db.cloud.syncState.pipe(filter(({ phase }) => phase === 'in-sync' || phase === 'error')));
                    console.debug('processing msg', msg);
                    const persistedSyncState = db.cloud.persistedSyncState.value;
                    //syncState.
                    if (!msg)
                        continue;
                    switch (msg.type) {
                        case 'token-expired':
                            console.debug('WebSocket observable: Token expired. Refreshing token...');
                            const user = db.cloud.currentUser.value;
                            // Refresh access token
                            const refreshedLogin = yield refreshAccessToken(db.cloud.options.databaseUrl, user);
                            // Persist updated access token
                            yield db.table('$logins').update(user.userId, {
                                accessToken: refreshedLogin.accessToken,
                                accessTokenExpiration: refreshedLogin.accessTokenExpiration,
                                claims: refreshedLogin.claims,
                                license: refreshedLogin.license,
                                data: refreshedLogin.data,
                            });
                            // Updating $logins will trigger emission of db.cloud.currentUser observable, which
                            // in turn will lead to that connectWebSocket.ts will reconnect the socket with the
                            // new token. So we don't need to do anything more here.
                            break;
                        case 'realm-added':
                            if (!((_a = persistedSyncState === null || persistedSyncState === void 0 ? void 0 : persistedSyncState.realms) === null || _a === void 0 ? void 0 : _a.includes(msg.realm)) &&
                                !((_b = persistedSyncState === null || persistedSyncState === void 0 ? void 0 : persistedSyncState.inviteRealms) === null || _b === void 0 ? void 0 : _b.includes(msg.realm))) {
                                yield db.cloud.sync({ purpose: 'pull', wait: true });
                                //triggerSync(db, 'pull');
                            }
                            break;
                        case 'realm-accepted':
                            if (!((_c = persistedSyncState === null || persistedSyncState === void 0 ? void 0 : persistedSyncState.realms) === null || _c === void 0 ? void 0 : _c.includes(msg.realm))) {
                                yield db.cloud.sync({ purpose: 'pull', wait: true });
                                //triggerSync(db, 'pull');
                            }
                            break;
                        case 'realm-removed':
                            if (((_d = persistedSyncState === null || persistedSyncState === void 0 ? void 0 : persistedSyncState.realms) === null || _d === void 0 ? void 0 : _d.includes(msg.realm)) ||
                                ((_e = persistedSyncState === null || persistedSyncState === void 0 ? void 0 : persistedSyncState.inviteRealms) === null || _e === void 0 ? void 0 : _e.includes(msg.realm))) {
                                yield db.cloud.sync({ purpose: 'pull', wait: true });
                                //triggerSync(db, 'pull');
                            }
                            break;
                        case 'realms-changed':
                            //triggerSync(db, 'pull');
                            yield db.cloud.sync({ purpose: 'pull', wait: true });
                            break;
                        case 'changes':
                            console.debug('changes');
                            if (((_f = db.cloud.syncState.value) === null || _f === void 0 ? void 0 : _f.phase) === 'error') {
                                triggerSync(db, 'pull');
                                break;
                            }
                            yield db.transaction('rw', db.dx.tables, (tx) => __awaiter(this, void 0, void 0, function* () {
                                // @ts-ignore
                                tx.idbtrans.disableChangeTracking = true;
                                // @ts-ignore
                                tx.idbtrans.disableAccessControl = true;
                                const [schema, syncState, currentUser] = yield Promise.all([
                                    db.getSchema(),
                                    db.getPersistedSyncState(),
                                    db.getCurrentUser(),
                                ]);
                                console.debug('ws message queue: in transaction');
                                if (!syncState || !schema || !currentUser) {
                                    console.debug('required vars not present', {
                                        syncState,
                                        schema,
                                        currentUser,
                                    });
                                    return; // Initial sync must have taken place - otherwise, ignore this.
                                }
                                // Verify again in ACID tx that we're on same server revision.
                                if (msg.baseRev !== syncState.serverRevision) {
                                    console.debug(`baseRev (${msg.baseRev}) differs from our serverRevision in syncState (${syncState.serverRevision})`);
                                    // Should we trigger a sync now? No. This is a normal case
                                    // when another local peer (such as the SW or a websocket channel on other tab) has
                                    // updated syncState from new server information but we are not aware yet. It would
                                    // be unnescessary to do a sync in that case. Instead, the caller of this consumeQueue()
                                    // function will do readyToServe.next(true) right after this return, which will lead
                                    // to a "ready" message being sent to server with the new accurate serverRev we have,
                                    // so that the next message indeed will be correct.
                                    if (typeof msg.baseRev === 'string' && // v2 format
                                        (typeof syncState.serverRevision === 'bigint' || // v1 format
                                            typeof syncState.serverRevision === 'object') // v1 format old browser
                                    ) {
                                        // The reason for the diff seems to be that server has migrated the revision format.
                                        // Do a full sync to update revision format.
                                        // If we don't do a sync request now, we could stuck in an endless loop.
                                        triggerSync(db, 'pull');
                                    }
                                    return; // Ignore message
                                }
                                // Verify also that the message is based on the exact same set of realms
                                const ourRealmSetHash = yield Dexie.waitFor(
                                // Keep TX in non-IDB work
                                computeRealmSetHash(syncState));
                                console.debug('ourRealmSetHash', ourRealmSetHash);
                                if (ourRealmSetHash !== msg.realmSetHash) {
                                    console.debug('not same realmSetHash', msg.realmSetHash);
                                    triggerSync(db, 'pull');
                                    // The message isn't based on the same realms.
                                    // Trigger a sync instead to resolve all things up.
                                    return;
                                }
                                // Get clientChanges
                                let clientChanges = [];
                                if (currentUser.isLoggedIn) {
                                    const mutationTables = getSyncableTables(db).map((tbl) => db.table(getMutationTable(tbl.name)));
                                    clientChanges = yield listClientChanges(mutationTables, db);
                                    console.debug('msg queue: client changes', clientChanges);
                                }
                                if (msg.changes.length > 0) {
                                    const filteredChanges = filterServerChangesThroughAddedClientChanges(msg.changes, clientChanges);
                                    //
                                    // apply server changes
                                    //
                                    console.debug('applying filtered server changes', filteredChanges);
                                    yield applyServerChanges(filteredChanges, db);
                                }
                                // Update latest revisions per table in case there are unsynced changes
                                // This can be a real case in future when we allow non-eagery sync.
                                // And it can actually be realistic now also, but very rare.
                                syncState.latestRevisions = getLatestRevisionsPerTable(clientChanges, syncState.latestRevisions);
                                syncState.serverRevision = msg.newRev;
                                // Update base revs
                                console.debug('Updating baseRefs', syncState.latestRevisions);
                                yield updateBaseRevs(db, schema, syncState.latestRevisions, msg.newRev);
                                //
                                // Update syncState
                                //
                                console.debug('Updating syncState', syncState);
                                yield db.$syncState.put(syncState, 'syncState');
                            }));
                            console.debug('msg queue: done with rw transaction');
                            break;
                    }
                }
                catch (error) {
                    console.error(`Error in msg queue`, error);
                }
            }
        });
    }
    return {
        enqueue,
        readyToServe,
    };
}

const wm$2 = new WeakMap();
const DEXIE_CLOUD_SCHEMA = {
    members: '@id, [userId+realmId], [email+realmId], realmId',
    roles: '[realmId+name]',
    realms: '@realmId',
    $jobs: '',
    $syncState: '',
    $baseRevs: '[tableName+clientRev]',
    $logins: 'claims.sub, lastLogin',
};
let static_counter = 0;
function DexieCloudDB(dx) {
    if ('vip' in dx)
        dx = dx['vip']; // Avoid race condition. Always map to a vipped dexie that don't block during db.on.ready().
    let db = wm$2.get(dx.cloud);
    if (!db) {
        const localSyncEvent = new Subject();
        let syncStateChangedEvent = new BroadcastedAndLocalEvent(`syncstatechanged-${dx.name}`);
        let syncCompleteEvent = new BroadcastedAndLocalEvent(`synccomplete-${dx.name}`);
        localSyncEvent['id'] = ++static_counter;
        let initiallySynced = false;
        db = {
            get name() {
                return dx.name;
            },
            close() {
                return dx.close();
            },
            transaction: dx.transaction.bind(dx),
            table: dx.table.bind(dx),
            get tables() {
                return dx.tables;
            },
            cloud: dx.cloud,
            get $jobs() {
                return dx.table('$jobs');
            },
            get $syncState() {
                return dx.table('$syncState');
            },
            get $baseRevs() {
                return dx.table('$baseRevs');
            },
            get $logins() {
                return dx.table('$logins');
            },
            get realms() {
                return dx.realms;
            },
            get members() {
                return dx.members;
            },
            get roles() {
                return dx.roles;
            },
            get initiallySynced() {
                return initiallySynced;
            },
            localSyncEvent,
            get syncStateChangedEvent() {
                return syncStateChangedEvent;
            },
            get syncCompleteEvent() {
                return syncCompleteEvent;
            },
            dx,
        };
        const helperMethods = {
            getCurrentUser() {
                return db.$logins
                    .toArray()
                    .then((logins) => logins.find((l) => l.isLoggedIn) || UNAUTHORIZED_USER);
            },
            getPersistedSyncState() {
                return db.$syncState.get('syncState');
            },
            getSchema() {
                return db.$syncState.get('schema').then((schema) => {
                    if (schema) {
                        for (const table of db.tables) {
                            if (table.schema.primKey && table.schema.primKey.keyPath && schema[table.name]) {
                                schema[table.name].primaryKey = nameFromKeyPath(table.schema.primKey.keyPath);
                            }
                        }
                    }
                    return schema;
                });
            },
            getOptions() {
                return db.$syncState.get('options');
            },
            setInitiallySynced(value) {
                initiallySynced = value;
            },
            reconfigure() {
                syncStateChangedEvent = new BroadcastedAndLocalEvent(`syncstatechanged-${dx.name}`);
                syncCompleteEvent = new BroadcastedAndLocalEvent(`synccomplete-${dx.name}`);
            },
        };
        Object.assign(db, helperMethods);
        db.messageConsumer = MessagesFromServerConsumer(db);
        db.messageProducer = new Subject();
        wm$2.set(dx.cloud, db);
    }
    return db;
}
function nameFromKeyPath(keyPath) {
    return typeof keyPath === 'string' ?
        keyPath :
        keyPath ? ('[' + [].join.call(keyPath, '+') + ']') : "";
}

// Emulate true-private property db. Why? So it's not stored in DB.
const wm$1 = new WeakMap();
class AuthPersistedContext {
    constructor(db, userLogin) {
        wm$1.set(this, db);
        Object.assign(this, userLogin);
    }
    static load(db, userId) {
        return db
            .table("$logins")
            .get(userId)
            .then((userLogin) => new AuthPersistedContext(db, userLogin || {
            userId,
            claims: {
                sub: userId
            },
            lastLogin: new Date(0)
        }));
    }
    save() {
        return __awaiter(this, void 0, void 0, function* () {
            const db = wm$1.get(this);
            db.table("$logins").put(this);
        });
    }
}

function waitUntil(o, // Works with Dexie's liveQuery observables if we'd need that
predicate) {
    return firstValueFrom(from(o).pipe(filter$1(predicate)));
}

function logout(db) {
    return __awaiter(this, void 0, void 0, function* () {
        const numUnsyncedChanges = yield _logout(db);
        if (numUnsyncedChanges) {
            if (yield confirmLogout(db.cloud.userInteraction, db.cloud.currentUserId, numUnsyncedChanges)) {
                yield _logout(db, { deleteUnsyncedData: true });
            }
            else {
                throw new Error(`User cancelled logout due to unsynced changes`);
            }
        }
    });
}
function _logout(db_1) {
    return __awaiter(this, arguments, void 0, function* (db, { deleteUnsyncedData = false } = {}) {
        // Clear the database without emptying configuration options.
        const [numUnsynced, loggedOut] = yield db.dx.transaction('rw', db.dx.tables, (tx) => __awaiter(this, void 0, void 0, function* () {
            // @ts-ignore
            const idbtrans = tx.idbtrans;
            idbtrans.disableChangeTracking = true;
            idbtrans.disableAccessControl = true;
            const mutationTables = tx.storeNames.filter((tableName) => tableName.endsWith('_mutations'));
            // Count unsynced changes
            const unsyncCounts = yield Promise.all(mutationTables.map((mutationTable) => tx.table(mutationTable).count()));
            const sumUnSynced = unsyncCounts.reduce((a, b) => a + b, 0);
            if (sumUnSynced > 0 && !deleteUnsyncedData) {
                // Let caller ask user if they want to delete unsynced data.
                return [sumUnSynced, false];
            }
            // Either there are no unsynched changes, or caller provided flag deleteUnsynchedData = true.
            // Clear all tables except $jobs and $syncState (except the persisted sync state which is
            // also cleared because we're going to rebuild it using a fresh sync).
            db.$syncState.delete('syncState');
            for (const table of db.dx.tables) {
                if (table.name !== '$jobs' && table.name !== '$syncState') {
                    table.clear();
                }
            }
            return [sumUnSynced, true];
        }));
        if (loggedOut) {
            // Wait for currentUser observable to emit UNAUTHORIZED_USER
            yield waitUntil(db.cloud.currentUser, (user) => user.userId === UNAUTHORIZED_USER.userId);
            // Then perform an initial sync
            yield db.cloud.sync({ purpose: 'pull', wait: true });
        }
        return numUnsynced;
    });
}

function otpFetchTokenCallback(db) {
    const { userInteraction } = db.cloud;
    return function otpAuthenticate(_a) {
        return __awaiter(this, arguments, void 0, function* ({ public_key, hints }) {
            var _b;
            let tokenRequest;
            const url = (_b = db.cloud.options) === null || _b === void 0 ? void 0 : _b.databaseUrl;
            if (!url)
                throw new Error(`No database URL given.`);
            if ((hints === null || hints === void 0 ? void 0 : hints.grant_type) === 'demo') {
                const demo_user = yield promptForEmail(userInteraction, 'Enter a demo user email', (hints === null || hints === void 0 ? void 0 : hints.email) || (hints === null || hints === void 0 ? void 0 : hints.userId));
                tokenRequest = {
                    demo_user,
                    grant_type: 'demo',
                    scopes: ['ACCESS_DB'],
                    public_key
                };
            }
            else if ((hints === null || hints === void 0 ? void 0 : hints.otpId) && hints.otp) {
                // User provided OTP ID and OTP code. This means that the OTP email
                // has already gone out and the user may have clicked a magic link
                // in the email with otp and otpId in query and the app has picked
                // up those values and passed them to db.cloud.login().
                tokenRequest = {
                    grant_type: 'otp',
                    otp_id: hints.otpId,
                    otp: hints.otp,
                    scopes: ['ACCESS_DB'],
                    public_key,
                };
            }
            else {
                const email = yield promptForEmail(userInteraction, 'Enter email address', hints === null || hints === void 0 ? void 0 : hints.email);
                if (/@demo.local$/.test(email)) {
                    tokenRequest = {
                        demo_user: email,
                        grant_type: 'demo',
                        scopes: ['ACCESS_DB'],
                        public_key
                    };
                }
                else {
                    tokenRequest = {
                        email,
                        grant_type: 'otp',
                        scopes: ['ACCESS_DB'],
                    };
                }
            }
            const res1 = yield fetch(`${url}/token`, {
                body: JSON.stringify(tokenRequest),
                method: 'post',
                headers: { 'Content-Type': 'application/json', mode: 'cors' },
            });
            if (res1.status !== 200) {
                const errMsg = yield res1.text();
                yield alertUser(userInteraction, "Token request failed", {
                    type: 'error',
                    messageCode: 'GENERIC_ERROR',
                    message: errMsg,
                    messageParams: {}
                }).catch(() => { });
                throw new HttpError(res1, errMsg);
            }
            const response = yield res1.json();
            if (response.type === 'tokens' || response.type === 'error') {
                // Demo user request can get a "tokens" response right away
                // Error can also be returned right away.
                return response;
            }
            else if (tokenRequest.grant_type === 'otp' && 'email' in tokenRequest) {
                if (response.type !== 'otp-sent')
                    throw new Error(`Unexpected response from ${url}/token`);
                const otp = yield promptForOTP(userInteraction, tokenRequest.email);
                const tokenRequest2 = Object.assign(Object.assign({}, tokenRequest), { otp: otp || '', otp_id: response.otp_id, public_key });
                let res2 = yield fetch(`${url}/token`, {
                    body: JSON.stringify(tokenRequest2),
                    method: 'post',
                    headers: { 'Content-Type': 'application/json' },
                    mode: 'cors',
                });
                while (res2.status === 401) {
                    const errorText = yield res2.text();
                    tokenRequest2.otp = yield promptForOTP(userInteraction, tokenRequest.email, {
                        type: 'error',
                        messageCode: 'INVALID_OTP',
                        message: errorText,
                        messageParams: {}
                    });
                    res2 = yield fetch(`${url}/token`, {
                        body: JSON.stringify(tokenRequest2),
                        method: 'post',
                        headers: { 'Content-Type': 'application/json' },
                        mode: 'cors',
                    });
                }
                if (res2.status !== 200) {
                    const errMsg = yield res2.text();
                    throw new HttpError(res2, errMsg);
                }
                const response2 = yield res2.json();
                return response2;
            }
            else {
                throw new Error(`Unexpected response from ${url}/token`);
            }
        });
    };
}

/** A way to log to console in production without terser stripping out
 * it from the release bundle.
 * This should be used very rarely and only in places where it's
 * absolutely necessary to log something in production.
 *
 * @param level
 * @param args
 */
function prodLog(level, ...args) {
    globalThis["con" + "sole"][level](...args);
}

/** This function changes or sets the current user as requested.
 *
 * Use cases:
 * * Initially on db.ready after reading the current user from db.$logins.
 *   This will make sure that any unsynced operations from the previous user is synced before
 *   changing the user.
 * * Upon user request
 *
 * @param db
 * @param newUser
 */
function setCurrentUser(db, user) {
    return __awaiter(this, void 0, void 0, function* () {
        const $logins = db.table('$logins');
        yield db.transaction('rw', $logins, (tx) => __awaiter(this, void 0, void 0, function* () {
            const existingLogins = yield $logins.toArray();
            yield Promise.all(existingLogins
                .filter((login) => login.userId !== user.userId && login.isLoggedIn)
                .map((login) => {
                login.isLoggedIn = false;
                return $logins.put(login);
            }));
            user.isLoggedIn = true;
            user.lastLogin = new Date();
            try {
                yield user.save();
            }
            catch (e) {
                try {
                    if (e.name === 'DataCloneError') {
                        // We've seen this buggy behavior in some browsers and in case it happens
                        // again we really need to collect the details to understand what's going on.
                        prodLog('debug', `Login context property names:`, Object.keys(user));
                        prodLog('debug', `Login context property names:`, Object.keys(user));
                        prodLog('debug', `Login context:`, user);
                        prodLog('debug', `Login context JSON:`, JSON.stringify(user));
                    }
                }
                catch (_a) { }
                throw e;
            }
            console.debug('Saved new user', user.email);
        }));
        yield waitUntil(db.cloud.currentUser, (currentUser) => currentUser.userId === user.userId);
    });
}

function login(db, hints) {
    return __awaiter(this, void 0, void 0, function* () {
        var _a;
        const currentUser = yield db.getCurrentUser();
        const origUserId = currentUser.userId;
        if (currentUser.isLoggedIn && (!hints || (!hints.email && !hints.userId))) {
            const licenseStatus = ((_a = currentUser.license) === null || _a === void 0 ? void 0 : _a.status) || 'ok';
            if (licenseStatus === 'ok' &&
                currentUser.accessToken &&
                (!currentUser.accessTokenExpiration ||
                    currentUser.accessTokenExpiration.getTime() > Date.now())) {
                // Already authenticated according to given hints. And license is valid.
                return false;
            }
            if (currentUser.refreshToken &&
                (!currentUser.refreshTokenExpiration ||
                    currentUser.refreshTokenExpiration.getTime() > Date.now())) {
                // Refresh the token
                yield loadAccessToken(db);
                return false;
            }
            // No refresh token - must re-authenticate:
        }
        const context = new AuthPersistedContext(db, {
            claims: {},
            lastLogin: new Date(0),
        });
        yield authenticate(db.cloud.options.databaseUrl, context, db.cloud.options.fetchTokens || otpFetchTokenCallback(db), db.cloud.userInteraction, hints);
        if (origUserId !== UNAUTHORIZED_USER.userId &&
            context.userId !== origUserId) {
            // User was logged in before, but now logged in as another user.
            yield logout(db);
        }
        /*try {
          await context.save();
        } catch (e) {
          try {
            if (e.name === 'DataCloneError') {
              console.debug(`Login context property names:`, Object.keys(context));
              console.debug(`Login context:`, context);
              console.debug(`Login context JSON:`, JSON.stringify(context));
            }
          } catch {}
          throw e;
        }*/
        yield setCurrentUser(db, context);
        // Make sure to resync as the new login will be authorized
        // for new realms.
        triggerSync(db, 'pull');
        return context.userId !== origUserId;
    });
}

// @ts-ignore
const isFirefox = typeof InstallTrigger !== 'undefined';

const isSafari = typeof navigator !== 'undefined' &&
    /Safari\//.test(navigator.userAgent) &&
    !/Chrom(e|ium)\/|Edge\//.test(navigator.userAgent);
const safariVersion = isSafari
    ? // @ts-ignore
        [].concat(navigator.userAgent.match(/Safari\/(\d*)/))[1]
    : NaN;

// What we know: Safari 14.1 (version 605) crashes when using dexie-cloud's service worker.
// We don't know what exact call is causing this. Have tried safari-14-idb-fix with no luck.
// Something we do in the service worker is triggering the crash.
// When next Safari version (606) is out we will start enabling SW again, hoping that the bug is solved.
// If not, we might increment 605 to 606.
const DISABLE_SERVICEWORKER_STRATEGY = (isSafari && safariVersion <= 605) || // Disable for Safari for now.
    isFirefox; // Disable for Firefox for now. Seems to have a bug in reading CryptoKeys from IDB from service workers

const IS_SERVICE_WORKER = typeof self !== "undefined" && "clients" in self && !self.document;

function throwVersionIncrementNeeded() {
    throw new Dexie.SchemaError(`Version increment needed to allow dexie-cloud change tracking`);
}

const { toString } = {};
function toStringTag(o) {
    return toString.call(o).slice(8, -1);
}
function getEffectiveKeys(primaryKey, req) {
    var _a;
    if (req.type === 'delete')
        return req.keys;
    return ((_a = req.keys) === null || _a === void 0 ? void 0 : _a.slice()) || req.values.map(primaryKey.extractKey);
}
function applyToUpperBitFix(orig, bits) {
    return ((bits & 1 ? orig[0].toUpperCase() : orig[0].toLowerCase()) +
        (bits & 2 ? orig[1].toUpperCase() : orig[1].toLowerCase()) +
        (bits & 4 ? orig[2].toUpperCase() : orig[2].toLowerCase()));
}
const consonants = /b|c|d|f|g|h|j|k|l|m|n|p|q|r|s|t|v|x|y|z/i;
function isUpperCase(ch) {
    return ch >= 'A' && ch <= 'Z';
}
function generateTablePrefix(tableName, allPrefixes) {
    let rv = tableName[0].toLocaleLowerCase(); // "users" = "usr", "friends" = "frn", "realms" = "rlm", etc.
    for (let i = 1, l = tableName.length; i < l && rv.length < 3; ++i) {
        if (consonants.test(tableName[i]) || isUpperCase(tableName[i]))
            rv += tableName[i].toLowerCase();
    }
    while (allPrefixes.has(rv)) {
        if (/\d/g.test(rv)) {
            rv = rv.substr(0, rv.length - 1) + (rv[rv.length - 1] + 1);
            if (rv.length > 3)
                rv = rv.substr(0, 3);
            else
                continue;
        }
        else if (rv.length < 3) {
            rv = rv + '2';
            continue;
        }
        let bitFix = 1;
        let upperFixed = rv;
        while (allPrefixes.has(upperFixed) && bitFix < 8) {
            upperFixed = applyToUpperBitFix(rv, bitFix);
            ++bitFix;
        }
        if (bitFix < 8)
            rv = upperFixed;
        else {
            let nextChar = (rv.charCodeAt(2) + 1) & 127;
            rv = rv.substr(0, 2) + String.fromCharCode(nextChar);
            // Here, in theory we could get an infinite loop if having 127*8 table names with identical 3 first consonants.
        }
    }
    return rv;
}
let time = 0;
/**
 *
 * @param prefix A unique 3-letter short-name of the table.
 * @param shardKey 3 last letters from another ID if colocation is requested. Verified on server on inserts - guarantees unique IDs across shards.
 *  The shardKey part of the key represent the shardId where it was first created. An object with this
 *  primary key can later on be moved to another shard without being altered. The reason for having
 *  the origin shardKey as part of the key, is that the server will not need to check uniqueness constraint
 *  across all shards on every insert. Updates / moves across shards are already controlled by the server
 *  in the sense that the objects needs to be there already - we only need this part for inserts.
 * @returns
 */
function generateKey(prefix, shardKey) {
    const a = new Uint8Array(18);
    const timePart = new Uint8Array(a.buffer, 0, 6);
    const now = Date.now(); // Will fit into 6 bytes until year 10 895.
    if (time >= now) {
        // User is bulk-creating objects the same millisecond.
        // Increment the time part by one millisecond for each item.
        // If bulk-creating 1,000,000 rows client-side in 10 seconds,
        // the last time-stamp will be 990 seconds in future, which is no biggie at all.
        // The point is to create a nice order of the generated IDs instead of
        // using random ids.
        ++time;
    }
    else {
        time = now;
    }
    timePart[0] = time / 1099511627776; // Normal division (no bitwise operator) --> works with >= 32 bits.
    timePart[1] = time / 4294967296;
    timePart[2] = time / 16777216;
    timePart[3] = time / 65536;
    timePart[4] = time / 256;
    timePart[5] = time;
    const randomPart = new Uint8Array(a.buffer, 6);
    crypto.getRandomValues(randomPart);
    const id = new Uint8Array(a.buffer);
    return prefix + b64LexEncode(id) + (shardKey || '');
}

function createIdGenerationMiddleware(db) {
    return {
        stack: 'dbcore',
        name: 'idGenerationMiddleware',
        level: 1,
        create: (core) => {
            return Object.assign(Object.assign({}, core), { table: (tableName) => {
                    const table = core.table(tableName);
                    function generateOrVerifyAtKeys(req, idPrefix) {
                        let valueClones = null;
                        const keys = getEffectiveKeys(table.schema.primaryKey, req);
                        keys.forEach((key, idx) => {
                            if (key === undefined) {
                                // Generate the key
                                const colocatedId = req.values[idx].realmId || db.cloud.currentUserId;
                                const shardKey = colocatedId.substr(colocatedId.length - 3);
                                keys[idx] = generateKey(idPrefix, shardKey);
                                if (!table.schema.primaryKey.outbound) {
                                    if (!valueClones)
                                        valueClones = req.values.slice();
                                    valueClones[idx] = Dexie.deepClone(valueClones[idx]);
                                    Dexie.setByKeyPath(valueClones[idx], table.schema.primaryKey.keyPath, keys[idx]);
                                }
                            }
                            else if (typeof key !== 'string' ||
                                (!key.startsWith(idPrefix) && !key.startsWith('#' + idPrefix))) {
                                // Key was specified by caller. Verify it complies with id prefix.
                                throw new Dexie.ConstraintError(`The ID "${key}" is not valid for table "${tableName}". ` +
                                    `Primary '@' keys requires the key to be prefixed with "${idPrefix}" (or "#${idPrefix}).\n` +
                                    `If you want to generate IDs programmatically, remove '@' from the schema to get rid of this constraint. Dexie Cloud supports custom IDs as long as they are random and globally unique.`);
                            }
                        });
                        return table.mutate(Object.assign(Object.assign({}, req), { keys, values: valueClones || req.values }));
                    }
                    return Object.assign(Object.assign({}, table), { mutate: (req) => {
                            var _a, _b;
                            const idbtrans = req.trans;
                            if (idbtrans.mode === 'versionchange') {
                                // Tell all the other middlewares to skip bothering. We're in versionchange mode.
                                // dexie-cloud is not initialized yet.
                                idbtrans.disableChangeTracking = true;
                                idbtrans.disableAccessControl = true;
                            }
                            if (idbtrans.disableChangeTracking) {
                                // Disable ID policy checks and ID generation
                                return table.mutate(req);
                            }
                            if (req.type === 'add' || req.type === 'put') {
                                const cloudTableSchema = (_a = db.cloud.schema) === null || _a === void 0 ? void 0 : _a[tableName];
                                if (!(cloudTableSchema === null || cloudTableSchema === void 0 ? void 0 : cloudTableSchema.generatedGlobalId)) {
                                    if (cloudTableSchema === null || cloudTableSchema === void 0 ? void 0 : cloudTableSchema.markedForSync) {
                                        // Just make sure primary key is of a supported type:
                                        const keys = getEffectiveKeys(table.schema.primaryKey, req);
                                        keys.forEach((key, idx) => {
                                            if (!isValidSyncableID(key)) {
                                                const type = Array.isArray(key)
                                                    ? key.map(toStringTag).join(',')
                                                    : toStringTag(key);
                                                throw new Dexie.ConstraintError(`Invalid primary key type ${type} for table ${tableName}. Tables marked for sync has primary keys of type string or Array of string (and optional numbers)`);
                                            }
                                        });
                                    }
                                }
                                else {
                                    if (((_b = db.cloud.options) === null || _b === void 0 ? void 0 : _b.databaseUrl) && !db.initiallySynced) {
                                        // A database URL is configured but no initial sync has been performed.
                                        const keys = getEffectiveKeys(table.schema.primaryKey, req);
                                        // Check if the operation would yield any INSERT. If so, complain! We never want wrong ID prefixes stored.
                                        return table
                                            .getMany({ keys, trans: req.trans, cache: 'immutable' })
                                            .then((results) => {
                                            if (results.length < keys.length) {
                                                // At least one of the given objects would be created. Complain since
                                                // the generated ID would be based on a locally computed ID prefix only - we wouldn't
                                                // know if the server would give the same ID prefix until an initial sync has been
                                                // performed.
                                                throw new Error(`Unable to create new objects without an initial sync having been performed.`);
                                            }
                                            return table.mutate(req);
                                        });
                                    }
                                    return generateOrVerifyAtKeys(req, cloudTableSchema.idPrefix);
                                }
                            }
                            return table.mutate(req);
                        } });
                } });
        },
    };
}

function createImplicitPropSetterMiddleware(db) {
    return {
        stack: 'dbcore',
        name: 'implicitPropSetterMiddleware',
        level: 1,
        create: (core) => {
            return Object.assign(Object.assign({}, core), { table: (tableName) => {
                    const table = core.table(tableName);
                    return Object.assign(Object.assign({}, table), { mutate: (req) => {
                            var _a, _b, _c, _d, _e, _f;
                            const trans = req.trans;
                            if (trans.disableChangeTracking) {
                                return table.mutate(req);
                            }
                            const currentUserId = (_b = (_a = trans.currentUser) === null || _a === void 0 ? void 0 : _a.userId) !== null && _b !== void 0 ? _b : UNAUTHORIZED_USER.userId;
                            if ((_d = (_c = db.cloud.schema) === null || _c === void 0 ? void 0 : _c[tableName]) === null || _d === void 0 ? void 0 : _d.markedForSync) {
                                if (req.type === 'add' || req.type === 'put') {
                                    if (tableName === 'members') {
                                        for (const member of req.values) {
                                            if (typeof member.email === 'string') {
                                                // Resolve https://github.com/dexie/dexie-cloud/issues/4
                                                // If adding a member, make sure email is lowercase and trimmed.
                                                // This is to avoid issues where the APP does not check this
                                                // and just allows the user to enter an email address that might
                                                // have been pasted by the user from a source that had a trailing
                                                // space or was in uppercase. We want to avoid that the user
                                                // creates a new member with a different email address than
                                                // the one he/she intended to create.
                                                member.email = member.email.trim().toLowerCase();
                                            }
                                        }
                                    }
                                    // No matter if user is logged in or not, make sure "owner" and "realmId" props are set properly.
                                    // If not logged in, this will be changed upon syncification of the tables (next sync after login),
                                    // however, application code will work better if we can always rely on that the properties realmId
                                    // and owner are set. Application code may index them and query them based on db.cloud.currentUserId,
                                    // and expect them to be returned. That scenario must work also when db.cloud.currentUserId === 'unauthorized'.
                                    for (const obj of req.values) {
                                        if (!obj.owner) {
                                            obj.owner = currentUserId;
                                        }
                                        if (!obj.realmId) {
                                            obj.realmId = currentUserId;
                                        }
                                        const key = (_f = (_e = table.schema.primaryKey).extractKey) === null || _f === void 0 ? void 0 : _f.call(_e, obj);
                                        if (typeof key === 'string' && key[0] === '#') {
                                            // Add $ts prop for put operations and
                                            // disable update operations as well as consistent
                                            // modify operations. Reason: Server may not have
                                            // the object. Object should be created on server only
                                            // if is being updated. An update operation won't create it
                                            // so we must delete req.changeSpec to degrade operation to
                                            // an upsert operation with timestamp so that it will be created.
                                            // We must also degrade from consistent modify operations for the
                                            // same reason - object might be there on server. Must but put up instead.
                                            // FUTURE: This clumpsy behavior of private IDs could be refined later.
                                            // Suggestion is to in future, treat private IDs as we treat all objects 
                                            // and sync operations normally. Only that deletions should become soft deletes
                                            // for them - so that server knows when a private ID has been deleted on server
                                            // not accept insert/upserts on them.
                                            if (req.type === 'put') {
                                                delete req.criteria;
                                                delete req.changeSpec;
                                                if (!req.upsert)
                                                    delete req.updates;
                                                obj.$ts = Date.now();
                                            }
                                        }
                                    }
                                }
                            }
                            return table.mutate(req);
                        } });
                } });
        },
    };
}

function allSettled(possiblePromises) {
    return new Promise(resolve => {
        if (possiblePromises.length === 0)
            resolve([]);
        let remaining = possiblePromises.length;
        const results = new Array(remaining);
        possiblePromises.forEach((p, i) => Promise.resolve(p).then(value => results[i] = { status: "fulfilled", value }, reason => results[i] = { status: "rejected", reason })
            .then(() => --remaining || resolve(results)));
    });
}

let counter$1 = 0;
function guardedTable(table) {
    const prop = "$lock" + (++counter$1);
    return Object.assign(Object.assign({}, table), { count: readLock(table.count, prop), get: readLock(table.get, prop), getMany: readLock(table.getMany, prop), openCursor: readLock(table.openCursor, prop), query: readLock(table.query, prop), mutate: writeLock(table.mutate, prop) });
}
function readLock(fn, prop) {
    return function readLocker(req) {
        const { readers, writers, } = req.trans[prop] || (req.trans[prop] = { writers: [], readers: [] });
        const numWriters = writers.length;
        const promise = (numWriters > 0
            ? writers[numWriters - 1].then(() => fn(req), () => fn(req))
            : fn(req)).finally(() => { readers.splice(readers.indexOf(promise)); });
        readers.push(promise);
        return promise;
    };
}
function writeLock(fn, prop) {
    return function writeLocker(req) {
        const { readers, writers, } = req.trans[prop] || (req.trans[prop] = { writers: [], readers: [] });
        let promise = (writers.length > 0
            ? writers[writers.length - 1].then(() => fn(req), () => fn(req))
            : readers.length > 0
                ? allSettled(readers).then(() => fn(req))
                : fn(req)).finally(() => { writers.shift(); });
        writers.push(promise);
        return promise;
    };
}

const outstandingTransactions = new BehaviorSubject(new Set());

function isEagerSyncDisabled(db) {
    var _a, _b, _c, _d;
    return (((_a = db.cloud.options) === null || _a === void 0 ? void 0 : _a.disableEagerSync) ||
        ((_c = (_b = db.cloud.currentUser.value) === null || _b === void 0 ? void 0 : _b.license) === null || _c === void 0 ? void 0 : _c.status) !== 'ok' ||
        !((_d = db.cloud.options) === null || _d === void 0 ? void 0 : _d.databaseUrl));
}

/** Tracks all mutations in the same transaction as the mutations -
 * so it is guaranteed that no mutation goes untracked - and if transaction
 * aborts, the mutations won't be tracked.
 *
 * The sync job will use the tracked mutations as the source of truth when pushing
 * changes to server and cleanup the tracked mutations once the server has
 * ackowledged that it got them.
 */
function createMutationTrackingMiddleware({ currentUserObservable, db, }) {
    return {
        stack: 'dbcore',
        name: 'MutationTrackingMiddleware',
        level: 1,
        create: (core) => {
            const allTableNames = new Set(core.schema.tables.map((t) => t.name));
            const ordinaryTables = core.schema.tables.filter((t) => !/^\$/.test(t.name));
            const mutTableMap = new Map();
            for (const tbl of ordinaryTables) {
                const mutationTableName = `$${tbl.name}_mutations`;
                if (allTableNames.has(mutationTableName)) {
                    mutTableMap.set(tbl.name, core.table(mutationTableName));
                }
            }
            return Object.assign(Object.assign({}, core), { transaction: (tables, mode) => {
                    let tx;
                    if (mode === 'readwrite') {
                        const mutationTables = tables
                            .filter((tbl) => { var _a, _b; return (_b = (_a = db.cloud.schema) === null || _a === void 0 ? void 0 : _a[tbl]) === null || _b === void 0 ? void 0 : _b.markedForSync; })
                            .map((tbl) => getMutationTable(tbl));
                        tx = core.transaction([...tables, ...mutationTables], mode);
                    }
                    else {
                        tx = core.transaction(tables, mode);
                    }
                    if (mode === 'readwrite') {
                        // Give each transaction a globally unique id.
                        tx.txid = randomString$1(16);
                        tx.opCount = 0;
                        // Introduce the concept of current user that lasts through the entire transaction.
                        // This is important because the tracked mutations must be connected to the user.
                        tx.currentUser = currentUserObservable.value;
                        outstandingTransactions.value.add(tx);
                        outstandingTransactions.next(outstandingTransactions.value);
                        const removeTransaction = () => {
                            tx.removeEventListener('complete', txComplete);
                            tx.removeEventListener('error', removeTransaction);
                            tx.removeEventListener('abort', removeTransaction);
                            outstandingTransactions.value.delete(tx);
                            outstandingTransactions.next(outstandingTransactions.value);
                        };
                        const txComplete = () => {
                            if (tx.mutationsAdded && !isEagerSyncDisabled(db)) {
                                triggerSync(db, 'push');
                            }
                            removeTransaction();
                        };
                        tx.addEventListener('complete', txComplete);
                        tx.addEventListener('error', removeTransaction);
                        tx.addEventListener('abort', removeTransaction);
                    }
                    return tx;
                }, table: (tableName) => {
                    const table = core.table(tableName);
                    if (/^\$/.test(tableName)) {
                        if (tableName.endsWith('_mutations')) {
                            // In case application code adds items to ..._mutations tables,
                            // make sure to set the mutationsAdded flag on transaction.
                            // This is also done in mutateAndLog() as that function talks to a
                            // lower level DBCore and wouldn't be catched by this code.
                            return Object.assign(Object.assign({}, table), { mutate: (req) => {
                                    if (req.type === 'add' || req.type === 'put') {
                                        req.trans.mutationsAdded = true;
                                    }
                                    return table.mutate(req);
                                } });
                        }
                        else if (tableName === '$logins') {
                            return Object.assign(Object.assign({}, table), { mutate: (req) => {
                                    //console.debug('Mutating $logins table', req);
                                    return table
                                        .mutate(req)
                                        .then((res) => {
                                        //console.debug('Mutating $logins');
                                        req.trans.mutationsAdded = true;
                                        //console.debug('$logins mutated');
                                        return res;
                                    })
                                        .catch((err) => {
                                        console.debug('Failed mutation $logins', err);
                                        return Promise.reject(err);
                                    });
                                } });
                        }
                        else {
                            return table;
                        }
                    }
                    const { schema } = table;
                    const mutsTable = mutTableMap.get(tableName);
                    if (!mutsTable) {
                        // We cannot track mutations on this table because there is no mutations table for it.
                        // This might happen in upgraders that executes before cloud schema is applied.
                        return table;
                    }
                    return guardedTable(Object.assign(Object.assign({}, table), { mutate: (req) => {
                            var _a, _b, _c;
                            const trans = req.trans;
                            if (!trans.txid)
                                return table.mutate(req); // Upgrade transactions not guarded by us.
                            if (trans.disableChangeTracking)
                                return table.mutate(req);
                            if (!((_b = (_a = db.cloud.schema) === null || _a === void 0 ? void 0 : _a[tableName]) === null || _b === void 0 ? void 0 : _b.markedForSync))
                                return table.mutate(req);
                            if (!((_c = trans.currentUser) === null || _c === void 0 ? void 0 : _c.isLoggedIn)) {
                                // Unauthorized user should not log mutations.
                                // Instead, after login all local data should be logged at once.
                                return table.mutate(req);
                            }
                            return req.type === 'deleteRange'
                                ? table
                                    // Query the actual keys (needed for server sending correct rollback to us)
                                    .query({
                                    query: { range: req.range, index: schema.primaryKey },
                                    trans: req.trans,
                                    values: false,
                                })
                                    // Do a delete request instead, but keep the criteria info for the server to execute
                                    .then((res) => {
                                    return mutateAndLog({
                                        type: 'delete',
                                        keys: res.result,
                                        trans: req.trans,
                                        criteria: { index: null, range: req.range },
                                    });
                                })
                                : mutateAndLog(req);
                        } }));
                    function mutateAndLog(req) {
                        var _a, _b;
                        const trans = req.trans;
                        const unsyncedProps = (_b = (_a = db.cloud.options) === null || _a === void 0 ? void 0 : _a.unsyncedProperties) === null || _b === void 0 ? void 0 : _b[tableName];
                        const { txid, currentUser: { userId }, } = trans;
                        const { type } = req;
                        const opNo = ++trans.opCount;
                        function stripChangeSpec(changeSpec) {
                            if (!unsyncedProps)
                                return changeSpec;
                            let rv = changeSpec;
                            for (const keyPath of Object.keys(changeSpec)) {
                                if (unsyncedProps.some((p) => keyPath === p || keyPath.startsWith(p + '.'))) {
                                    if (rv === changeSpec)
                                        rv = Object.assign({}, changeSpec); // clone on demand
                                    delete rv[keyPath];
                                }
                            }
                            return rv;
                        }
                        return table.mutate(req).then((res) => {
                            var _a;
                            const { numFailures: hasFailures, failures } = res;
                            let keys = type === 'delete' ? req.keys : res.results;
                            let values = 'values' in req ? req.values : [];
                            let changeSpec = 'changeSpec' in req ? req.changeSpec : undefined;
                            let updates = 'updates' in req ? req.updates : undefined;
                            let upsert = updates && 'upsert' in req ? req.upsert : false;
                            if (hasFailures) {
                                keys = keys.filter((_, idx) => !failures[idx]);
                                values = values.filter((_, idx) => !failures[idx]);
                            }
                            if (unsyncedProps) {
                                // Filter out unsynced properties
                                values = values.map((value) => {
                                    const newValue = Object.assign({}, value);
                                    for (const prop of unsyncedProps) {
                                        delete newValue[prop];
                                    }
                                    return newValue;
                                });
                                if (changeSpec) {
                                    // modify operation with criteria and changeSpec.
                                    // We must strip out unsynced properties from changeSpec.
                                    // We deal with criteria later.
                                    changeSpec = stripChangeSpec(changeSpec);
                                    if (Object.keys(changeSpec).length === 0) {
                                        // Nothing to change on server
                                        return res;
                                    }
                                }
                                if (updates) {
                                    let strippedChangeSpecs = updates.changeSpecs.map(stripChangeSpec);
                                    let newUpdates = {
                                        keys: [],
                                        changeSpecs: [],
                                    };
                                    const validKeys = new RangeSet();
                                    let anyChangeSpecBecameEmpty = false;
                                    if (!upsert) {
                                        for (let i = 0, l = strippedChangeSpecs.length; i < l; ++i) {
                                            if (Object.keys(strippedChangeSpecs[i]).length > 0) {
                                                newUpdates.keys.push(updates.keys[i]);
                                                newUpdates.changeSpecs.push(strippedChangeSpecs[i]);
                                                validKeys.addKey(updates.keys[i]);
                                            }
                                            else {
                                                anyChangeSpecBecameEmpty = true;
                                            }
                                        }
                                        updates = newUpdates;
                                        if (anyChangeSpecBecameEmpty) {
                                            // Some keys were stripped. We must also strip them from keys and values
                                            // unless this is an upsert operation in which case we want to send them all.
                                            let newKeys = [];
                                            let newValues = [];
                                            for (let i = 0, l = keys.length; i < l; ++i) {
                                                if (validKeys.hasKey(keys[i])) {
                                                    newKeys.push(keys[i]);
                                                    newValues.push(values[i]);
                                                }
                                            }
                                            keys = newKeys;
                                            values = newValues;
                                        }
                                    }
                                }
                            }
                            const ts = Date.now();
                            // Canonicalize req.criteria.index to null if it's on the primary key.
                            let criteria = 'criteria' in req && req.criteria
                                ? Object.assign(Object.assign({}, req.criteria), { index: req.criteria.index === schema.primaryKey.keyPath // Use null to inform server that criteria is on primary key
                                        ? null // This will disable the server from trying to log consistent operations where it shouldnt.
                                        : req.criteria.index }) : undefined;
                            if (unsyncedProps && (criteria === null || criteria === void 0 ? void 0 : criteria.index)) {
                                const keyPaths = (_a = schema.indexes.find((idx) => idx.name === criteria.index)) === null || _a === void 0 ? void 0 : _a.keyPath;
                                const involvedProps = keyPaths
                                    ? typeof keyPaths === 'string'
                                        ? [keyPaths]
                                        : keyPaths
                                    : [];
                                if (involvedProps.some((p) => unsyncedProps === null || unsyncedProps === void 0 ? void 0 : unsyncedProps.includes(p))) {
                                    // Don't log criteria on unsynced properties as the server could not test them.
                                    criteria = undefined;
                                }
                            }
                            const mut = req.type === 'delete'
                                ? {
                                    type: 'delete',
                                    ts,
                                    opNo,
                                    keys,
                                    criteria,
                                    txid,
                                    userId,
                                }
                                : req.type === 'add'
                                    ? {
                                        type: 'insert',
                                        ts,
                                        opNo,
                                        keys,
                                        txid,
                                        userId,
                                        values,
                                    }
                                    : upsert && updates ? {
                                        type: 'upsert',
                                        ts,
                                        opNo,
                                        keys,
                                        values,
                                        changeSpecs: updates.changeSpecs.filter((_, idx) => !failures[idx]),
                                        txid,
                                        userId,
                                    }
                                        : criteria && changeSpec
                                            ? {
                                                // Common changeSpec for all keys
                                                type: 'modify',
                                                ts,
                                                opNo,
                                                keys,
                                                criteria,
                                                changeSpec,
                                                txid,
                                                userId,
                                            }
                                            : changeSpec
                                                ? {
                                                    // In case criteria involved an unsynced property, we go for keys instead.
                                                    type: 'update',
                                                    ts,
                                                    opNo,
                                                    keys,
                                                    changeSpecs: keys.map(() => changeSpec),
                                                    txid,
                                                    userId,
                                                }
                                                : updates
                                                    ? {
                                                        // One changeSpec per key
                                                        type: 'update',
                                                        ts,
                                                        opNo,
                                                        keys: updates.keys,
                                                        changeSpecs: updates.changeSpecs,
                                                        txid,
                                                        userId,
                                                    }
                                                    : {
                                                        type: 'upsert',
                                                        ts,
                                                        opNo,
                                                        keys,
                                                        values,
                                                        txid,
                                                        userId,
                                                    };
                            if ('isAdditionalChunk' in req && req.isAdditionalChunk) {
                                mut.isAdditionalChunk = true;
                            }
                            return keys.length > 0 || criteria
                                ? mutsTable
                                    .mutate({ type: 'add', trans, values: [mut] }) // Log entry
                                    .then(() => {
                                    trans.mutationsAdded = true; // Mark transaction as having added mutations to trigger eager sync
                                    return res; // Return original response
                                })
                                : res;
                        });
                    }
                } });
        },
    };
}

function overrideParseStoresSpec(origFunc, dexie) {
    return function (stores, dbSchema) {
        var _a;
        const storesClone = Object.assign(Object.assign({}, DEXIE_CLOUD_SCHEMA), stores);
        // Merge indexes of DEXIE_CLOUD_SCHEMA with stores
        Object.keys(DEXIE_CLOUD_SCHEMA).forEach((tableName) => {
            const schemaSrc = storesClone[tableName];
            // Verify that they don't try to delete a table that is needed for access control of Dexie Cloud
            if (schemaSrc == null) {
                // They try to delete one of the built-in schema tables.
                throw new Error(`Cannot delete table ${tableName} as it is needed for access control of Dexie Cloud`);
            }
            // If not trying to override a built-in table, then we can skip this and continue to next table.
            if (!stores[tableName]) {
                // They haven't tried to declare this table. No need to merge indexes.
                return; // Continue
            }
            // They have declared this table. Merge indexes in case they didn't declare all indexes we need.
            const requestedIndexes = schemaSrc.split(',').map(spec => spec.trim());
            const builtInIndexes = DEXIE_CLOUD_SCHEMA[tableName].split(',').map(spec => spec.trim());
            const requestedIndexSet = new Set(requestedIndexes.map(index => index.replace(/([&*]|\+\+)/g, "")));
            // Verify that primary key is unchanged
            if (requestedIndexes[0] !== builtInIndexes[0]) {
                // Primary key must match exactly
                throw new Error(`Cannot override primary key of table ${tableName}. Please declare it as {${tableName}: ${JSON.stringify(DEXIE_CLOUD_SCHEMA[tableName])}`);
            }
            // Merge indexes
            for (let i = 1; i < builtInIndexes.length; ++i) {
                const builtInIndex = builtInIndexes[i];
                if (!requestedIndexSet.has(builtInIndex.replace(/([&*]|\+\+)/g, ""))) {
                    // Add built-in index if not already requested
                    storesClone[tableName] += `,${builtInIndex}`;
                }
            }
        });
        // Populate dexie.cloud.schema
        const cloudSchema = dexie.cloud.schema || (dexie.cloud.schema = {});
        const allPrefixes = new Set();
        Object.keys(storesClone).forEach(tableName => {
            var _a;
            const schemaSrc = (_a = storesClone[tableName]) === null || _a === void 0 ? void 0 : _a.trim();
            const cloudTableSchema = cloudSchema[tableName] || (cloudSchema[tableName] = {});
            if (schemaSrc != null) {
                if (/^\@/.test(schemaSrc)) {
                    storesClone[tableName] = storesClone[tableName].substr(1);
                    cloudTableSchema.generatedGlobalId = true;
                    cloudTableSchema.idPrefix = generateTablePrefix(tableName, allPrefixes);
                    allPrefixes.add(cloudTableSchema.idPrefix);
                }
                if (!/^\$/.test(tableName)) {
                    storesClone[`$${tableName}_mutations`] = '++rev';
                    cloudTableSchema.markedForSync = true;
                }
                if (cloudTableSchema.deleted) {
                    cloudTableSchema.deleted = false;
                }
            }
            else {
                cloudTableSchema.deleted = true;
                cloudTableSchema.markedForSync = false;
                storesClone[`$${tableName}_mutations`] = null;
            }
        });
        const rv = origFunc.call(this, storesClone, dbSchema);
        for (const [tableName, spec] of Object.entries(dbSchema)) {
            if ((_a = spec.yProps) === null || _a === void 0 ? void 0 : _a.length) {
                const cloudTableSchema = cloudSchema[tableName];
                if (cloudTableSchema) {
                    cloudTableSchema.yProps = spec.yProps.map((yProp) => yProp.prop);
                }
            }
        }
        return rv;
    };
}

function performGuardedJob(db, jobName, job) {
    if (typeof navigator === 'undefined' || !navigator.locks) {
        // No support for guarding jobs. IE11, node.js, etc.
        return job();
    }
    // @ts-expect-error - LockManager callback type inference issue with generics
    return navigator.locks.request(db.name + '|' + jobName, job);
}

function performInitialSync(db, cloudOptions, cloudSchema) {
    return __awaiter(this, void 0, void 0, function* () {
        console.debug('Performing initial sync');
        yield performGuardedJob(db, CURRENT_SYNC_WORKER, () => sync(db, cloudOptions, cloudSchema, { isInitialSync: true }));
        console.debug('Done initial sync');
    });
}

const USER_INACTIVITY_TIMEOUT = 180000; // 3 minutes
const INACTIVE_WAIT_TIME = 20000;
// This observable will be emitted to later down....
const userIsActive = new BehaviorSubject(true);
// A refined version that waits before changing state:
// * Wait another INACTIVE_WAIT_TIME before accepting that the user is inactive.
//   Reason 1: Spare resources - no need to setup the entire websocket flow when
//             switching tabs back and forth.
//   Reason 2: Less flickering for the end user when switching tabs back and forth.
// * Wait another ACTIVE_WAIT_TIME before accepting that the user is active.
//   Possible reason to have a value here: Sparing resources if users often temporary click the tab
//   for just a short time.
const userIsReallyActive = new BehaviorSubject(true);
userIsActive
    .pipe(switchMap((isActive) => {
    //console.debug('SyncStatus: DUBB: isActive changed to', isActive);
    return isActive
        ? of(true)
        : of(false).pipe(delay(INACTIVE_WAIT_TIME))
            ;
}), distinctUntilChanged())
    .subscribe(userIsReallyActive);
//
// First create some corner-stone observables to build the flow on
//
// document.onvisibilitychange:
const visibilityStateIsChanged = typeof document !== 'undefined'
    ? fromEvent(document, 'visibilitychange')
    : of({});
// document.onvisibilitychange makes document hidden:
const documentBecomesHidden = visibilityStateIsChanged.pipe(filter(() => document.visibilityState === 'hidden'));
// document.onvisibilitychange makes document visible
const documentBecomesVisible = visibilityStateIsChanged.pipe(filter(() => document.visibilityState === 'visible'));
// Any of various user-activity-related events happen:
const userDoesSomething = typeof window !== 'undefined'
    ? merge(documentBecomesVisible, fromEvent(window, 'mousedown'), fromEvent(window, 'mousemove'), fromEvent(window, 'keydown'), fromEvent(window, 'wheel'), fromEvent(window, 'touchmove'))
    : of({});
if (typeof document !== 'undefined') {
    //
    // Now, create a final observable and start subscribing to it in order
    // to make it emit values to userIsActive BehaviourSubject (which is the
    // most important global hot observable we have here)
    //
    // Live test: https://jsitor.com/LboCDHgbn
    //
    merge(of(true), // Make sure something is always emitted from start
    documentBecomesHidden, // so that we can eagerly emit false!
    userDoesSomething)
        .pipe(
    // No matter event source, compute whether user is visible using visibilityState:
    map(() => document.visibilityState === 'visible'), 
    // Make sure to emit it
    tap((isActive) => {
        if (userIsActive.value !== isActive) {
            // Emit new value unless it already has that value
            userIsActive.next(isActive);
        }
    }), 
    // Now, if true was emitted, make sure to set a timeout to emit false
    // unless new user activity things happen (in that case, the timeout will be cancelled!)
    switchMap((isActive) => isActive
        ? of(0).pipe(delay(USER_INACTIVITY_TIMEOUT - INACTIVE_WAIT_TIME), tap(() => userIsActive.next(false)))
        : of(0)))
        .subscribe(() => { }); // Unless we subscribe nothing will be propagated to userIsActive observable
}

class TokenExpiredError extends Error {
    constructor() {
        super(...arguments);
        this.name = "TokenExpiredError";
    }
}

function createYClientUpdateObservable(db) {
    const yTableRecords = flatten(db.tables
        .filter((table) => { var _a, _b; return ((_b = (_a = db.cloud.schema) === null || _a === void 0 ? void 0 : _a[table.name]) === null || _b === void 0 ? void 0 : _b.markedForSync) && table.schema.yProps; })
        .map((table) => table.schema.yProps.map((p) => ({
        table: table.name,
        ydocProp: p.prop,
        updatesTable: p.updatesTable,
    }))));
    return merge(...yTableRecords.map(({ table, ydocProp, updatesTable }) => {
        // Per updates table (table+prop combo), we first read syncer.unsentFrom,
        // and then start listening for updates since that number.
        const yTbl = db.table(updatesTable);
        return from(yTbl.get(DEXIE_CLOUD_SYNCER_ID)).pipe(switchMap$1((syncer) => {
            let currentUnsentFrom = (syncer === null || syncer === void 0 ? void 0 : syncer.unsentFrom) || 1;
            return from(liveQuery(() => __awaiter(this, void 0, void 0, function* () {
                const addedUpdates = yield listUpdatesSince(yTbl, currentUnsentFrom);
                return addedUpdates
                    .filter((update) => update.f && update.f & 1) // Only include local updates
                    .map((update) => {
                    return {
                        type: 'u-c',
                        table,
                        prop: ydocProp,
                        k: update.k,
                        u: update.u,
                        i: update.i,
                    };
                });
            }))).pipe(tap$1((addedUpdates) => {
                // Update currentUnsentFrom to only listen for updates that will be newer than the ones we emitted.
                // (Before, we did this within the liveQuery, but that caused a bug because
                // a cancelled emittion of a liveQuery would update the currentUnsentFrom without
                // emitting anything, leading to that we jumped over some updates. Here we update it
                // after the liveQuery has emitted its updates)
                if (addedUpdates.length > 0) {
                    currentUnsentFrom = addedUpdates.at(-1).i + 1;
                }
            }));
        }));
    })).pipe(
    // Flatten the array of messages.
    // If messageProducer emits empty array, nothing is emitted
    // but if messageProducer emits array of messages, they are
    // emitted one by one.
    mergeMap((messages) => messages));
}

const awarenessWeakMap = new WeakMap();
const getDocAwareness = (doc) => awarenessWeakMap.get(doc);

const wm = new WeakMap();
/** A property (package-private) on Y.Doc that is used
 * to signal that the server wants us to send a 'doc-open' message
 * to the server for this document.
 *
 * @param doc
 * @returns
 */
function getOpenDocSignal(doc) {
    let signal = wm.get(doc);
    if (!signal) {
        signal = new Subject();
        wm.set(doc, signal);
    }
    return signal;
}

const SERVER_PING_TIMEOUT = 20000;
const CLIENT_PING_INTERVAL = 30000;
const FAIL_RETRY_WAIT_TIME = 60000;
class WSObservable extends Observable {
    constructor(db, rev, yrev, realmSetHash, clientIdentity, messageProducer, webSocketStatus, user) {
        super((subscriber) => new WSConnection(db, rev, yrev, realmSetHash, clientIdentity, user, subscriber, messageProducer, webSocketStatus));
    }
}
let counter = 0;
class WSConnection extends Subscription {
    constructor(db, rev, yrev, realmSetHash, clientIdentity, user, subscriber, messageProducer, webSocketStatus) {
        super(() => this.teardown());
        this.id = ++counter;
        this.subscriptions = new Set();
        this.reconnecting = false;
        console.debug('New WebSocket Connection', this.id, user.accessToken ? 'authorized' : 'unauthorized');
        this.db = db;
        this.databaseUrl = db.cloud.options.databaseUrl;
        this.rev = rev;
        this.yrev = yrev;
        this.realmSetHash = realmSetHash;
        this.clientIdentity = clientIdentity;
        this.user = user;
        this.subscriber = subscriber;
        this.lastUserActivity = new Date();
        this.messageProducer = messageProducer;
        this.webSocketStatus = webSocketStatus;
        this.connect();
    }
    teardown() {
        console.debug('Teardown WebSocket Connection', this.id);
        this.disconnect();
    }
    disconnect() {
        this.webSocketStatus.next('disconnected');
        if (this.pinger) {
            clearInterval(this.pinger);
            this.pinger = null;
        }
        if (this.ws) {
            try {
                this.ws.close();
            }
            catch (_a) { }
        }
        this.ws = null;
        for (const sub of this.subscriptions) {
            sub.unsubscribe();
        }
        this.subscriptions.clear();
    }
    reconnect() {
        if (this.reconnecting)
            return;
        this.reconnecting = true;
        try {
            this.disconnect();
        }
        catch (_a) { }
        this.connect()
            .catch(() => { })
            .then(() => (this.reconnecting = false)); // finally()
    }
    connect() {
        return __awaiter(this, void 0, void 0, function* () {
            this.lastServerActivity = new Date();
            if (this.pauseUntil && this.pauseUntil > new Date()) {
                console.debug('WS not reconnecting just yet', {
                    id: this.id,
                    pauseUntil: this.pauseUntil,
                });
                return;
            }
            if (this.ws) {
                throw new Error(`Called connect() when a connection is already open`);
            }
            if (!this.databaseUrl)
                throw new Error(`Cannot connect without a database URL`);
            if (this.closed) {
                //console.debug('SyncStatus: DUBB: Ooops it was closed!');
                return;
            }
            const tokenExpiration = this.user.accessTokenExpiration;
            if (tokenExpiration && tokenExpiration < new Date()) {
                this.subscriber.error(new TokenExpiredError()); // Will be handled in connectWebSocket.ts.
                return;
            }
            this.webSocketStatus.next('connecting');
            this.pinger = setInterval(() => __awaiter(this, void 0, void 0, function* () {
                // setInterval here causes unnecessary pings when server is proved active anyway.
                // TODO: Use setTimout() here instead. When triggered, check if we really need to ping.
                // In case we've had server activity, we don't need to ping. Then schedule then next ping
                // to the time when we should ping next time (based on lastServerActivity + CLIENT_PING_INTERVAL).
                // Else, ping now and schedule next ping to CLIENT_PING_INTERVAL from now.
                if (this.closed) {
                    console.debug('pinger check', this.id, 'CLOSED.');
                    this.teardown();
                    return;
                }
                if (this.ws) {
                    try {
                        this.ws.send(JSON.stringify({ type: 'ping' }));
                        setTimeout(() => {
                            console.debug('pinger setTimeout', this.id, this.pinger ? `alive` : 'dead');
                            if (!this.pinger)
                                return;
                            if (this.closed) {
                                console.debug('pinger setTimeout', this.id, 'subscription is closed');
                                this.teardown();
                                return;
                            }
                            if (this.lastServerActivity <
                                new Date(Date.now() - SERVER_PING_TIMEOUT)) {
                                // Server inactive. Reconnect if user is active.
                                console.debug('pinger: server is inactive');
                                console.debug('pinger reconnecting');
                                this.reconnect();
                            }
                            else {
                                console.debug('pinger: server still active');
                            }
                        }, SERVER_PING_TIMEOUT);
                    }
                    catch (_a) {
                        console.debug('pinger catch error', this.id, 'reconnecting');
                        this.reconnect();
                    }
                }
                else {
                    console.debug('pinger', this.id, 'reconnecting');
                    this.reconnect();
                }
            }), CLIENT_PING_INTERVAL);
            // The following vars are needed because we must know which callback to ack when server sends it's ack to us.
            const wsUrl = new URL(this.databaseUrl);
            wsUrl.protocol = wsUrl.protocol === 'http:' ? 'ws' : 'wss';
            const searchParams = new URLSearchParams();
            if (this.subscriber.closed)
                return;
            searchParams.set('v', '2');
            if (this.rev)
                searchParams.set('rev', this.rev);
            if (this.yrev)
                searchParams.set('yrev', this.yrev);
            searchParams.set('realmsHash', this.realmSetHash);
            searchParams.set('clientId', this.clientIdentity);
            searchParams.set('dxcv', this.db.cloud.version);
            if (this.user.accessToken) {
                searchParams.set('token', this.user.accessToken);
            }
            // Connect the WebSocket to given url:
            console.debug('dexie-cloud WebSocket create');
            const ws = (this.ws = new WebSocket(`${wsUrl}/changes?${searchParams}`));
            ws.binaryType = "arraybuffer";
            ws.onclose = (event) => {
                if (!this.pinger)
                    return;
                console.debug('dexie-cloud WebSocket onclosed', this.id);
                this.reconnect();
            };
            ws.onmessage = (event) => {
                if (!this.pinger)
                    return;
                this.lastServerActivity = new Date();
                try {
                    const msg = typeof event.data === 'string'
                        ? TSON.parse(event.data)
                        : decodeYMessage(new Uint8Array(event.data));
                    console.debug('dexie-cloud WebSocket onmessage', msg.type, msg);
                    if (msg.type === 'error') {
                        throw new Error(`Error message from dexie-cloud: ${msg.error}`);
                    }
                    else if (msg.type === 'aware') {
                        const docCache = DexieYProvider.getDocCache(this.db.dx);
                        const doc = docCache.find(msg.table, msg.k, msg.prop);
                        if (doc) {
                            const awareness = getDocAwareness(doc);
                            if (awareness) {
                                awap.applyAwarenessUpdate(awareness, msg.u, 'server');
                            }
                        }
                    }
                    else if (msg.type === 'pong') {
                        // Do nothing
                    }
                    else if (msg.type === 'doc-open') {
                        const docCache = DexieYProvider.getDocCache(this.db.dx);
                        const doc = docCache.find(msg.table, msg.k, msg.prop);
                        if (doc) {
                            getOpenDocSignal(doc).next(); // Make yHandler reopen the document on server.
                        }
                    }
                    else if (msg.type === 'u-ack' || msg.type === 'u-reject' || msg.type === 'u-s' || msg.type === 'in-sync' || msg.type === 'outdated-server-rev' || msg.type === 'y-complete-sync-done') {
                        applyYServerMessages([msg], this.db).then((_a) => __awaiter(this, [_a], void 0, function* ({ resyncNeeded, yServerRevision, receivedUntils }) {
                            if (yServerRevision) {
                                yield this.db.$syncState.update('syncState', { yServerRevision: yServerRevision });
                            }
                            if (msg.type === 'u-s' && receivedUntils) {
                                const utbl = getUpdatesTable(this.db, msg.table, msg.prop);
                                if (utbl) {
                                    const receivedUntil = receivedUntils[utbl.name];
                                    if (receivedUntil) {
                                        yield utbl.update(DEXIE_CLOUD_SYNCER_ID, { receivedUntil });
                                    }
                                }
                            }
                            if (resyncNeeded) {
                                yield this.db.cloud.sync({ purpose: 'pull', wait: true });
                            }
                        }));
                    }
                    else {
                        // Forward the request to our subscriber, wich is in messageFromServerQueue.ts (via connectWebSocket's subscribe() at the end!)
                        this.subscriber.next(msg);
                    }
                }
                catch (e) {
                    this.subscriber.error(e);
                }
            };
            try {
                let everConnected = false;
                yield new Promise((resolve, reject) => {
                    ws.onopen = (event) => {
                        console.debug('dexie-cloud WebSocket onopen');
                        everConnected = true;
                        resolve(null);
                    };
                    ws.onerror = (event) => {
                        if (!everConnected) {
                            const error = event.error || new Error('WebSocket Error');
                            this.subscriber.error(error);
                            this.webSocketStatus.next('error');
                            reject(error);
                        }
                        else {
                            this.reconnect();
                        }
                    };
                });
                this.subscriptions.add(this.messageProducer.subscribe((msg) => {
                    var _a, _b;
                    if (!this.closed) {
                        if (msg.type === 'ready' &&
                            this.webSocketStatus.value !== 'connected') {
                            this.webSocketStatus.next('connected');
                        }
                        console.debug('dexie-cloud WebSocket send', msg.type, msg);
                        if (msg.type === 'ready') {
                            // Ok, we are certain to have stored everything up until revision msg.rev.
                            // Update this.rev in case of reconnect - remember where we were and don't just start over!
                            this.rev = msg.rev;
                            // ... and then send along the request to the server so it would also be updated!
                            (_a = this.ws) === null || _a === void 0 ? void 0 : _a.send(TSON.stringify(msg));
                        }
                        else {
                            // If it's not a "ready" message, it's an YMessage.
                            // YMessages can be sent binary encoded.
                            (_b = this.ws) === null || _b === void 0 ? void 0 : _b.send(encodeYMessage(msg));
                        }
                    }
                }));
                if (this.user.isLoggedIn && !isEagerSyncDisabled(this.db)) {
                    this.subscriptions.add(createYClientUpdateObservable(this.db).subscribe(this.db.messageProducer));
                }
            }
            catch (error) {
                this.pauseUntil = new Date(Date.now() + FAIL_RETRY_WAIT_TIME);
            }
        });
    }
}

class InvalidLicenseError extends Error {
    constructor(license) {
        super(license === 'expired'
            ? `License expired`
            : license === 'deactivated'
                ? `User deactivated`
                : 'Invalid license');
        this.name = 'InvalidLicenseError';
        if (license) {
            this.license = license;
        }
    }
}

function sleep$1(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
}
function waitAndReconnectWhenUserDoesSomething(error) {
    return __awaiter(this, void 0, void 0, function* () {
        console.error(`WebSocket observable: error but revive when user does some active thing...`, error);
        // Sleep some seconds...
        yield sleep$1(3000);
        // Wait til user does something (move mouse, tap, scroll, click etc)
        console.debug('waiting for someone to do something');
        yield firstValueFrom(userDoesSomething);
        console.debug('someone did something!');
    });
}
function connectWebSocket(db) {
    var _a;
    if (!((_a = db.cloud.options) === null || _a === void 0 ? void 0 : _a.databaseUrl)) {
        throw new Error(`No database URL to connect WebSocket to`);
    }
    const readyForChangesMessage = db.messageConsumer.readyToServe.pipe(filter((isReady) => isReady), // When consumer is ready for new messages, produce such a message to inform server about it
    switchMap(() => db.getPersistedSyncState()), // We need the info on which server revision we are at:
    filter((syncState) => syncState && syncState.serverRevision), // We wont send anything to server before inital sync has taken place
    switchMap((syncState) => __awaiter(this, void 0, void 0, function* () {
        return ({
            // Produce the message to trigger server to send us new messages to consume:
            type: 'ready',
            rev: syncState.serverRevision,
            realmSetHash: yield computeRealmSetHash(syncState)
        });
    })));
    const messageProducer = merge(readyForChangesMessage, db.messageProducer);
    function createObservable() {
        return db.cloud.persistedSyncState.pipe(filter((syncState) => syncState === null || syncState === void 0 ? void 0 : syncState.serverRevision), // Don't connect before there's no initial sync performed.
        take(1), // Don't continue waking up whenever syncState change
        switchMap((syncState) => db.cloud.currentUser.pipe(map((userLogin) => [userLogin, syncState]))), switchMap(([userLogin, syncState]) => {
            /*if (userLogin.license?.status && userLogin.license.status !== 'ok') {
              throw new InvalidLicenseError();
            }*/
            return userIsReallyActive.pipe(map((isActive) => [isActive ? userLogin : null, syncState]));
        }), switchMap(([userLogin, syncState]) => {
            if ((userLogin === null || userLogin === void 0 ? void 0 : userLogin.isLoggedIn) && !(syncState === null || syncState === void 0 ? void 0 : syncState.realms.includes(userLogin.userId))) {
                // We're in an in-between state when user is logged in but the user's realms are not yet synced.
                // Don't make this change reconnect the websocket just yet. Wait till syncState is updated
                // to iclude the user's realm.
                return db.cloud.persistedSyncState.pipe(filter((syncState) => (syncState === null || syncState === void 0 ? void 0 : syncState.realms.includes(userLogin.userId)) || false), take(1), map((syncState) => [userLogin, syncState]));
            }
            return new BehaviorSubject([userLogin, syncState]);
        }), switchMap((_a) => __awaiter(this, [_a], void 0, function* ([userLogin, syncState]) { return [userLogin, yield computeRealmSetHash(syncState)]; })), distinctUntilChanged(([prevUser, prevHash], [currUser, currHash]) => prevUser === currUser && prevHash === currHash), switchMap(([userLogin, realmSetHash]) => {
            var _a;
            if (!((_a = db.cloud.persistedSyncState) === null || _a === void 0 ? void 0 : _a.value)) {
                // Restart the flow if persistedSyncState is not yet available.
                return createObservable();
            }
            // Let server end query changes from last entry of same client-ID and forward.
            // If no new entries, server won't bother the client. If new entries, server sends only those
            // and the baseRev of the last from same client-ID.
            if (userLogin) {
                return new WSObservable(db, db.cloud.persistedSyncState.value.serverRevision, db.cloud.persistedSyncState.value.yServerRevision, realmSetHash, db.cloud.persistedSyncState.value.clientIdentity, messageProducer, db.cloud.webSocketStatus, userLogin);
            }
            else {
                return from([]);
            }
        }), catchError((error) => {
            if ((error === null || error === void 0 ? void 0 : error.name) === 'TokenExpiredError') {
                console.debug('WebSocket observable: Token expired. Refreshing token...');
                return of(true).pipe(switchMap(() => __awaiter(this, void 0, void 0, function* () {
                    // Refresh access token
                    const user = yield db.getCurrentUser();
                    const refreshedLogin = yield refreshAccessToken(db.cloud.options.databaseUrl, user);
                    // Persist updated access token
                    yield db.table('$logins').update(user.userId, {
                        accessToken: refreshedLogin.accessToken,
                        accessTokenExpiration: refreshedLogin.accessTokenExpiration,
                        claims: refreshedLogin.claims,
                        license: refreshedLogin.license,
                        data: refreshedLogin.data
                    });
                })), switchMap(() => createObservable()));
            }
            else {
                return throwError(() => error);
            }
        }), catchError((error) => {
            db.cloud.webSocketStatus.next("error");
            if (error instanceof InvalidLicenseError) {
                // Don't retry. Just throw and don't try connect again.
                return throwError(() => error);
            }
            return from(waitAndReconnectWhenUserDoesSomething(error)).pipe(switchMap(() => createObservable()));
        }));
    }
    return createObservable().subscribe({
        next: (msg) => {
            if (msg) {
                console.debug('WS got message', msg);
                db.messageConsumer.enqueue(msg);
            }
        },
        error: (error) => {
            console.error('WS got error', error);
        },
        complete: () => {
            console.debug('WS observable completed');
        },
    });
}

function isSyncNeeded(db) {
    return __awaiter(this, void 0, void 0, function* () {
        var _a;
        return ((_a = db.cloud.options) === null || _a === void 0 ? void 0 : _a.databaseUrl) && db.cloud.schema
            ? yield sync(db, db.cloud.options, db.cloud.schema, { justCheckIfNeeded: true })
            : false;
    });
}

const ongoingSyncs = new WeakMap();
function syncIfPossible(db, cloudOptions, cloudSchema, options) {
    const ongoing = ongoingSyncs.get(db);
    if (ongoing) {
        if (ongoing.pull || (options === null || options === void 0 ? void 0 : options.purpose) === 'push') {
            console.debug('syncIfPossible(): returning the ongoing sync promise.');
            return ongoing.promise;
        }
        else {
            // Ongoing sync may never do anything in case there are no outstanding changes
            // to sync (because its purpose was "push" not "pull")
            // Now, however, we are asked to do a sync with the purpose of "pull"
            // We want to optimize here. We must wait for the ongoing to complete
            // and then, if the ongoing sync never resulted in a sync request,
            // we must redo the sync.
            // To inspect what is happening in the ongoing request, let's subscribe
            // to db.cloud.syncState and look for if it is doing any "pulling" phase:
            let hasPullTakenPlace = false;
            const subscription = db.cloud.syncState.subscribe((syncState) => {
                if (syncState.phase === 'pulling') {
                    hasPullTakenPlace = true;
                }
            });
            // Ok, so now we are watching. At the same time, wait for the ongoing to complete
            // and when it has completed, check if we're all set or if we need to redo
            // the call:
            return (ongoing.promise
                // This is a finally block but we are still running tests on
                // browsers that don't support it, so need to do it like this:
                .then(() => {
                subscription.unsubscribe();
            })
                .catch((error) => {
                subscription.unsubscribe();
                return Promise.reject(error);
            })
                .then(() => {
                if (!hasPullTakenPlace) {
                    // No pull took place in the ongoing sync but the caller had "pull" as
                    // an explicit purpose of this call - so we need to redo the call!
                    return syncIfPossible(db, cloudOptions, cloudSchema, options);
                }
            }));
        }
    }
    const promise = _syncIfPossible();
    ongoingSyncs.set(db, { promise, pull: (options === null || options === void 0 ? void 0 : options.purpose) !== 'push' });
    return promise;
    function _syncIfPossible() {
        return __awaiter(this, void 0, void 0, function* () {
            try {
                // Check if should delay sync due to ratelimit:
                yield checkSyncRateLimitDelay(db);
                yield performGuardedJob(db, CURRENT_SYNC_WORKER, () => sync(db, cloudOptions, cloudSchema, options));
                ongoingSyncs.delete(db);
                console.debug('Done sync');
            }
            catch (error) {
                ongoingSyncs.delete(db);
                console.error(`Failed to sync client changes`, error);
                throw error; // Make sure we rethrow error so that sync event is retried.
                // I don't think we should setTimout or so here.
                // Unless server tells us to in some response.
                // Then we could follow that advice but not by waiting here but by registering
                // Something that triggers an event listened to in startPushWorker()
            }
        });
    }
}

const SECONDS = 1000;

function LocalSyncWorker(db, cloudOptions, cloudSchema) {
    let localSyncEventSubscription = null;
    let cancelToken = { cancelled: false };
    let nextRetryTime = 0;
    let syncStartTime = 0;
    function syncAndRetry(retryNum = 1) {
        // Use setTimeout() to get onto a clean stack and
        // break free from possible active transaction:
        setTimeout(() => {
            const purpose = pullSignalled ? 'pull' : 'push';
            syncStartTime = Date.now();
            syncIfPossible(db, cloudOptions, cloudSchema, {
                cancelToken,
                retryImmediatelyOnFetchError: true, // workaround for "net::ERR_NETWORK_CHANGED" in chrome.
                purpose,
            }).then(() => {
                if (cancelToken.cancelled) {
                    stop();
                }
                else {
                    if (pullSignalled || pushSignalled) {
                        // If we have signalled for more sync, do it now.
                        pullSignalled = false;
                        pushSignalled = false;
                        return syncAndRetry();
                    }
                }
                ongoingSync = false;
                nextRetryTime = 0;
                syncStartTime = 0;
            }).catch((error) => {
                console.error('error in syncIfPossible()', error);
                if (cancelToken.cancelled) {
                    stop();
                    ongoingSync = false;
                    nextRetryTime = 0;
                    syncStartTime = 0;
                }
                else if (retryNum < 5) {
                    // Mimic service worker sync event but a bit more eager: retry 4 times
                    // * first retry after 20 seconds
                    // * second retry 40 seconds later
                    // * third retry 5 minutes later
                    // * last retry 15 minutes later
                    const retryIn = [0, 20, 40, 300, 900][retryNum] * SECONDS;
                    nextRetryTime = Date.now() + retryIn;
                    syncStartTime = 0;
                    setTimeout(() => syncAndRetry(retryNum + 1), retryIn);
                }
                else {
                    ongoingSync = false;
                    nextRetryTime = 0;
                    syncStartTime = 0;
                }
            });
        }, 0);
    }
    let pullSignalled = false;
    let pushSignalled = false;
    let ongoingSync = false;
    const consumer = (purpose) => {
        if (cancelToken.cancelled)
            return;
        if (purpose === 'pull') {
            pullSignalled = true;
        }
        if (purpose === 'push') {
            pushSignalled = true;
        }
        if (ongoingSync) {
            if (nextRetryTime) {
                console.debug(`Sync is paused until ${new Date(nextRetryTime).toISOString()} due to error in last sync attempt`);
            }
            else if (syncStartTime > 0 && Date.now() - syncStartTime > 20 * SECONDS) {
                console.debug(`An existing sync operation is taking more than 20 seconds. Will resync when done.`);
            }
            return;
        }
        ongoingSync = true;
        syncAndRetry();
    };
    const start = () => {
        // Sync eagerly whenever a change has happened (+ initially when there's no syncState yet)
        // This initial subscribe will also trigger an sync also now.
        console.debug('Starting LocalSyncWorker', db.localSyncEvent['id']);
        localSyncEventSubscription = db.localSyncEvent.subscribe(({ purpose }) => {
            consumer(purpose || 'pull');
        });
    };
    const stop = () => {
        console.debug('Stopping LocalSyncWorker');
        cancelToken.cancelled = true;
        if (localSyncEventSubscription)
            localSyncEventSubscription.unsubscribe();
    };
    return {
        start,
        stop,
    };
}

function updateSchemaFromOptions(schema, options) {
    if (schema && options) {
        if (options.unsyncedTables) {
            for (const tableName of options.unsyncedTables) {
                if (schema[tableName]) {
                    schema[tableName].markedForSync = false;
                }
            }
        }
    }
}

function verifySchema(db) {
    var _a, _b;
    for (const table of db.tables) {
        if ((_b = (_a = db.cloud.schema) === null || _a === void 0 ? void 0 : _a[table.name]) === null || _b === void 0 ? void 0 : _b.markedForSync) {
            if (table.schema.primKey.auto) {
                throw new Dexie.SchemaError(`Table ${table.name} is both autoIncremented and synced. ` +
                    `Use db.cloud.configure({unsyncedTables: [${JSON.stringify(table.name)}]}) to blacklist it from sync`);
            }
            if (!table.schema.primKey.keyPath) {
                throw new Dexie.SchemaError(`Table ${table.name} cannot be both synced and outbound. ` +
                    `Use db.cloud.configure({unsyncedTables: [${JSON.stringify(table.name)}]}) to blacklist it from sync`);
            }
        }
    }
}

var n,l$1,u$1,i$1,r$1,o$1,e$1,f$1,c$1,s$1,a$1,p$1={},v$1=[],y=/acit|ex(?:s|g|n|p|$)|rph|grid|ows|mnc|ntw|ine[ch]|zoo|^ord|itera/i,w$1=Array.isArray;function d$1(n,l){for(var u in l)n[u]=l[u];return n}function g(n){n&&n.parentNode&&n.parentNode.removeChild(n);}function _$1(l,u,t){var i,r,o,e={};for(o in u)"key"==o?i=u[o]:"ref"==o?r=u[o]:e[o]=u[o];if(arguments.length>2&&(e.children=arguments.length>3?n.call(arguments,2):t),"function"==typeof l&&null!=l.defaultProps)for(o in l.defaultProps) void 0===e[o]&&(e[o]=l.defaultProps[o]);return m$1(l,e,i,r,null)}function m$1(n,t,i,r,o){var e={type:n,props:t,key:i,ref:r,__k:null,__:null,__b:0,__e:null,__c:null,constructor:void 0,__v:null==o?++u$1:o,__i:-1,__u:0};return null==o&&null!=l$1.vnode&&l$1.vnode(e),e}function k$1(n){return n.children}function x(n,l){this.props=n,this.context=l;}function S(n,l){if(null==l)return n.__?S(n.__,n.__i+1):null;for(var u;l<n.__k.length;l++)if(null!=(u=n.__k[l])&&null!=u.__e)return u.__e;return "function"==typeof n.type?S(n):null}function C$1(n){var l,u;if(null!=(n=n.__)&&null!=n.__c){for(n.__e=n.__c.base=null,l=0;l<n.__k.length;l++)if(null!=(u=n.__k[l])&&null!=u.__e){n.__e=n.__c.base=u.__e;break}return C$1(n)}}function M(n){(!n.__d&&(n.__d=true)&&i$1.push(n)&&!$.__r++||r$1!=l$1.debounceRendering)&&((r$1=l$1.debounceRendering)||o$1)($);}function $(){for(var n,u,t,r,o,f,c,s=1;i$1.length;)i$1.length>s&&i$1.sort(e$1),n=i$1.shift(),s=i$1.length,n.__d&&(t=void 0,r=void 0,o=(r=(u=n).__v).__e,f=[],c=[],u.__P&&((t=d$1({},r)).__v=r.__v+1,l$1.vnode&&l$1.vnode(t),O(u.__P,t,r,u.__n,u.__P.namespaceURI,32&r.__u?[o]:null,f,null==o?S(r):o,!!(32&r.__u),c),t.__v=r.__v,t.__.__k[t.__i]=t,N(f,t,c),r.__e=r.__=null,t.__e!=o&&C$1(t)));$.__r=0;}function I(n,l,u,t,i,r,o,e,f,c,s){var a,h,y,w,d,g,_,m=t&&t.__k||v$1,b=l.length;for(f=P(u,l,m,f,b),a=0;a<b;a++)null!=(y=u.__k[a])&&(h=-1==y.__i?p$1:m[y.__i]||p$1,y.__i=a,g=O(n,y,h,i,r,o,e,f,c,s),w=y.__e,y.ref&&h.ref!=y.ref&&(h.ref&&B$1(h.ref,null,y),s.push(y.ref,y.__c||w,y)),null==d&&null!=w&&(d=w),(_=!!(4&y.__u))||h.__k===y.__k?f=A$1(y,f,n,_):"function"==typeof y.type&&void 0!==g?f=g:w&&(f=w.nextSibling),y.__u&=-7);return u.__e=d,f}function P(n,l,u,t,i){var r,o,e,f,c,s=u.length,a=s,h=0;for(n.__k=new Array(i),r=0;r<i;r++)null!=(o=l[r])&&"boolean"!=typeof o&&"function"!=typeof o?("string"==typeof o||"number"==typeof o||"bigint"==typeof o||o.constructor==String?o=n.__k[r]=m$1(null,o,null,null,null):w$1(o)?o=n.__k[r]=m$1(k$1,{children:o},null,null,null):null==o.constructor&&o.__b>0?o=n.__k[r]=m$1(o.type,o.props,o.key,o.ref?o.ref:null,o.__v):n.__k[r]=o,f=r+h,o.__=n,o.__b=n.__b+1,-1!=(c=o.__i=L(o,u,f,a))&&(a--,(e=u[c])&&(e.__u|=2)),null==e||null==e.__v?(-1==c&&(i>s?h--:i<s&&h++),"function"!=typeof o.type&&(o.__u|=4)):c!=f&&(c==f-1?h--:c==f+1?h++:(c>f?h--:h++,o.__u|=4))):n.__k[r]=null;if(a)for(r=0;r<s;r++)null!=(e=u[r])&&0==(2&e.__u)&&(e.__e==t&&(t=S(e)),D$1(e,e));return t}function A$1(n,l,u,t){var i,r;if("function"==typeof n.type){for(i=n.__k,r=0;i&&r<i.length;r++)i[r]&&(i[r].__=n,l=A$1(i[r],l,u,t));return l}n.__e!=l&&(t&&(l&&n.type&&!l.parentNode&&(l=S(n)),u.insertBefore(n.__e,l||null)),l=n.__e);do{l=l&&l.nextSibling;}while(null!=l&&8==l.nodeType);return l}function L(n,l,u,t){var i,r,o,e=n.key,f=n.type,c=l[u],s=null!=c&&0==(2&c.__u);if(null===c&&null==e||s&&e==c.key&&f==c.type)return u;if(t>(s?1:0))for(i=u-1,r=u+1;i>=0||r<l.length;)if(null!=(c=l[o=i>=0?i--:r++])&&0==(2&c.__u)&&e==c.key&&f==c.type)return o;return  -1}function T$1(n,l,u){"-"==l[0]?n.setProperty(l,null==u?"":u):n[l]=null==u?"":"number"!=typeof u||y.test(l)?u:u+"px";}function j$1(n,l,u,t,i){var r,o;n:if("style"==l)if("string"==typeof u)n.style.cssText=u;else {if("string"==typeof t&&(n.style.cssText=t=""),t)for(l in t)u&&l in u||T$1(n.style,l,"");if(u)for(l in u)t&&u[l]==t[l]||T$1(n.style,l,u[l]);}else if("o"==l[0]&&"n"==l[1])r=l!=(l=l.replace(f$1,"$1")),o=l.toLowerCase(),l=o in n||"onFocusOut"==l||"onFocusIn"==l?o.slice(2):l.slice(2),n.l||(n.l={}),n.l[l+r]=u,u?t?u.u=t.u:(u.u=c$1,n.addEventListener(l,r?a$1:s$1,r)):n.removeEventListener(l,r?a$1:s$1,r);else {if("http://www.w3.org/2000/svg"==i)l=l.replace(/xlink(H|:h)/,"h").replace(/sName$/,"s");else if("width"!=l&&"height"!=l&&"href"!=l&&"list"!=l&&"form"!=l&&"tabIndex"!=l&&"download"!=l&&"rowSpan"!=l&&"colSpan"!=l&&"role"!=l&&"popover"!=l&&l in n)try{n[l]=null==u?"":u;break n}catch(n){}"function"==typeof u||(null==u||false===u&&"-"!=l[4]?n.removeAttribute(l):n.setAttribute(l,"popover"==l&&1==u?"":u));}}function F(n){return function(u){if(this.l){var t=this.l[u.type+n];if(null==u.t)u.t=c$1++;else if(u.t<t.u)return;return t(l$1.event?l$1.event(u):u)}}}function O(n,u,t,i,r,o,e,f,c,s){var a,h,p,v,y,_,m,b,S,C,M,$,P,A,H,L,T,j=u.type;if(null!=u.constructor)return null;128&t.__u&&(c=!!(32&t.__u),o=[f=u.__e=t.__e]),(a=l$1.__b)&&a(u);n:if("function"==typeof j)try{if(b=u.props,S="prototype"in j&&j.prototype.render,C=(a=j.contextType)&&i[a.__c],M=a?C?C.props.value:a.__:i,t.__c?m=(h=u.__c=t.__c).__=h.__E:(S?u.__c=h=new j(b,M):(u.__c=h=new x(b,M),h.constructor=j,h.render=E),C&&C.sub(h),h.state||(h.state={}),h.__n=i,p=h.__d=!0,h.__h=[],h._sb=[]),S&&null==h.__s&&(h.__s=h.state),S&&null!=j.getDerivedStateFromProps&&(h.__s==h.state&&(h.__s=d$1({},h.__s)),d$1(h.__s,j.getDerivedStateFromProps(b,h.__s))),v=h.props,y=h.state,h.__v=u,p)S&&null==j.getDerivedStateFromProps&&null!=h.componentWillMount&&h.componentWillMount(),S&&null!=h.componentDidMount&&h.__h.push(h.componentDidMount);else {if(S&&null==j.getDerivedStateFromProps&&b!==v&&null!=h.componentWillReceiveProps&&h.componentWillReceiveProps(b,M),u.__v==t.__v||!h.__e&&null!=h.shouldComponentUpdate&&!1===h.shouldComponentUpdate(b,h.__s,M)){for(u.__v!=t.__v&&(h.props=b,h.state=h.__s,h.__d=!1),u.__e=t.__e,u.__k=t.__k,u.__k.some(function(n){n&&(n.__=u);}),$=0;$<h._sb.length;$++)h.__h.push(h._sb[$]);h._sb=[],h.__h.length&&e.push(h);break n}null!=h.componentWillUpdate&&h.componentWillUpdate(b,h.__s,M),S&&null!=h.componentDidUpdate&&h.__h.push(function(){h.componentDidUpdate(v,y,_);});}if(h.context=M,h.props=b,h.__P=n,h.__e=!1,P=l$1.__r,A=0,S){for(h.state=h.__s,h.__d=!1,P&&P(u),a=h.render(h.props,h.state,h.context),H=0;H<h._sb.length;H++)h.__h.push(h._sb[H]);h._sb=[];}else do{h.__d=!1,P&&P(u),a=h.render(h.props,h.state,h.context),h.state=h.__s;}while(h.__d&&++A<25);h.state=h.__s,null!=h.getChildContext&&(i=d$1(d$1({},i),h.getChildContext())),S&&!p&&null!=h.getSnapshotBeforeUpdate&&(_=h.getSnapshotBeforeUpdate(v,y)),L=a,null!=a&&a.type===k$1&&null==a.key&&(L=V(a.props.children)),f=I(n,w$1(L)?L:[L],u,t,i,r,o,e,f,c,s),h.base=u.__e,u.__u&=-161,h.__h.length&&e.push(h),m&&(h.__E=h.__=null);}catch(n){if(u.__v=null,c||null!=o)if(n.then){for(u.__u|=c?160:128;f&&8==f.nodeType&&f.nextSibling;)f=f.nextSibling;o[o.indexOf(f)]=null,u.__e=f;}else {for(T=o.length;T--;)g(o[T]);z$1(u);}else u.__e=t.__e,u.__k=t.__k,n.then||z$1(u);l$1.__e(n,u,t);}else null==o&&u.__v==t.__v?(u.__k=t.__k,u.__e=t.__e):f=u.__e=q(t.__e,u,t,i,r,o,e,c,s);return (a=l$1.diffed)&&a(u),128&u.__u?void 0:f}function z$1(n){n&&n.__c&&(n.__c.__e=true),n&&n.__k&&n.__k.forEach(z$1);}function N(n,u,t){for(var i=0;i<t.length;i++)B$1(t[i],t[++i],t[++i]);l$1.__c&&l$1.__c(u,n),n.some(function(u){try{n=u.__h,u.__h=[],n.some(function(n){n.call(u);});}catch(n){l$1.__e(n,u.__v);}});}function V(n){return "object"!=typeof n||null==n||n.__b&&n.__b>0?n:w$1(n)?n.map(V):d$1({},n)}function q(u,t,i,r,o,e,f,c,s){var a,h,v,y,d,_,m,b=i.props||p$1,k=t.props,x=t.type;if("svg"==x?o="http://www.w3.org/2000/svg":"math"==x?o="http://www.w3.org/1998/Math/MathML":o||(o="http://www.w3.org/1999/xhtml"),null!=e)for(a=0;a<e.length;a++)if((d=e[a])&&"setAttribute"in d==!!x&&(x?d.localName==x:3==d.nodeType)){u=d,e[a]=null;break}if(null==u){if(null==x)return document.createTextNode(k);u=document.createElementNS(o,x,k.is&&k),c&&(l$1.__m&&l$1.__m(t,e),c=false),e=null;}if(null==x)b===k||c&&u.data==k||(u.data=k);else {if(e=e&&n.call(u.childNodes),!c&&null!=e)for(b={},a=0;a<u.attributes.length;a++)b[(d=u.attributes[a]).name]=d.value;for(a in b)if(d=b[a],"children"==a);else if("dangerouslySetInnerHTML"==a)v=d;else if(!(a in k)){if("value"==a&&"defaultValue"in k||"checked"==a&&"defaultChecked"in k)continue;j$1(u,a,null,d,o);}for(a in k)d=k[a],"children"==a?y=d:"dangerouslySetInnerHTML"==a?h=d:"value"==a?_=d:"checked"==a?m=d:c&&"function"!=typeof d||b[a]===d||j$1(u,a,d,b[a],o);if(h)c||v&&(h.__html==v.__html||h.__html==u.innerHTML)||(u.innerHTML=h.__html),t.__k=[];else if(v&&(u.innerHTML=""),I("template"==t.type?u.content:u,w$1(y)?y:[y],t,i,r,"foreignObject"==x?"http://www.w3.org/1999/xhtml":o,e,f,e?e[0]:i.__k&&S(i,0),c,s),null!=e)for(a=e.length;a--;)g(e[a]);c||(a="value","progress"==x&&null==_?u.removeAttribute("value"):null!=_&&(_!==u[a]||"progress"==x&&!_||"option"==x&&_!=b[a])&&j$1(u,a,_,b[a],o),a="checked",null!=m&&m!=u[a]&&j$1(u,a,m,b[a],o));}return u}function B$1(n,u,t){try{if("function"==typeof n){var i="function"==typeof n.__u;i&&n.__u(),i&&null==u||(n.__u=n(u));}else n.current=u;}catch(n){l$1.__e(n,t);}}function D$1(n,u,t){var i,r;if(l$1.unmount&&l$1.unmount(n),(i=n.ref)&&(i.current&&i.current!=n.__e||B$1(i,null,u)),null!=(i=n.__c)){if(i.componentWillUnmount)try{i.componentWillUnmount();}catch(n){l$1.__e(n,u);}i.base=i.__P=null;}if(i=n.__k)for(r=0;r<i.length;r++)i[r]&&D$1(i[r],u,t||"function"!=typeof n.type);t||g(n.__e),n.__c=n.__=n.__e=void 0;}function E(n,l,u){return this.constructor(n,u)}function G(u,t,i){var r,o,e,f;t==document&&(t=document.documentElement),l$1.__&&l$1.__(u,t),o=(r="function"=="undefined")?null:t.__k,e=[],f=[],O(t,u=(t).__k=_$1(k$1,null,[u]),o||p$1,p$1,t.namespaceURI,o?null:t.firstChild?n.call(t.childNodes):null,e,o?o.__e:t.firstChild,r,f),N(e,u,f);}n=v$1.slice,l$1={__e:function(n,l,u,t){for(var i,r,o;l=l.__;)if((i=l.__c)&&!i.__)try{if((r=i.constructor)&&null!=r.getDerivedStateFromError&&(i.setState(r.getDerivedStateFromError(n)),o=i.__d),null!=i.componentDidCatch&&(i.componentDidCatch(n,t||{}),o=i.__d),o)return i.__E=i}catch(l){n=l;}throw n}},u$1=0,x.prototype.setState=function(n,l){var u;u=null!=this.__s&&this.__s!=this.state?this.__s:this.__s=d$1({},this.state),"function"==typeof n&&(n=n(d$1({},u),this.props)),n&&d$1(u,n),null!=n&&this.__v&&(l&&this._sb.push(l),M(this));},x.prototype.forceUpdate=function(n){this.__v&&(this.__e=true,n&&this.__h.push(n),M(this));},x.prototype.render=k$1,i$1=[],o$1="function"==typeof Promise?Promise.prototype.then.bind(Promise.resolve()):setTimeout,e$1=function(n,l){return n.__v.__b-l.__v.__b},$.__r=0,f$1=/(PointerCapture)$|Capture$/i,c$1=0,s$1=F(false),a$1=F(true);

const Styles = {
    Alert: {
        error: {
            color: "red",
            fontWeight: "bold"
        },
        warning: {
            color: "#f80",
            fontWeight: "bold"
        },
        info: {
            color: "black"
        }
    },
    Darken: {
        position: "fixed",
        top: 0,
        left: 0,
        opacity: 0.5,
        backgroundColor: "#000",
        width: "100vw",
        height: "100vh",
        zIndex: 150,
        webkitBackdropFilter: "blur(2px)",
        backdropFilter: "blur(2px)",
    },
    DialogOuter: {
        position: "fixed",
        top: 0,
        left: 0,
        width: "100vw",
        height: "100vh",
        zIndex: 150,
        alignItems: "center",
        display: "flex",
        justifyContent: "center",
        padding: "16px",
        boxSizing: "border-box"
    },
    DialogInner: {
        position: "relative",
        color: "#222",
        backgroundColor: "#fff",
        padding: "24px",
        marginBottom: "2em",
        maxWidth: "400px",
        width: "100%",
        maxHeight: "90%",
        overflowY: "auto",
        border: "3px solid #3d3d5d",
        borderRadius: "8px",
        boxShadow: "0 0 80px 10px #666",
        fontFamily: "sans-serif",
        boxSizing: "border-box"
    },
    Input: {
        height: "35px",
        width: "100%",
        maxWidth: "100%",
        borderColor: "#ccf4",
        outline: "none",
        fontSize: "16px",
        padding: "8px",
        boxSizing: "border-box",
        backgroundColor: "#f9f9f9",
        borderRadius: "4px",
        border: "1px solid #ccc",
        marginTop: "6px",
        fontFamily: "inherit"
    },
    Button: {
        padding: "10px 20px",
        margin: "0 4px",
        border: "1px solid #d1d5db",
        borderRadius: "6px",
        backgroundColor: "#ffffff",
        cursor: "pointer",
        fontSize: "14px",
        fontWeight: "500",
        color: "#374151",
        transition: "all 0.2s ease"
    },
    PrimaryButton: {
        padding: "10px 20px",
        margin: "0 4px",
        border: "1px solid #3b82f6",
        borderRadius: "6px",
        backgroundColor: "#3b82f6",
        color: "white",
        cursor: "pointer",
        fontSize: "14px",
        fontWeight: "500",
        transition: "all 0.2s ease"
    },
    ButtonsDiv: {
        display: "flex",
        justifyContent: "flex-end",
        gap: "12px",
        marginTop: "24px",
        paddingTop: "20px"
    },
    Label: {
        display: "block",
        marginBottom: "12px",
        fontSize: "14px",
        fontWeight: "500",
        color: "#333"
    },
    WindowHeader: {
        margin: "0 0 20px 0",
        fontSize: "18px",
        fontWeight: "600",
        color: "#333",
        borderBottom: "1px solid #eee",
        paddingBottom: "10px"
    }
};

function Dialog({ children, className }) {
    return (_$1("div", { className: `dexie-dialog ${className || ''}` },
        _$1("div", { style: Styles.Darken }),
        _$1("div", { style: Styles.DialogOuter },
            _$1("div", { style: Styles.DialogInner }, children))));
}

var t,r,u,i,o=0,f=[],c=l$1,e=c.__b,a=c.__r,v=c.diffed,l=c.__c,m=c.unmount,s=c.__;function p(n,t){c.__h&&c.__h(r,n,o||t),o=0;var u=r.__H||(r.__H={__:[],__h:[]});return n>=u.__.length&&u.__.push({}),u.__[n]}function d(n){return o=1,h(D,n)}function h(n,u,i){var o=p(t++,2);if(o.t=n,!o.__c&&(o.__=[D(void 0,u),function(n){var t=o.__N?o.__N[0]:o.__[0],r=o.t(t,n);t!==r&&(o.__N=[r,o.__[1]],o.__c.setState({}));}],o.__c=r,!r.__f)){var f=function(n,t,r){if(!o.__c.__H)return  true;var u=o.__c.__H.__.filter(function(n){return !!n.__c});if(u.every(function(n){return !n.__N}))return !c||c.call(this,n,t,r);var i=o.__c.props!==n;return u.forEach(function(n){if(n.__N){var t=n.__[0];n.__=n.__N,n.__N=void 0,t!==n.__[0]&&(i=true);}}),c&&c.call(this,n,t,r)||i};r.__f=true;var c=r.shouldComponentUpdate,e=r.componentWillUpdate;r.componentWillUpdate=function(n,t,r){if(this.__e){var u=c;c=void 0,f(n,t,r),c=u;}e&&e.call(this,n,t,r);},r.shouldComponentUpdate=f;}return o.__N||o.__}function _(n,u){var i=p(t++,4);!c.__s&&C(i.__H,u)&&(i.__=n,i.u=u,r.__h.push(i));}function A(n){return o=5,T(function(){return {current:n}},[])}function T(n,r){var u=p(t++,7);return C(u.__H,r)&&(u.__=n(),u.__H=r,u.__h=n),u.__}function j(){for(var n;n=f.shift();)if(n.__P&&n.__H)try{n.__H.__h.forEach(z),n.__H.__h.forEach(B),n.__H.__h=[];}catch(t){n.__H.__h=[],c.__e(t,n.__v);}}c.__b=function(n){r=null,e&&e(n);},c.__=function(n,t){n&&t.__k&&t.__k.__m&&(n.__m=t.__k.__m),s&&s(n,t);},c.__r=function(n){a&&a(n),t=0;var i=(r=n.__c).__H;i&&(u===r?(i.__h=[],r.__h=[],i.__.forEach(function(n){n.__N&&(n.__=n.__N),n.u=n.__N=void 0;})):(i.__h.forEach(z),i.__h.forEach(B),i.__h=[],t=0)),u=r;},c.diffed=function(n){v&&v(n);var t=n.__c;t&&t.__H&&(t.__H.__h.length&&(1!==f.push(t)&&i===c.requestAnimationFrame||((i=c.requestAnimationFrame)||w)(j)),t.__H.__.forEach(function(n){n.u&&(n.__H=n.u),n.u=void 0;})),u=r=null;},c.__c=function(n,t){t.some(function(n){try{n.__h.forEach(z),n.__h=n.__h.filter(function(n){return !n.__||B(n)});}catch(r){t.some(function(n){n.__h&&(n.__h=[]);}),t=[],c.__e(r,n.__v);}}),l&&l(n,t);},c.unmount=function(n){m&&m(n);var t,r=n.__c;r&&r.__H&&(r.__H.__.forEach(function(n){try{z(n);}catch(n){t=n;}}),r.__H=void 0,t&&c.__e(t,r.__v));};var k="function"==typeof requestAnimationFrame;function w(n){var t,r=function(){clearTimeout(u),k&&cancelAnimationFrame(t),setTimeout(n);},u=setTimeout(r,35);k&&(t=requestAnimationFrame(r));}function z(n){var t=r,u=n.__c;"function"==typeof u&&(n.__c=void 0,u()),r=t;}function B(n){var t=r;n.__c=n.__(),r=t;}function C(n,t){return !n||n.length!==t.length||t.some(function(t,r){return t!==n[r]})}function D(n,t){return "function"==typeof t?t(n):t}

/** Resolve a message template with parameters.
 *
 * Example:
 *  resolveText({
 *    message: "Hello {name}!",
 *    messageCode: "HELLO",
 *    messageParams: {name: "David"}
 *  }) => "Hello David!"
 *
 * @param message Template message with {vars} in it.
 * @param messageCode Unique code for the message. Can be used for translation.
 * @param messageParams Parameters to be used in the message.
 * @returns A final message where parameters have been replaced with values.
 */
function resolveText({ message, messageCode, messageParams }) {
    return message.replace(/\{\w+\}/ig, n => messageParams[n.substring(1, n.length - 1)]);
}

const OTP_LENGTH = 8;
function LoginDialog({ title, type, alerts, fields, submitLabel, cancelLabel, onCancel, onSubmit, }) {
    const [params, setParams] = d({});
    const firstFieldRef = A(null);
    _(() => { var _a; return (_a = firstFieldRef.current) === null || _a === void 0 ? void 0 : _a.focus(); }, []);
    return (_$1(Dialog, { className: "dxc-login-dlg" },
        _$1(k$1, null,
            _$1("h3", { style: Styles.WindowHeader }, title),
            alerts.map((alert) => (_$1("p", { style: Styles.Alert[alert.type] }, resolveText(alert)))),
            _$1("form", { onSubmit: (ev) => {
                    ev.preventDefault();
                    onSubmit(params);
                } }, Object.entries(fields).map(([fieldName, { type, label, placeholder }], idx) => (_$1("label", { style: Styles.Label, key: idx },
                label ? `${label}: ` : '',
                _$1("input", { ref: idx === 0 ? firstFieldRef : undefined, type: type, name: fieldName, autoComplete: "on", style: Styles.Input, autoFocus: true, placeholder: placeholder, value: params[fieldName] || '', onInput: (ev) => {
                        var _a;
                        const value = valueTransformer(type, (_a = ev.target) === null || _a === void 0 ? void 0 : _a['value']);
                        let updatedParams = Object.assign(Object.assign({}, params), { [fieldName]: value });
                        setParams(updatedParams);
                        if (type === 'otp' && (value === null || value === void 0 ? void 0 : value.trim().length) === OTP_LENGTH) {
                            // Auto-submit when OTP is filled in.
                            onSubmit(updatedParams);
                        }
                    } })))))),
        _$1("div", { style: Styles.ButtonsDiv },
            _$1(k$1, null,
                _$1("button", { type: "submit", style: Styles.PrimaryButton, onClick: () => onSubmit(params) }, submitLabel),
                cancelLabel && (_$1("button", { style: Styles.Button, onClick: onCancel }, cancelLabel))))));
}
function valueTransformer(type, value) {
    switch (type) {
        case 'email':
            return value.toLowerCase();
        case 'otp':
            return value.toUpperCase();
        default:
            return value;
    }
}

class LoginGui extends x {
    constructor(props) {
        super(props);
        this.observer = (userInteraction) => this.setState({ userInteraction });
        this.state = { userInteraction: undefined };
    }
    componentDidMount() {
        this.subscription = from(this.props.db.cloud.userInteraction).subscribe(this.observer);
    }
    componentWillUnmount() {
        if (this.subscription) {
            this.subscription.unsubscribe();
            delete this.subscription;
        }
    }
    render(props, { userInteraction }) {
        if (!userInteraction)
            return null;
        //if (props.db.cloud.userInteraction.observers.length > 1) return null; // Someone else subscribes.
        return _$1(LoginDialog, Object.assign({}, userInteraction));
    }
}
function setupDefaultGUI(db) {
    let closed = false;
    const el = document.createElement('div');
    if (document.body) {
        document.body.appendChild(el);
        G(_$1(LoginGui, { db: db.vip }), el);
    }
    else {
        addEventListener('DOMContentLoaded', () => {
            if (!closed) {
                document.body.appendChild(el);
                G(_$1(LoginGui, { db: db.vip }), el);
            }
        });
    }
    return {
        unsubscribe() {
            try {
                el.remove();
            }
            catch (_a) { }
            closed = true;
        },
        get closed() {
            return closed;
        }
    };
}

function associate(factory) {
    const wm = new WeakMap();
    return (x) => {
        let rv = wm.get(x);
        if (!rv) {
            rv = factory(x);
            wm.set(x, rv);
        }
        return rv;
    };
}

const getCurrentUserEmitter = associate((db) => new BehaviorSubject(UNAUTHORIZED_USER));

function computeSyncState(db) {
    let _prevStatus = db.cloud.webSocketStatus.value;
    const lazyWebSocketStatus = db.cloud.webSocketStatus.pipe(switchMap((status) => {
        const prevStatus = _prevStatus;
        _prevStatus = status;
        const rv = of(status);
        switch (status) {
            // A normal scenario is that the WS reconnects and falls shortly in disconnected-->connection-->connected.
            // Don't distract user with this unless these things take more time than normal:
            // Only show disconnected if disconnected more than 500ms, or if we can
            // see that the user is indeed not active.
            case 'disconnected':
                return userIsActive.value ? rv.pipe(debounceTime(500)) : rv;
            // Only show connecting if previous state was 'not-started' or 'error', or if
            // the time it takes to connect goes beyond 4 seconds.
            case 'connecting':
                return prevStatus === 'not-started' || prevStatus === 'error'
                    ? rv
                    : rv.pipe(debounceTime(4000));
            default:
                return rv;
        }
    }));
    return combineLatest([
        lazyWebSocketStatus,
        db.syncStateChangedEvent.pipe(startWith({ phase: 'initial' })),
        getCurrentUserEmitter(db.dx._novip),
        userIsReallyActive
    ]).pipe(map(([status, syncState, user, userIsActive]) => {
        var _a;
        if (((_a = user.license) === null || _a === void 0 ? void 0 : _a.status) && user.license.status !== 'ok') {
            return {
                phase: 'offline',
                status: 'offline',
                license: user.license.status
            };
        }
        let { phase, error, progress } = syncState;
        let adjustedStatus = status;
        if (phase === 'error') {
            // Let users only rely on the status property to display an icon.
            // If there's an error in the sync phase, let it show on that
            // status icon also.
            adjustedStatus = 'error';
        }
        if (status === 'not-started') {
            // If websocket isn't yet connected becase we're doing
            // the startup sync, let the icon show the symbol for connecting.
            if (phase === 'pushing' || phase === 'pulling') {
                adjustedStatus = 'connecting';
            }
        }
        const previousPhase = db.cloud.syncState.value.phase;
        //const previousStatus = db.cloud.syncState.value.status;
        if (previousPhase === 'error' && (syncState.phase === 'pushing' || syncState.phase === 'pulling')) {
            // We were in an errored state but is now doing sync. Show "connecting" icon.
            adjustedStatus = 'connecting';
        }
        /*if (syncState.phase === 'in-sync' && adjustedStatus === 'connecting') {
          adjustedStatus = 'connected';
        }*/
        if (!userIsActive) {
            adjustedStatus = 'disconnected';
        }
        const retState = {
            phase,
            error,
            progress,
            status: isOnline ? adjustedStatus : 'offline',
            license: 'ok'
        };
        return retState;
    }));
}

function createSharedValueObservable(o, defaultValue) {
    let currentValue = defaultValue;
    let shared = from(o).pipe(map$1((x) => (currentValue = x)), share({ resetOnRefCountZero: () => timer(1000) }));
    const rv = new Observable((observer) => {
        let didEmit = false;
        const subscription = shared.subscribe({
            next(value) {
                didEmit = true;
                observer.next(value);
            },
            error(error) {
                observer.error(error);
            },
            complete() {
                observer.complete();
            }
        });
        if (!didEmit && !subscription.closed) {
            observer.next(currentValue);
        }
        return subscription;
    });
    rv.getValue = () => currentValue;
    return rv;
}

const getGlobalRolesObservable = associate((db) => {
    return createSharedValueObservable(liveQuery(() => db.roles
        .where({ realmId: 'rlm-public' })
        .toArray()
        .then((roles) => {
        const rv = {};
        for (const role of roles
            .slice()
            .sort((a, b) => (a.sortOrder || 0) - (b.sortOrder || 0))) {
            rv[role.name] = role;
        }
        return rv;
    })), {});
});

const getInternalAccessControlObservable = associate((db) => {
    return createSharedValueObservable(getCurrentUserEmitter(db._novip).pipe(switchMap((currentUser) => liveQuery(() => db.transaction('r', 'realms', 'members', () => Promise.all([
        db.members.where({ userId: currentUser.userId }).toArray(),
        db.realms.toArray(),
        currentUser.userId,
    ]).then(([selfMembers, realms, userId]) => {
        //console.debug(`PERMS: Result from liveQUery():`, JSON.stringify({selfMembers, realms, userId}, null, 2))
        return { selfMembers, realms, userId };
    }))))), {
        selfMembers: [],
        realms: [],
        get userId() {
            return db.cloud.currentUserId;
        },
    });
    /* let refCount = 0;
    return new Observable(observer => {
      const subscription = o.subscribe(observer);
      console.debug ('PERMS subscribe', ++refCount);
      return {
        unsubscribe() {
          console.debug ('PERMS unsubscribe', --refCount);
          subscription.unsubscribe();
        }
      }
    })*/
});

function mapValueObservable(o, mapper) {
    let currentValue;
    const rv = o.pipe(map$1((x) => (currentValue = mapper(x))));
    rv.getValue = () => currentValue !== undefined
        ? currentValue
        : (currentValue = mapper(o.getValue()));
    return rv;
}

// TODO: Move to dexie-cloud-common
function mergePermissions(...permissions) {
    if (permissions.length === 0)
        return {};
    const reduced = permissions.reduce((result, next) => {
        const ret = Object.assign({}, result);
        for (const [verb, rights] of Object.entries(next)) {
            if (verb in ret && ret[verb]) {
                if (ret[verb] === '*')
                    continue;
                if (rights === '*') {
                    ret[verb] = '*';
                }
                else if (Array.isArray(rights) && Array.isArray(ret[verb])) {
                    // Both are arrays (verb is 'add' or 'manage')
                    const r = ret;
                    const retVerb = r[verb]; // "!" because Array.isArray(ret[verb])
                    r[verb] = [...new Set([...retVerb, ...rights])];
                }
                else if (typeof rights === 'object' &&
                    rights &&
                    typeof ret[verb] === 'object') {
                    // Both are objects (verb is 'update')
                    const mergedRights = ret[verb]; // because we've checked that typeof ret[verb] === 'object' and earlier that not ret[verb] === '*'.
                    for (const [tableName, tableRights] of Object.entries(rights)) {
                        if (mergedRights[tableName] === '*')
                            continue;
                        if (tableRights === '*') {
                            mergedRights[tableName] = '*';
                        }
                        else if (Array.isArray(mergedRights[tableName]) &&
                            Array.isArray(tableRights)) {
                            mergedRights[tableName] = [
                                ...new Set([...mergedRights[tableName], ...tableRights]),
                            ];
                        }
                    }
                }
            }
            else {
                /* This compiles without type assertions. Keeping the comment to
                   explain why we do tsignore on the next statement.
                if (verb === "add") {
                  ret[verb] = next[verb];
                } else if (verb === "update") {
                  ret[verb] = next[verb];
                } else if (verb === "manage") {
                  ret[verb] = next[verb];
                } else {
                  ret[verb] = next[verb];
                }
                */
                //@ts-ignore
                ret[verb] = next[verb];
            }
        }
        return ret;
    });
    return reduced;
}

const getPermissionsLookupObservable = associate((db) => {
    const o = createSharedValueObservable(combineLatest([
        getInternalAccessControlObservable(db._novip),
        getGlobalRolesObservable(db._novip),
    ]).pipe(map(([{ selfMembers, realms, userId }, globalRoles]) => ({
        selfMembers,
        realms,
        userId,
        globalRoles,
    }))), {
        selfMembers: [],
        realms: [],
        userId: UNAUTHORIZED_USER.userId,
        globalRoles: {},
    });
    return mapValueObservable(o, ({ selfMembers, realms, userId, globalRoles }) => {
        const rv = realms
            .map((realm) => {
            const selfRealmMembers = selfMembers.filter((m) => m.realmId === realm.realmId);
            const directPermissionSets = selfRealmMembers
                .map((m) => m.permissions)
                .filter((p) => p);
            const rolePermissionSets = flatten(selfRealmMembers.map((m) => m.roles).filter((roleName) => roleName))
                .map((role) => globalRoles[role])
                .filter((role) => role)
                .map((role) => role.permissions);
            return Object.assign(Object.assign({}, realm), { permissions: realm.owner === userId
                    ? { manage: '*' }
                    : mergePermissions(...directPermissionSets, ...rolePermissionSets) });
        })
            .reduce((p, c) => (Object.assign(Object.assign({}, p), { [c.realmId]: c })), {
            [userId]: {
                realmId: userId,
                owner: userId,
                name: userId,
                permissions: { manage: '*' },
            },
        });
        return rv;
    });
});

class PermissionChecker {
    constructor(permissions, tableName, isOwner) {
        this.permissions = permissions || {};
        this.tableName = tableName;
        this.isOwner = isOwner;
    }
    add(...tableNames) {
        var _a;
        // If user can manage the whole realm, return true.
        if (this.permissions.manage === '*')
            return true;
        // If user can manage given table in realm, return true
        if ((_a = this.permissions.manage) === null || _a === void 0 ? void 0 : _a.includes(this.tableName))
            return true;
        // If user can add any type, return true
        if (this.permissions.add === '*')
            return true;
        // If user can add objects into given table names in the realm, return true
        if (tableNames.every((tableName) => { var _a; return (_a = this.permissions.add) === null || _a === void 0 ? void 0 : _a.includes(tableName); })) {
            return true;
        }
        return false;
    }
    update(...props) {
        var _a, _b;
        // If user is owner of this object, or if user can manage the whole realm, return true.
        if (this.isOwner || this.permissions.manage === '*')
            return true;
        // If user can manage given table in realm, return true
        if ((_a = this.permissions.manage) === null || _a === void 0 ? void 0 : _a.includes(this.tableName))
            return true;
        // If user can update any prop in any table in this realm, return true unless
        // it regards to ownership change:
        if (this.permissions.update === '*') {
            // @ts-ignore
            return props.every((prop) => prop !== 'owner');
        }
        const tablePermissions = (_b = this.permissions.update) === null || _b === void 0 ? void 0 : _b[this.tableName];
        // If user can update any prop in table and realm, return true unless
        // accessing special props owner or realmId
        if (tablePermissions === '*')
            return props.every((prop) => prop !== 'owner');
        // Explicitely listed properties to allow updates on:
        return props.every((prop) => tablePermissions === null || tablePermissions === void 0 ? void 0 : tablePermissions.some((permittedProp) => permittedProp === prop || (permittedProp === '*' && prop !== 'owner')));
    }
    delete() {
        var _a;
        // If user is owner of this object, or if user can manage the whole realm, return true.
        if (this.isOwner || this.permissions.manage === '*')
            return true;
        // If user can manage given table in realm, return true
        if ((_a = this.permissions.manage) === null || _a === void 0 ? void 0 : _a.includes(this.tableName))
            return true;
        return false;
    }
}

function permissions(dexie, obj, tableName) {
    if (!obj)
        throw new TypeError(`Cannot check permissions of undefined or null. A Dexie Cloud object with realmId and owner expected.`);
    const { owner, realmId } = obj;
    if (!tableName) {
        if (typeof obj.table !== 'function') {
            throw new TypeError(`Missing 'table' argument to permissions and table could not be extracted from entity`);
        }
        tableName = obj.table();
    }
    const source = getPermissionsLookupObservable(dexie);
    const mapper = (permissionsLookup) => {
        // If realmId is undefined, it can be due to that the object is not yet syncified - it exists
        // locally only as the user might not yet be authenticated. This is ok and we shall treat it
        // as if the realmId is dexie.cloud.currentUserId (which is "unauthorized" by the way)
        const realm = permissionsLookup[realmId || dexie.cloud.currentUserId];
        if (!realm)
            return new PermissionChecker({}, tableName, !owner || owner === dexie.cloud.currentUserId);
        return new PermissionChecker(realm.permissions, tableName, realmId === undefined || realmId === dexie.cloud.currentUserId || owner === dexie.cloud.currentUserId);
    };
    const o = source.pipe(map(mapper));
    o.getValue = () => mapper(source.getValue());
    return o;
}

const getInvitesObservable = associate((db) => {
    const membersByEmail = getCurrentUserEmitter(db._novip).pipe(switchMap((currentUser) => liveQuery(() => db.members.where({ email: currentUser.email || '' }).toArray())));
    const permissions = getPermissionsLookupObservable(db._novip);
    const accessControl = getInternalAccessControlObservable(db._novip);
    return createSharedValueObservable(combineLatest([membersByEmail, accessControl, permissions]).pipe(map(([membersByEmail, accessControl, realmLookup]) => {
        const reducer = (result, m) => (Object.assign(Object.assign({}, result), { [m.id]: Object.assign(Object.assign({}, m), { realm: realmLookup[m.realmId] }) }));
        const emailMembersById = membersByEmail.reduce(reducer, {});
        const membersById = accessControl.selfMembers.reduce(reducer, emailMembersById);
        return Object.values(membersById)
            .filter((invite) => !invite.accepted)
            .map((invite) => (Object.assign(Object.assign({}, invite), { accept() {
                return __awaiter(this, void 0, void 0, function* () {
                    yield db.members.update(invite.id, { accepted: new Date() });
                });
            },
            reject() {
                return __awaiter(this, void 0, void 0, function* () {
                    yield db.members.update(invite.id, { rejected: new Date() });
                });
            } })));
    })), []);
});

function createYHandler(db) {
    return (provider) => {
        var _a;
        const doc = provider.doc;
        if (!doc) {
            throw new Error('Internal error: DexieYProvider.createYHandler called without a doc. This is unexpected.');
        }
        const { parentTable } = doc.meta || {};
        if (!((_a = db.cloud.schema) === null || _a === void 0 ? void 0 : _a[parentTable].markedForSync)) {
            return; // The table that holds the doc is not marked for sync - leave it to dexie. No syncing, no awareness.
        }
        let awareness;
        Object.defineProperty(provider, 'awareness', {
            get() {
                if (awareness)
                    return awareness;
                awareness = createAwareness(db, doc, provider);
                awarenessWeakMap.set(doc, awareness);
                return awareness;
            },
        });
    };
}
function createAwareness(db, doc, provider) {
    const { parentTable, parentId, parentProp, updatesTable } = doc.meta;
    const awareness = new awap.Awareness(doc);
    const reopenDocSignal = getOpenDocSignal(doc);
    awareness.on('update', ({ added, updated, removed }, origin) => {
        // Send the update
        const changedClients = added.concat(updated).concat(removed);
        const user = db.cloud.currentUser.value;
        if (origin !== 'server' && user.isLoggedIn && !isEagerSyncDisabled(db)) {
            const update = awap.encodeAwarenessUpdate(awareness, changedClients);
            db.messageProducer.next({
                type: 'aware',
                table: parentTable,
                prop: parentProp,
                k: doc.meta.parentId,
                u: update,
            });
            if (provider.destroyed) {
                // We're called from awareness.on('destroy') that did
                // removeAwarenessStates.
                // It's time to also send the doc-close message that dexie-cloud understands
                // and uses to stop subscribing for updates and awareness updates and brings
                // down the cached information in memory on the WS connection for this.
                db.messageProducer.next({
                    type: 'doc-close',
                    table: parentTable,
                    prop: parentProp,
                    k: doc.meta.parentId,
                });
            }
        }
    });
    awareness.on('destroy', () => {
        // Signal to server that this provider is destroyed (the update event will be triggered, which
        // in turn will trigger db.messageProducer that will send the message to the server if WS is connected)
        awap.removeAwarenessStates(awareness, [doc.clientID], 'provider destroyed');
    });
    // Open the document on the server
    (() => __awaiter(this, void 0, void 0, function* () {
        if (provider.destroyed)
            return;
        let connected = false;
        let currentFlowId = 1;
        const subscription = combineLatest([
            db.cloud.webSocketStatus, // Wake up when webSocket status changes
            reopenDocSignal.pipe(startWith$1(null)), // Wake up when reopenDocSignal emits
        ]).subscribe(([wsStatus]) => {
            if (provider.destroyed)
                return;
            // Keep "connected" state in a variable so we can check it after async operations
            connected = wsStatus === 'connected';
            // We are or got connected. Open the document on the server.
            const user = db.cloud.currentUser.value;
            if (wsStatus === 'connected' &&
                user.isLoggedIn &&
                !isEagerSyncDisabled(db)) {
                ++currentFlowId;
                openDocumentOnServer().catch((error) => {
                    console.warn(`Error catched in createYHandler.ts: ${error}`);
                });
            }
        });
        // Wait until WebSocket is connected
        provider.addCleanupHandler(subscription);
        /** Sends an 'doc-open' message to server whenever websocket becomes
         * connected, or if it is already connected.
         * The flow is aborted in case websocket is disconnected while querying
         * information required to compute the state vector. Flow is also
         * aborted in case document or provider has been destroyed during
         * the async parts of the task.
         *
         * The state vector is only computed from the updates that have occured
         * after the last full sync - which could very often be zero - in which
         * case no state vector is sent (then the server already knows us by
         * revision)
         *
         * When server gets the doc-open message, it will authorize us for
         * whether we are allowed to read / write to this document, and then
         * keep the cached information in memory on the WS connection for this
         * particular document, as well as subscribe to updates and awareness updates
         * from other clients on the document.
         */
        function openDocumentOnServer() {
            return __awaiter(this, void 0, void 0, function* () {
                const myFlow = currentFlowId; // So we can abort when a new flow is started
                const yTbl = db.table(updatesTable);
                const syncStateTbl = db.$syncState;
                const [receivedUntil, yServerRev] = yield db.transaction('r', syncStateTbl, yTbl, () => __awaiter(this, void 0, void 0, function* () {
                    const syncState = yield yTbl.get(DEXIE_CLOUD_SYNCER_ID);
                    const persistedSyncState = yield syncStateTbl.get('syncState');
                    return [
                        (syncState === null || syncState === void 0 ? void 0 : syncState.receivedUntil) || 0,
                        (persistedSyncState === null || persistedSyncState === void 0 ? void 0 : persistedSyncState.yServerRevision) ||
                            (persistedSyncState === null || persistedSyncState === void 0 ? void 0 : persistedSyncState.serverRevision),
                    ];
                }));
                // After every await, check if we still should be working on this task.
                if (provider.destroyed || currentFlowId !== myFlow || !connected)
                    return;
                const docOpenMsg = {
                    type: 'doc-open',
                    table: parentTable,
                    prop: parentProp,
                    k: parentId,
                    serverRev: yServerRev,
                };
                const serverUpdatesSinceLastSync = yield yTbl
                    .where('i')
                    .between(receivedUntil, Infinity, false)
                    .filter((update) => cmp(update.k, parentId) === 0 && // Only updates for this document
                    ((update.f || 0) & 1) === 0 // Don't include local changes
                )
                    .toArray();
                // After every await, check if we still should be working on this task.
                if (provider.destroyed || currentFlowId !== myFlow || !connected)
                    return;
                if (serverUpdatesSinceLastSync.length > 0) {
                    const mergedUpdate = Y.mergeUpdatesV2(serverUpdatesSinceLastSync.map((update) => update.u));
                    const stateVector = Y.encodeStateVectorFromUpdateV2(mergedUpdate);
                    docOpenMsg.sv = stateVector;
                }
                db.messageProducer.next(docOpenMsg);
            });
        }
    }))();
    return awareness;
}

const DEFAULT_OPTIONS = {
    nameSuffix: true,
};
function dexieCloud(dexie) {
    const origIdbName = dexie.name;
    //
    //
    //
    const currentUserEmitter = getCurrentUserEmitter(dexie);
    const subscriptions = [];
    let configuredProgramatically = false;
    // local sync worker - used when there's no service worker.
    let localSyncWorker = null;
    dexie.on('ready', (dexie) => __awaiter(this, void 0, void 0, function* () {
        try {
            yield onDbReady(dexie);
        }
        catch (error) {
            console.error(error);
            // Make sure to succeed with database open even if network is down.
        }
    }), true // true = sticky
    );
    /** Void starting subscribers after a close has happened. */
    let closed = false;
    function throwIfClosed() {
        if (closed)
            throw new Dexie.DatabaseClosedError();
    }
    dexie.once('close', () => {
        subscriptions.forEach((subscription) => subscription.unsubscribe());
        subscriptions.splice(0, subscriptions.length);
        closed = true;
        localSyncWorker && localSyncWorker.stop();
        localSyncWorker = null;
        currentUserEmitter.next(UNAUTHORIZED_USER);
    });
    const syncComplete = new Subject();
    dexie.cloud = {
        // @ts-ignore
        version: "4.2.5",
        options: Object.assign({}, DEFAULT_OPTIONS),
        schema: null,
        get currentUserId() {
            return currentUserEmitter.value.userId || UNAUTHORIZED_USER.userId;
        },
        currentUser: currentUserEmitter,
        syncState: new BehaviorSubject({
            phase: 'initial',
            status: 'not-started',
        }),
        events: {
            syncComplete,
        },
        persistedSyncState: new BehaviorSubject(undefined),
        userInteraction: new BehaviorSubject(undefined),
        webSocketStatus: new BehaviorSubject('not-started'),
        login(hint) {
            return __awaiter(this, void 0, void 0, function* () {
                const db = DexieCloudDB(dexie);
                yield db.cloud.sync();
                yield login(db, hint);
            });
        },
        invites: getInvitesObservable(dexie),
        roles: getGlobalRolesObservable(dexie),
        configure(options) {
            options = dexie.cloud.options = Object.assign(Object.assign({}, dexie.cloud.options), options);
            configuredProgramatically = true;
            if (options.databaseUrl && options.nameSuffix) {
                // @ts-ignore
                dexie.name = `${origIdbName}-${getDbNameFromDbUrl(options.databaseUrl)}`;
                DexieCloudDB(dexie).reconfigure(); // Update observable from new dexie.name
            }
            updateSchemaFromOptions(dexie.cloud.schema, dexie.cloud.options);
        },
        logout() {
            return __awaiter(this, arguments, void 0, function* ({ force } = {}) {
                force
                    ? yield _logout(DexieCloudDB(dexie), { deleteUnsyncedData: true })
                    : yield logout(DexieCloudDB(dexie));
            });
        },
        sync() {
            return __awaiter(this, arguments, void 0, function* ({ wait, purpose } = { wait: true, purpose: 'push' }) {
                var _a;
                if (wait === undefined)
                    wait = true;
                const db = DexieCloudDB(dexie);
                const licenseStatus = ((_a = db.cloud.currentUser.value.license) === null || _a === void 0 ? void 0 : _a.status) || 'ok';
                if (licenseStatus !== 'ok') {
                    // Refresh access token to check for updated license
                    yield loadAccessToken(db);
                }
                if (purpose === 'pull') {
                    const syncState = db.cloud.persistedSyncState.value;
                    triggerSync(db, purpose);
                    if (wait) {
                        const newSyncState = yield firstValueFrom(db.cloud.persistedSyncState.pipe(filter((newSyncState) => (newSyncState === null || newSyncState === void 0 ? void 0 : newSyncState.timestamp) != null &&
                            (!syncState || newSyncState.timestamp > syncState.timestamp))));
                        if (newSyncState === null || newSyncState === void 0 ? void 0 : newSyncState.error) {
                            throw new Error(`Sync error: ` + newSyncState.error);
                        }
                    }
                }
                else if (yield isSyncNeeded(db)) {
                    const syncState = db.cloud.persistedSyncState.value;
                    triggerSync(db, purpose);
                    if (wait) {
                        console.debug('db.cloud.login() is waiting for sync completion...');
                        yield firstValueFrom(from(liveQuery(() => __awaiter(this, void 0, void 0, function* () {
                            const syncNeeded = yield isSyncNeeded(db);
                            const newSyncState = yield db.getPersistedSyncState();
                            if ((newSyncState === null || newSyncState === void 0 ? void 0 : newSyncState.timestamp) !== (syncState === null || syncState === void 0 ? void 0 : syncState.timestamp) &&
                                (newSyncState === null || newSyncState === void 0 ? void 0 : newSyncState.error))
                                throw new Error(`Sync error: ` + newSyncState.error);
                            return syncNeeded;
                        }))).pipe(filter((isNeeded) => !isNeeded)));
                        console.debug('Done waiting for sync completion because we have nothing to push anymore');
                    }
                }
            });
        },
        permissions(obj, tableName) {
            return permissions(dexie._novip, obj, tableName);
        },
    };
    dexie.Version.prototype['_parseStoresSpec'] = Dexie.override(dexie.Version.prototype['_parseStoresSpec'], (origFunc) => overrideParseStoresSpec(origFunc, dexie));
    dexie.Table.prototype.newId = function ({ colocateWith } = {}) {
        const shardKey = colocateWith && colocateWith.substr(colocateWith.length - 3);
        return generateKey(dexie.cloud.schema[this.name].idPrefix || '', shardKey);
    };
    dexie.Table.prototype.idPrefix = function () {
        var _a, _b;
        return ((_b = (_a = this.db.cloud.schema) === null || _a === void 0 ? void 0 : _a[this.name]) === null || _b === void 0 ? void 0 : _b.idPrefix) || '';
    };
    dexie.use(createMutationTrackingMiddleware({
        currentUserObservable: dexie.cloud.currentUser,
        db: DexieCloudDB(dexie),
    }));
    dexie.use(createImplicitPropSetterMiddleware(DexieCloudDB(dexie)));
    dexie.use(createIdGenerationMiddleware(DexieCloudDB(dexie)));
    function onDbReady(dexie) {
        return __awaiter(this, void 0, void 0, function* () {
            var _a, _b, _c, _d, _e, _f, _g;
            closed = false; // As Dexie calls us, we are not closed anymore. Maybe reopened? Remember db.ready event is registered with sticky flag!
            const db = DexieCloudDB(dexie);
            // Setup default GUI:
            if (typeof window !== 'undefined' && typeof document !== 'undefined') {
                if (!((_a = db.cloud.options) === null || _a === void 0 ? void 0 : _a.customLoginGui)) {
                    subscriptions.push(setupDefaultGUI(dexie));
                }
            }
            if (!db.cloud.isServiceWorkerDB) {
                subscriptions.push(computeSyncState(db).subscribe(dexie.cloud.syncState));
            }
            // Forward db.syncCompleteEvent to be publicly consumable via db.cloud.events.syncComplete:
            subscriptions.push(db.syncCompleteEvent.subscribe(syncComplete));
            //verifyConfig(db.cloud.options); Not needed (yet at least!)
            // Verify the user has allowed version increment.
            if (!db.tables.every((table) => table.core)) {
                throwVersionIncrementNeeded();
            }
            const swRegistrations = 'serviceWorker' in navigator
                ? yield navigator.serviceWorker.getRegistrations()
                : [];
            const [initiallySynced, lastSyncedRealms] = yield db.transaction('rw', db.$syncState, () => __awaiter(this, void 0, void 0, function* () {
                var _a, _b;
                const { options, schema } = db.cloud;
                const [persistedOptions, persistedSchema, persistedSyncState] = yield Promise.all([
                    db.getOptions(),
                    db.getSchema(),
                    db.getPersistedSyncState(),
                ]);
                if (!configuredProgramatically) {
                    // Options not specified programatically (use case for SW!)
                    // Take persisted options:
                    db.cloud.options = persistedOptions || null;
                }
                else if (!persistedOptions ||
                    JSON.stringify(persistedOptions) !== JSON.stringify(options)) {
                    // Update persisted options:
                    if (!options)
                        throw new Error(`Internal error`); // options cannot be null if configuredProgramatically is set.
                    const newPersistedOptions = Object.assign({}, options);
                    delete newPersistedOptions.fetchTokens;
                    delete newPersistedOptions.awarenessProtocol;
                    yield db.$syncState.put(newPersistedOptions, 'options');
                }
                if (((_a = db.cloud.options) === null || _a === void 0 ? void 0 : _a.tryUseServiceWorker) &&
                    'serviceWorker' in navigator &&
                    swRegistrations.length > 0 &&
                    !DISABLE_SERVICEWORKER_STRATEGY) {
                    // * Configured for using service worker if available.
                    // * Browser supports service workers
                    // * There are at least one service worker registration
                    console.debug('Dexie Cloud Addon: Using service worker');
                    db.cloud.usingServiceWorker = true;
                }
                else {
                    // Not configured for using service worker or no service worker
                    // registration exists. Don't rely on service worker to do any job.
                    // Use LocalSyncWorker instead.
                    if (((_b = db.cloud.options) === null || _b === void 0 ? void 0 : _b.tryUseServiceWorker) &&
                        !db.cloud.isServiceWorkerDB) {
                        console.debug('dexie-cloud-addon: Not using service worker.', swRegistrations.length === 0
                            ? 'No SW registrations found.'
                            : 'serviceWorker' in navigator && DISABLE_SERVICEWORKER_STRATEGY
                                ? 'Avoiding SW background sync and SW periodic bg sync for this browser due to browser bugs.'
                                : 'navigator.serviceWorker not present');
                    }
                    db.cloud.usingServiceWorker = false;
                }
                updateSchemaFromOptions(schema, db.cloud.options);
                updateSchemaFromOptions(persistedSchema, db.cloud.options);
                if (!schema) {
                    // Database opened dynamically (use case for SW!)
                    // Take persisted schema:
                    db.cloud.schema = persistedSchema || null;
                }
                else if (!persistedSchema ||
                    JSON.stringify(persistedSchema) !== JSON.stringify(schema)) {
                    // Update persisted schema (but don't overwrite table prefixes)
                    const newPersistedSchema = persistedSchema || {};
                    for (const [table, tblSchema] of Object.entries(schema)) {
                        const newTblSchema = newPersistedSchema[table];
                        if (!newTblSchema) {
                            newPersistedSchema[table] = Object.assign({}, tblSchema);
                        }
                        else {
                            newTblSchema.markedForSync = tblSchema.markedForSync;
                            tblSchema.deleted = newTblSchema.deleted;
                            newTblSchema.generatedGlobalId = tblSchema.generatedGlobalId;
                        }
                    }
                    yield db.$syncState.put(newPersistedSchema, 'schema');
                    // Make sure persisted table prefixes are being used instead of computed ones:
                    // Let's assign all props as the newPersistedSchems should be what we should be working with.
                    Object.assign(schema, newPersistedSchema);
                }
                return [persistedSyncState === null || persistedSyncState === void 0 ? void 0 : persistedSyncState.initiallySynced, persistedSyncState === null || persistedSyncState === void 0 ? void 0 : persistedSyncState.realms];
            }));
            if (initiallySynced) {
                db.setInitiallySynced(true);
            }
            verifySchema(db);
            // Manage CurrentUser observable:
            throwIfClosed();
            if (!db.cloud.isServiceWorkerDB) {
                subscriptions.push(liveQuery(() => db.getCurrentUser()).subscribe(currentUserEmitter));
                // Manage PersistendSyncState observable:
                subscriptions.push(liveQuery(() => db.getPersistedSyncState()).subscribe(db.cloud.persistedSyncState));
                // Wait till currentUser and persistedSyncState gets populated
                // with things from the database and not just the default values.
                // This is so that when db.open() completes, user should be safe
                // to subscribe to these observables and get actual data.
                yield firstValueFrom(combineLatest([
                    currentUserEmitter.pipe(skip(1), take(1)),
                    db.cloud.persistedSyncState.pipe(skip(1), take(1)),
                ]));
                const yHandler = createYHandler(db);
                DexieYProvider.on.new.subscribe(yHandler);
                db.dx.once('close', () => {
                    DexieYProvider.on.new.unsubscribe(yHandler);
                });
            }
            // HERE: If requireAuth, do athentication now.
            let changedUser = false;
            const user = yield db.getCurrentUser();
            const requireAuth = (_b = db.cloud.options) === null || _b === void 0 ? void 0 : _b.requireAuth;
            if (requireAuth) {
                if (db.cloud.isServiceWorkerDB) {
                    // If this is a service worker DB, we can't do authentication here,
                    // we just wait until the application has done it.
                    console.debug('Dexie Cloud Service worker. Waiting for application to authenticate.');
                    yield firstValueFrom(currentUserEmitter.pipe(filter((user) => !!user.isLoggedIn), take(1)));
                    console.debug('Dexie Cloud Service worker. Application has authenticated.');
                }
                else {
                    if (typeof requireAuth === 'object') {
                        // requireAuth contains login hints. Check if we already fulfil it:
                        if (!user.isLoggedIn ||
                            (requireAuth.userId && user.userId !== requireAuth.userId) ||
                            (requireAuth.email && user.email !== requireAuth.email)) {
                            // If not, login the configured user:
                            changedUser = yield login(db, requireAuth);
                        }
                    }
                    else if (!user.isLoggedIn) {
                        // requireAuth is true and user is not logged in
                        changedUser = yield login(db);
                    }
                }
            }
            if (user.isLoggedIn && (!lastSyncedRealms || !lastSyncedRealms.includes(user.userId))) {
                // User has been logged in but this is not reflected in the sync state.
                // This can happen if page is reloaded after login but before the sync call following
                // the login was complete.
                // The user is to be viewed as changed becuase current syncState does not reflect the presence
                // of the logged-in user.
                changedUser = true; // Set changedUser to true to trigger a pull-sync later down.
            }
            if (localSyncWorker)
                localSyncWorker.stop();
            localSyncWorker = null;
            throwIfClosed();
            const doInitialSync = ((_c = db.cloud.options) === null || _c === void 0 ? void 0 : _c.databaseUrl) && (!initiallySynced || changedUser);
            if (doInitialSync) {
                // Do the initial sync directly in the browser thread no matter if we are using service worker or not.
                yield performInitialSync(db, db.cloud.options, db.cloud.schema);
                db.setInitiallySynced(true);
            }
            throwIfClosed();
            if (db.cloud.usingServiceWorker && ((_d = db.cloud.options) === null || _d === void 0 ? void 0 : _d.databaseUrl)) {
                if (!doInitialSync) {
                    registerSyncEvent(db, 'push').catch(() => { });
                }
                registerPeriodicSyncEvent(db).catch(() => { });
            }
            else if (((_e = db.cloud.options) === null || _e === void 0 ? void 0 : _e.databaseUrl) &&
                db.cloud.schema &&
                !db.cloud.isServiceWorkerDB) {
                // There's no SW. Start SyncWorker instead.
                localSyncWorker = LocalSyncWorker(db, db.cloud.options, db.cloud.schema);
                localSyncWorker.start();
                if (!doInitialSync) {
                    triggerSync(db, 'push');
                }
            }
            // Listen to online event and do sync.
            throwIfClosed();
            if (!db.cloud.isServiceWorkerDB) {
                subscriptions.push(fromEvent(self, 'online').subscribe(() => {
                    console.debug('online!');
                    db.syncStateChangedEvent.next({
                        phase: 'not-in-sync',
                    });
                    if (!isEagerSyncDisabled(db)) {
                        triggerSync(db, 'push');
                    }
                }), fromEvent(self, 'offline').subscribe(() => {
                    console.debug('offline!');
                    db.syncStateChangedEvent.next({
                        phase: 'offline',
                    });
                }));
            }
            // Connect WebSocket unless we are in a service worker or websocket is disabled.
            if (((_f = db.cloud.options) === null || _f === void 0 ? void 0 : _f.databaseUrl) &&
                !((_g = db.cloud.options) === null || _g === void 0 ? void 0 : _g.disableWebSocket) &&
                !IS_SERVICE_WORKER) {
                subscriptions.push(connectWebSocket(db));
            }
        });
    }
}
// @ts-ignore
dexieCloud.version = "4.2.5";
Dexie.Cloud = dexieCloud;

// In case the SW lives for a while, let it reuse already opened connections:
const managedDBs = new Map();
function getDbNameFromTag(tag) {
    return tag.startsWith('dexie-cloud:') && tag.split(':')[1];
}
const syncDBSemaphore = new Map();
function syncDB(dbName, purpose) {
    // We're taking hight for being double-signalled both
    // via message event and sync event.
    // Which one comes first doesnt matter, just
    // that we return the existing promise if there is
    // an ongoing sync.
    let promise = syncDBSemaphore.get(dbName + '/' + purpose);
    if (!promise) {
        promise = _syncDB(dbName, purpose)
            .then(() => {
            // When legacy enough across browsers, use .finally() instead of then() and catch():
            syncDBSemaphore.delete(dbName + '/' + purpose);
        })
            .catch((error) => {
            syncDBSemaphore.delete(dbName + '/' + purpose);
            return Promise.reject(error);
        });
        syncDBSemaphore.set(dbName + '/' + purpose, promise);
    }
    return promise;
    function _syncDB(dbName, purpose) {
        return __awaiter(this, void 0, void 0, function* () {
            var _a;
            let db = managedDBs.get(dbName);
            if (!db) {
                console.debug('Dexie Cloud SW: Creating new Dexie instance for', dbName);
                const dexie = new Dexie(dbName, { addons: [dexieCloud] });
                db = DexieCloudDB(dexie);
                db.cloud.isServiceWorkerDB = true;
                dexie.on('versionchange', stopManagingDB);
                yield db.dx.open(); // Makes sure db.cloud.options and db.cloud.schema are read from db,
                if (managedDBs.get(dbName)) {
                    // Avoid race conditions.
                    db.close();
                    return yield _syncDB(dbName, purpose);
                }
                managedDBs.set(dbName, db);
            }
            if (!((_a = db.cloud.options) === null || _a === void 0 ? void 0 : _a.databaseUrl)) {
                console.error(`Dexie Cloud: No databaseUrl configured`);
                return; // Nothing to sync.
            }
            if (!db.cloud.schema) {
                console.error(`Dexie Cloud: No schema persisted`);
                return; // Nothing to sync.
            }
            function stopManagingDB() {
                db.dx.on.versionchange.unsubscribe(stopManagingDB);
                if (managedDBs.get(db.name) === db) {
                    // Avoid race conditions.
                    managedDBs.delete(db.name);
                }
                console.debug(`Dexie Cloud SW: Closing Dexie instance for ${dbName}`);
                db.dx.close();
                return false;
            }
            try {
                console.debug('Dexie Cloud SW: Syncing');
                yield syncIfPossible(db, db.cloud.options, db.cloud.schema, {
                    retryImmediatelyOnFetchError: true,
                    purpose,
                });
                console.debug('Dexie Cloud SW: Done Syncing');
            }
            catch (e) {
                console.error(`Dexie Cloud SW Error`, e);
                // Error occured. Stop managing this DB until we wake up again by a sync event,
                // which will open a new Dexie and start trying to sync it.
                stopManagingDB();
                if (e.name !== Dexie.errnames.NoSuchDatabase) {
                    // Unless the error was that DB doesn't exist, rethrow to trigger sync retry.
                    throw e; // Throw e to make syncEvent.waitUntil() receive a rejected promis, so it will retry.
                }
            }
        });
    }
}
// Avoid taking care of events if browser bugs out by using dexie cloud from a service worker.
if (!DISABLE_SERVICEWORKER_STRATEGY) {
    self.addEventListener('sync', (event) => {
        console.debug('SW "sync" Event', event.tag);
        const dbName = getDbNameFromTag(event.tag);
        if (dbName) {
            event.waitUntil(syncDB(dbName, "push")); // The purpose of sync events are "push"
        }
    });
    self.addEventListener('periodicsync', (event) => {
        console.debug('SW "periodicsync" Event', event.tag);
        const dbName = getDbNameFromTag(event.tag);
        if (dbName) {
            event.waitUntil(syncDB(dbName, "pull")); // The purpose of periodic sync events are "pull"
        }
    });
    self.addEventListener('message', (event) => {
        console.debug('SW "message" Event', event.data);
        if (event.data.type === 'dexie-cloud-sync') {
            const { dbName } = event.data;
            // Mimic background sync behavior - retry in X minutes on failure.
            // But lesser timeout and more number of times.
            const syncAndRetry = (num = 1) => {
                return syncDB(dbName, event.data.purpose || "pull").catch((e) => __awaiter(void 0, void 0, void 0, function* () {
                    if (num === 3)
                        throw e;
                    yield sleep(60000); // 1 minute
                    syncAndRetry(num + 1);
                }));
            };
            if ('waitUntil' in event) {
                event.waitUntil(syncAndRetry().catch(error => console.error(error)));
            }
            else {
                syncAndRetry().catch(error => console.error(error));
            }
        }
    });
}
function sleep(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
}
//# sourceMappingURL=service-worker.js.map
